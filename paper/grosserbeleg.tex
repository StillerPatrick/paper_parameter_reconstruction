\documentclass[hyperref,german,beleg,final]{cgvpub}
\usepackage{subfigure}
\usepackage{pdfpages}
\usepackage{array}
\usepackage{listings}
\usepackage{placeins}
%weitere Optionen zum Ergänzen (in eckigen Klammern):
% 
% female	weibliche Titelbezeichnung bei Diplom
% bibnum	numerische Literaturschlüssel
% final 	für Abgabe	
% lof			Abbildungsverzeichis
% lot			Tabellenverzeichnis
% noproblem	keine Aufgabenstellung
% notoc			kein Inhaltsverzeichnis
% twoside		zweiseitig
\author{Patrick Stiller}
\title{Parameterrekonstruktion für Röntgen-Kleinwinkelstreuung mit Deep Learning}
\birthday{8. Januar 1994}
\placeofbirth{Dresden}
\matno{3951290}
\betreuer{Dr. Dmytro Schlesinger (TU Dresden), Dr. Heide Meißner (HZDR), Dr. Michael Bussmann (HZDR)}
\bibfiles{literatur}
\problem{\includepdf[pages=-]{Aufgabenstellung.pdf}}
\acknowledgments{Das Erstellen einer so umfangreichen Studienarbeit ist keineswegs nur die Leistung einer Person. Deswegen möchte ich mich bei all denjenigen bedanken, die mich bei der Erstellung dieses großen Belegs unterstützt haben.

Als Erstes möchte ich mich bei meinen beiden Betreuern Heide Meißner und Dmytro Schlesinger bedanken. Vielen Dank für die Geduld, konstruktive Kritik und vielen Ratschläge.  

Des Weiteren möchte ich mich bei meinem Kollegen Max Glaser bedanken, der immer für eine fachliche Diskussion zur Verfügung stand und die Arbeit Korrektur gelesen hat. 

Außerdem möchte ich mich bedanken bei: 
\\
\begin{itemize} 
\item Michael Bussmann (Betreuung)
\item Malte Zacharias (Hilfe bei der Simulation)
\item Matthias Werner (Motivation)
\item Thomas Kluge (Hilfestellung SAXS)
\item Tobias Sebastian Hahn (Korrektur)
\end{itemize}
 }

\begin{document}

\chapter{Einleitung}
Die Erforschung von laser-induzierten Plasmazuständen ist einer der Forschungsschwerpunkte des HZDR. Im Jahr 2018 wurde von Thomas Kluge ein Paper mit dem Titel: \glqq Observation of ultrafast solid-density plasma dynamics using femtosecond X-ray pulses from a free-electron laser \grqq \  \cite{SAXS18} veröffentlicht, welches die Charakterisierung von Plasma anhand des Streubildes der Kleinwinklelstreuung beschreibt. Das Experiment, welches in \cite{SAXS18} beschrieben wurde, nutzt ein Gitterförmiges Target, welches durch wenige Parameter beschreibbar ist. Um Plasma zu erzeugen, wird das Target mit einem Hochintentisätslaser beschossen. Für die Charkateriseirung des entstandenen Plasmas wird zusätzlich ein Röntgenlaser verwendet. Während des Beschusses durch den Röntgenlaser kommt es zu Streueffekten, welche durch einen Detektor, der hinter dem Target platziert ist, aufgenommen werden. Dieser Detektor ist zeit integrierend, das heißt, dass ankommende Wellen summiert werden und somit die Phaseninformationen der Photonen verloren gehen. 

Um die Struktur des Targets (Beschreibungsparameter) zu rekonstruieren, werden im Allgemeinen Phase-Retrieval-Algorithmen angewendet. Diese Algorithmen sind meistens iterativ und unterliegen Limitierungen. In diesem Beleg soll, anstatt iterativer Verfahren, Deep-Learning verwendet werden, um die Charakterisierung des Plasmas zu unterstützen. \glqq Deep-Learning erlaubt mathematischen Modellen, welche aus mehreren Verarbeitungsschichten bestehen, die Repräsentation von Daten auf verschiedenen Abstraktionsniveaus zu lernen. Deep Learning hat den Stand der Technik in Spracherkennung, Objekterkennung und in vielen anderen Bereichen wie der Genetik stark verbessert. [...] Deep Convolutional Neuronal Networks gelang der Durchbruch in der Verarbeitung von Text, Bild und Video.\grqq \  (\cite{deep_learning_cite}, Seite 1, Übersetzung des Autors). 

In diesem Beleg wurde eine umfangreiche Datenanalyse der Detekorbilder vorgenommen, um aus deren Erkenntnissen einen Protoyp eines Deep Learning Models zu entwickeln. Um das Deep-Learning Model zu trainieren, wurde mit Hilfe einer Simulation eine Datenbasis  aus synthetisch erzeugten Detektorbildern erstellt. Das trainierte Deep-Learning-Model wurde anschließend auf seine Qualität getestet und auf seine Tauglichkeit als Ersatz für die derzeit genutzte Vorwärtssimulation geprüft.
 
 
\chapter{Grundlagen}

\section{Physikalischer Hintergrund}

\subsection{Kleinwinkelstreuung}
Die Kleinwinkelstreuung, in Englisch Small Angle X-Ray Scattering (SAXS), ist eine universelle Technik zur Untersuchung von Feststoffen. Dabei kann SAXS Informationen über die kristalline Struktur, chemische Komposition und die physikalischen Eigenschaften eines untersuchten Feststoffes liefern \cite{THEORYSAXS}. Die Untersuchung von Feststoffen unter Einfluss von Hochintensitätslasern ist ein Schwerpunkt der heutigen Physik. Wissen über das Verhalten von Feststoffen unter Einfluss von Hochintensitätslasern kann offene Fragen in der Krebsforschung und in der Astrophysik beantworten. Dieser große Beleg bezieht sich auf die Publikation von Thomas Kluge, welche 2018 mit dem Titel:\ \grqq Observation of ultrafast solid-density plasma dynamics using femtosecond X-ray pulses from a free-electron laser\grqq \ veröffentlicht wurde. In der angesprochenen Publikation wurde SAXS für die Untersuchung von Plasma eingesetzt \cite{SAXS18}. Bisher konnte die Plasmadynamik, welche bei der Interaktion eines Feststoffes und eines Hochintensitätslasers entsteht, nur durch Simulationen modelliert werden. Mit Hilfe von SAXS gibt es neue Möglichkeiten, das entstehende Plasma zu charakterisieren. SAXS erreicht außerdem eine räumliche Auflösung im Femtosekunden-Bereich und eine zeitliche Auflösung im Nanosekunden-Bereich. Mit SAXS ist es möglich anhand der Einstrahlung auf den Detektor mit Hilfe von SAXS-Vorwärtssimulationen Aussagen über die Elektronendynamik im Plasma zu treffen \cite{SAXS18}.
 
\begin{figure}[ht]
	\centering
		\includegraphics [scale=0.5]{images/saxs_setup.png}
	\caption{Links: Schematischer Aufbau des Experimentaufbaus. Rechts: der Abbildung sind Detektorbilder in Abhängigkeit der 					Bestrahlungsdauer des Hochintensitätslasern dargestellt. Bildquelle: \cite{SAXS18}}
	\label{fig:saxssetup}
\end{figure}

\subsection{Experimentbeschreibung} \label{Experiment}

Das in \cite{SAXS18} beschriebene Experiment besteht aus vier Hauptkomponenten (siehe Abbildung \ref{fig:saxssetup} links): dem Target (Mitte), dem Hochintensitätslasern (UHI) (Links), dem Röntgen-Freie-Elektronen-Laser (XFEL) (links unten) und dem Detektor (rechts oben). Der Hauptbestandteil des Targets ist Kupfer. Um eine analytische Beschreibung des Experimentausgangs zu ermöglichen, wurde eine Gitterstruktur in das Kupfertarget eingraviert. Zusätzlich wurde das Taget mit einer 2 $\mu$m breiten Siliziumschicht überzogen. Durch die eingravierte Gitterstruktur besitzt das Target einen eindimensionalen Informationsgehalt und kann somit durch drei Parameter vollständig beschrieben werden. Die drei Paramter sind Pitch, Feature-Size und die Aufweichungsbreite Sigma($ \sigma $). Dabei beschreiben Pitch und Feature-Size die Struktur des Targets und Sigma($ \sigma $) den Aufweichungseffekt des Hochintensitätslasers (siehe Abbildung \ref{fig:grating_structure}). Die Gesamtheit des Targets wird auch als Grating bezeichnet. Erhebungen des Gratings werden als Features bezeichnet. Im weiteren Verlauf dieser Arbeit wird der Begriff Streudichte $\eta$ verwendet, welcher oft im Zusammenfang des SAXS-Ansatzes fällt. Der Begriff Streudichte $\eta$ wird in dieser Arbeit als Synonym für das Gitter verwendet. 

\begin{figure}[hh]
	\centering
		\includegraphics [scale=0.5]{images/grating_structure.png}
	\caption{Analytische Beschreibung des Querschnittes des Targets. Dabei ist das Grating zu erkennen und dass es durch drei Parameter: Pitch, Feature-Size und Sigma beschrieben werden kann. Bildquelle: \cite{Zach17}}
	\label{fig:grating_structure}
\end{figure}

Während des Experiments wird das Target durch einen Hochintensitätslasers in einem Winkel von 90° beschossen. Aufgrund des elektrischen Feldes des Lasers entsteht Plasma. Bei Plasma handelt es sich um ein Gemisch aus freien Elektronen, positiven Ionen und neutralen Teilchen, welche unter ständiger Wechselwirkung miteinander und mit Photonen stehen. Dadurch kann es zu unterschiedlichen Energie- bzw. Anregungszuständen kommen. Der Plasmazustand eines Stoffes wird auch als vierter Aggregatzustand bezeichnet \cite{PLASMADEF}. Während des Beschusses durch den Hochintensitätslasers ist außerdem ein Schmelzprozess und somit eine Aufweichung der Gitterstruktur des Targets wahrzunehmen (siehe Abbildung \ref{fig:melting_grating}). Das durch den Hochintensitätslasers erzeugte Plasma soll auf seine Struktur und Elektrodynamik mit Hilfe von SAXS untersucht werden. Dafür wird leicht zeitversetzt ein zweiter Laser benutzt. Dabei handelt es sich um einen Röntgen-Freie-Elektronen-Laser, welcher in einem Winkel von 45° mit einer Pulsdauer von 40 Femtosekunden auf das Target schießt. Bei diesem Vorgang kommt es zu einer Streuung des Lichts des Röntgenlasers an den Elektronen des Targets. Die Lichtintensitäten des gestreuten Röntgenlasers werden durch einen Detektor, welches hinter dem Target platziert ist, gemessen (Abbildung \ref{fig:saxssetup} links). 

\begin{figure}[hh]
\centering
\includegraphics [scale=0.7]{images/melting_grating.png}
\caption{Veränderung des Gratings nach einer Bestrahlungsdauer von 60 Femtosekunden Bildquelle: \cite{SAXS18}}
\label{fig:melting_grating}
\end{figure}

Beim Detektor handelt es sich um ein Raster von Lichtdetektoren, welche die ankommenden Lichtintensitäten messen. Dabei integriert der Detektor über die Zeit, das heißt, dass ankommende Lichtintensitäten über die Zeit summiert werden. Dieser Effekt ist in der Abbildung \ref{fig:electron_scattering} zu erkennen, welche einen beispielhaften Streuprozess an zwei Elektronen zeigt. 

\begin{figure}[hh]
	\centering
		\includegraphics [scale=0.4 ]{images/electron_scattering.png}
	\caption{Beispielhafte Darstellung einer Streuung an zwei Elektronen. Die Röntgenlaserpulse treffen geradlinig auf die Elektronen und werden dann bei den Elektronen gestreut. Der Detektor dahinter misst die ankommenden Intensitäten der kreisförmigen Wellen und summiert diese über die Zeit.  Bildquelle: \cite{Zach17}}
\label{fig:electron_scattering}
\end{figure}

Durch die Zeitintegration des Detektors gehen die zeitlichen Abstände der Wellen verloren (Phase). Das entstandene Detektorsignal skaliert mit dem  Betragsquadrat der Fouriertransformation der Gitterstruktur $\eta $ (siehe Gleichung \eqref{eq:xrayscattering}) \cite{SAXS18}.


\begin{equation}\label{eq:xrayscattering}
\Phi  \propto | \int \eta (\vec r) \cdot e^{i\vec q \vec r} d \vec r|^2
\end{equation}


\section{Problemidentifikation }
Eine der Herausforderungen des beschriebenen Experimentes ist die Zeitintegration des Detektors. Diese Detektoreigenschaft ruft den Verlust der Phase hervor, sodass eine Rekonstruktion der Elektronendichteverteilung $ \eta $ mit Hilfe einer inversen Fouriertransformation nicht möglich ist. Um dieses Problem zu lösen, werden iterative Algorithmen, sogenannte Phaseretrieval-Algorithmen verwendet. Beispiele für solche Algorithmen sind \cite{Fienup:82}: Error-Reduction Algorithm, Gradient Search Methods und der Input-Output Algorithmus. Probleme bei diesen Algorithmen sind, dass erstens bei allen Algorithmen keine Konvergenz zum richtigem Ergebnis nicht garantiert ist und zweitens die Anzahl der Iterationen, die notwendig sind, um eine Optimierung der errechneten Phase zu erzeugen nicht bekannt ist. Diese Eigenschaften führen dazu, dass eine hochfrequente Verarbeitung von Experimentergebnissen verwehrt bleibt. Deswegen soll mit Hilfe von Deep Learning die Parameter zur Beschreibung der Gitterstruktur rekonstruiert werden. Neural  Networks haben den Vorteil, dass sie ihre Schätzung nicht iterativ bestimmen (Einschrittverfahren)

\section{Fouriertransformation}
Die Fouriertransformation (benannt nach Jean Baptiste Joseph Fourier) ist eine Transformation, welche zeitbezogene Wellen im Ortsraum in ihre frequenzmä\ss igen Spektralanteile zerlegt. Die Fouriertransformation wird auch als Transformation vom Orts- in den Frequenzraum bezeichnet. Die Fouriertransformation $F(u)$ einer Welle $f(x)$ ist folgendermaßen definiert:

\begin{equation}\label{eq:fourier-series}
F ( u ) = \int _ { - \infty } ^ { \infty } f ( x ) e ^ { - 2 \pi i x u } d x
\end{equation}


Die Spektralanteile \textit{F(u)} werden wie bei einem Basiswechsel durch ein Integral bestimmt. Dabei ist das Ergebnis des Integrals die Länge der Projektion in Richtung der durch $ u $ kodierten Frequenz. Im endlich-diskreten Fall wird das Integral durch eine Summe bis zur Anzahl der zu verwendeten Wellen ersetzt.  Jede Stelle u der Fouriertransformation kodiert eine Welle $e ^ { - 2 \pi i x u }$, welche über die Euler-Identität $e ^ { i k x } = \cos ( k x ) + i \cdot \sin ( k x )$ auch durch ihre Kosinus- und Sinusanteile beschrieben werden kann. Der Funktionswert der Fouriertransformation \textit{F(u)} kodiert mit welchem Anteil die durch \textit{u} kodierte Frequenz verwendet wird. Das Ergebnis der Fouriertransformation kann auch durch das Amplituden- und durch das Phasenspektrum beschrieben werden. Dabei bestimmt die Amplitude das Maximum und das Minimum der jeweiligen Welle und die Phase die Verschiebung der jeweiligen Welle.  Um die Amplitude $| F ( u ) | $ und die  Phaseninformation $\phi ( u )$ einer komplexen Zahl $ u $ zu errechnen, werden folgende Gleichungen verwendet \cite{FOURIER2}:

\begin{equation}
| F ( u ) | = \sqrt { R ^ { 2 } ( u ) + I ^ { 2 } ( u ) }
\end{equation}

\begin{equation}
\phi ( u ) = \tan ^ { - 1 } \frac { I ( u ) } { R ( u ) }
\end{equation}


\section{Filter}

Ein Filter ist eine Operation, welche auf einem Signal verwendet wird, um Signale zu glätten, Signalstörungen zu vermeiden, oder um Rauschen zu verhindern. In den meisten Fällen wird die Filteroperation mit Hilfe von Faltung realisiert. Die Faltung zweier Funktionen $(f * g)$ wird durch den funktionalen Zusammenhang in Formel \eqref{eq:convolution} beschrieben. Dabei ist $f$ die Funktion, welche das Signal beschreibt und $g$ die Funktion, welche den Filter beschreibt. Im diskreten Fall wird das Integral durch eine Summe bis zur entsprechenden Filtergröße ersetzt \cite{CONV}. 

\begin{equation}\label{eq:convolution}
( f * g ) ( x ) : = \int _ { \mathbb { R } ^ { n } } f ( \tau ) g ( x - \tau ) \mathrm { d } \tau
\end{equation}



\section{Neural Networks}
Neural Networks sind eine mathematische Adaption des realen menschlichen Gehirns. Wie im realen menschlichen Gehirn sind Neuronen miteinander verbunden, um einen Informationsfluss zu gewährleisten. Die ersten Ansätze für Neural Networks wurden bereits 1943 von Warren McCulloch und Walter Pitts entwickelt \cite{Kriesel2007NeuralNetworks}. Heute sind Neural Networks der Schwerpunkt des Machine Learnings und werden auf großen Datenmengen angewendet, um ein gewünschtes Verhalten zu trainieren. 

\subsection{Aufbau}
Ein Neural Network besteht aus vielen kleinen Komponenten, Neuronen, welche durch gerichtete und gewichtete Verbindungen verbunden sind.  Sämtliche Beschreibungen und Notationen beziehen sich auf \cite{Kriesel2007NeuralNetworks}. Mathematisch definiert ist ein Neural Network als ein Tripel $(N,V,w)$ mit den Beiden Mengen $N$ und $V$ und der Funktion $w$.  $N$ ist die Menge aller Neuronen und $V$ = $\{ (i,j) |  i, j \epsilon \mathbb{N}\}$ die Menge der Verbindungen zwischen Neuron i und Neuron j. Die Funktion $w : V \longrightarrow \mathbb{R} $  beschreibt die Gewichte des Neural Networks, wobei $w(i,j)$ das Gewicht zwischen dem Neuron i und Neuron j beschreibt. Im Allgemeinen wird anstatt der Funktionsnotation die Notation $w_{i,j}$ für die Gewichte zwischen zwei Neuronen verwendet. Die nächste wichtige Komponente ist die Propagierungsfunktion $net_{j}$  eines Neurons, welche einen wichtigen Teil des Informationsflusses in einem Neural Networks definiert. Dabei wird der Input des Neurons j durch dessen Propagierungsfunktion $net_{j}$ bestimmt. Die Propagierungsfunktion $net_{j}$ nimmt den Output aller Neuronen, welche eine ausgehende Verbindung zum Neuron j besitzen als Input.  So wird die Propagierungsfunktion $net_{j}$ durch folgenden funktionalen Zusammenhang beschrieben : 

\begin{equation}\label{eq:propagation_function}
 net_ { j } = \sum _ { i \in I_{j}} ( o _ { i }\cdot w _ { i , j }) \textrm{ mit } I_{j} = \{\ i \ \epsilon \  N\ |\ (i,j) \  \epsilon \  V\ \}
\end{equation}

Der Output  $o_{j} $ eines Neurons $j$ wird mit Hilfe der Aktivierungsfunktion $a_{j}$ und der Propagierungsfunktion  $net_{j}$  berechnet. Dazu wird noch der Schwellwert $ \theta_{j} $ zur Hemmung des Aktivierungszustandes des Neurons zur Hilfe genommen. Somit ergibt sich für den Output des Neurons folgender funktionaler Zusammenhang: 

\begin{equation}
o_{j} = a_{j}(net_{j} - \theta_{j}) = f(x)
\end{equation}

In den meisten Fällen werden differenzierbare Aktivierungsfunktionen benutzt, da sie den Lernprozess des Neural Networks erleichtern. Für diesen Beleg ist die Rectified Linear Unit- Aktivierungsfunktion (Formel \eqref{eq:relu}) relevant.


\begin{equation}\label{eq:relu}
f(x)= max(0,x)
\end{equation}

Die ReLu-Aktivierungsfunktion ist im Vergleich zu anderen Aktivierungsfunktionen schneller zu berechnen und bietet größere Gradienten. Jedoch können Neuronen, welche einen negativen Input bekommen nur noch 0 Ausgeben. Es wird in diesem Zusammenhang von einem gestorbenen Neuron gesprochen. Ein weiterer Nachteil der ReLu-Aktivierungsfunktion ist der Wertebereich, denn dieser ist nach oben nicht eingeschränkt. Somit können in einem Neuronalen Netz sehr große Werte entstehen, welche den Wertebereich von Zahlenstandards wie zum Beispiel IEEE 754 (Single Precision Float 32-Bit) \cite{IEEE754} überschreiten, womit kein valider Datenfluss im Neural Network gegeben ist. 

\subsection{Feed-Forward Neural  Networks}
Für ein Neural Network können verschiedene Netzwerktopologien verwendet werden. Ein Beispiel dafür sind Feed-Forward Neural Networks (Abbildung \ref{fig:ffnn}). Bei einem Feed-Forward Neural Network werden die Neuronen als Schichten (Layer) angeordnet. Diese Layer sind miteinander verbunden. Die erste Layer, welche die Input Daten bekommt, wird als Input-Layer bezeichnet. Die letzte Layer, welche die Netzberechnung ausgibt, wird als Output-Layer bezeichnet. Schichten, welche sich zwischen Input- und Output-Layer befinden und somit keinen Kontakt nach Außen haben, werden als Hidden Layer bezeichnet.Ein wichtiges Merkmal von Feed-Forward Neural Networks ist, dass der Datenfluss geradlinig  vom Input-Layer über die Hidden-Layer zum Output-Layer ohne Rückkopplung verläuft. Eine wichtige Komponente von Feed-Forward Neural Networks sind die Fully-Connected Layer. Bei einem Fully-Connected Layer ist jedes Neuron des Fully-Connected Layer mit jedem Neuron des vorherigen Layers verbunden. In Abbildung \ref{fig:ffnn} sind die Verbindungen eines Fully-Connected Layer dargestellt.  

\begin{figure}[hh]
\centering
\includegraphics [scale=0.4]{images/feed_forward_neuronal_network.png}
\caption{Beispielhafte Darstellung eines Feed-Forward Neural Networks. Bildquelle: \cite{COMPMETHODS}}
\label{fig:ffnn}
\end{figure}

\subsection{Lernprozess}
Das Anlernen von Neural Networks wird in den meisten Fällen durch überwachtes Lernen (supervised Learning) realisiert. Im Speziellen wird der Lernprozess durch den Backpropagation-Algorithmus und Gradientenabstiegsverfahren durchgeführt. Bei einem überwachten Lernansatz besteht der Datensatz zum Trainieren des Neural Networks aus zwei Teilen. Zu jedem Netzinput $x_{i}$ gibt es ein zugehöriges Label $y_{i}$, welches den gewünschten Netzoutput definiert. Der Lernprozess eines Neural Networks kann in drei Phasen eingeteilt werden: dem Forward-Pass, die Loss-Calculation und dem Backward Pass \cite{NeuronaleNetze}. Zu Beginn des Trainingsprozesses werden die Gewichte des Neuronalen Netzes mit Zufallszahlen initialisiert. In vielen Implementationen werden die Gewichte zufällig und normal verteilt initialisiert. Beim Forward Pass werden die Input-Daten zur Kalkulation des derzeitigen Netz-Outputs zum Input-Layer des Neural Network gegeben. Das Neural Network bestimmt dann durch die Rechenvorschriften des Neural Network den Netz-Output $\hat { y } _ { i }$. Im zweiten Schritt wird die Qualität des Net-Ouputs $\hat { y } _ { i }$ bestimmt. Dazu wird ein Fehlermaß benutzt, das den Grad des Unterschiedes zwischen $\hat { y } _ { i }$ und $y_{i}$  bestimmt. Eine beispielhafte Fehlerfunktion ist Mean-Squared Error \eqref{eq:mse}. 


\begin{equation}\label{eq:mse}
\mathrm { MSE } = \frac { 1 } { n } \sum _ { i = 1 } ^ { n } \left( Y _ { i } - \hat { Y } _ { i } \right) ^ { 2 }
\end{equation}

Im dritten Schritt, dem Backward-Pass, kommt es zur Optimierung des Neuronalen Netzes. Mithilfe des Fehlers, welcher bis zur Eingabeschicht zurück propagiert wird, werden die Gewichte entsprechend ihres Einflusses auf den Net-Output \eqref{eq:gradient} mittels Gradientenabstiegsverfahrens angepasst. Für die Anwendung des Gradientenabstiegsverfahrens werden die partiellen Ableitungen des Fehlerterms benötigt. Die Gewichtsveränderung $\Delta w _ { i j }$ des Gewichts zwischen Neuron $i$ und Neuron $j$  ergibt sich durch folgenden funktionalen Zusammenhang : 

\begin{equation}\label{eq: deltaw}
\Delta w _ { i j } = - \lambda \frac { \partial E } { \partial w _ { i j } } = - \lambda \delta _ { j } o _ { i }
\end{equation}

Dabei ist \textit{E} die Errorfunktion, $\delta _ { j }$ dem Gradient  des Neurons j,  $o _ { i }$ die Ausgabe des Neurons i. Der Parameter $\lambda $ , welcher die Learning-Rate des Gradientenabstiegsverfahren bestimmt. Schlussendlich fehlt die Definition des Gradienten. Dieser ist davon abhängig, wie stark ein Neuron den Output des Neuronalen Netzes beeinträchtigt. Deswegen wird eine Unterscheidung getroffen, ob ein Neuron sich im Output-Layer oder dem Hidden- bzw. Input-Layer befindet. In der folgenden Gleichung \eqref{eq:gradient} ist die Definition des Gradienten und die zugehörige Propagierung des Fehlers definiert. 


\begin{equation}\label{eq:gradient}
\delta _ { j } = \left\{ \begin{array} { l l } { a_{j}  \left( net_{ j } \right) \left( o _ { j } - t _ { j } \right) } & { \text { falls } j \text { sich in der Output-Layer befindet} } \\ { a_{j}  \left( net_{ j } \right) \sum _ { k } \delta _ { k } w _ { j k } } & { \text { falls } j \text { verdecktes Neuron oder ein Input-Neuron ist } } \end{array} \right.
\end{equation}

Dabei ist die Gleichung \eqref{eq:gradient} in Abhängigkeit von den Variablen $o_{j}$, die Soll-Ausgabe  $t_{j}$ des Neurons $j$ und der Aktivierungsfunktion $a_{j} $ des Neurons $j$ angegeben. Somit ergibt sich das neue Gewicht durch eine Addition des alten Gewichts mit der errechneten Gewichtsveränderung. 

\begin{equation}
w _ { i j } ^ { \text { neu } } = w _ { i j } ^ { \text { alt } } + \Delta w _ { i j }
\end{equation} 

Der Backpropagation-Algorithmus wird iterativ solange angewandt, bis eine bestimmte Anzahl von Iterationen erreicht ist oder andere Kriterien erfüllt sind \cite{wiki:Backpropagation}.

\subsection{Convolutional Neural Networks} \label{CNN}
Klassische Neural Networks besitzen die Einschränkung, dass deren Inputs als Vektoren geliefert werden müssen. Soll ein klassisches Neural Network zum Beispiel ein Bild der Größe $N   \times M \times C$ (C steht für Kanäle) verarbeiten, muss das Bild in einen Vektor der Größe $ N * M * C $ transformiert werden (Flatten). Convolutional Neural Networks (CNNs) besitzen im Gegensatz zu klassischen Neural Networks Convolutional Layer, und können somit Inputs höherer Dimension verarbeiten. Dazu sind die Neuronen als Filter $k$ der Größe $ H \times  W \times D $ (Höhe Breite,Tiefe) angeordnet. In diesem Kapitel wird von einem Filter mit quadratischer Grundfläche ausgegangen ($ H = W$). Zur Berechnun des jeweiligen Layer-Outpus führt ein Filter $k$ an einer Position $(x,y)$ des Inputs $I$  eine zweidimensionale diskrete Faltung \eqref{eq:2Dconv} \cite{2DCONV} durch und berechnet somit einen Datenpunkt der Feature-Map $I ^{*} $ (Ergebnis eines Filters des Convolutional Layers).  Der Parameter $a$ in der Faltungsformel \eqref{eq:2Dconv} steht für die Koordinate des Mittelpunktes des Filters. Ist der Filter die Grundfläche des Filters zum Beispiel $5 \times 5$, so ist der Wert von $a$ drei \cite{cnn_basics}.


\begin{equation}\label{eq:2Dconv}
 	I ^ { * } ( x , y ) = \sum _ { i = 1 } ^ { H} \sum _ { j = 1 } ^ { W } I ( x - i + a , y - j + a ) k ( i , j )
\end{equation}
 
Zur Berechnung des nächsten Datenpunktes der Feature Map $I ^{*} $ wird der Filter um eine Schrittweite   (\textit{stride}) auf dem Input  verschoben. Sollten für die Berechnung von $ I ^ { * } ( x , y )$ Datenpunkte benötigt werden, welche über den Rand des Inputs hinaus liegen, müssen diese Punkte auf eine andere Weise bestimmt werden. Eine mögliche Strategie ist das vernachlässigen dieser Punkte, was je nach Größe des Filters eine Verkleinerung der Feature-Map $I ^ { * }$ zur Folge hätte. Die zweite mögliche Strategie, welche die fehlenden Datenpunkte zur Verfügung stellt, ist das Zero-Padding, welches die fehlenden Datenpunkte mit dem Wert Null ersetzt. Außerdem besteht die dritte Möglichkeit, dass die fehlenden Datenpunkte mit dem dazugehörigen Randwert ersetzt werden \cite{ZeroPadding} . 

Nach Ausführung der Faltung wird die errechnete Feature-Map durch eine ausgewählte Aktivierungsfunktion verarbeitet. Ein Convolutional-Layer besteht nicht nur aus einem Filter, sondern kann mehrere Filter enthalten. Für jeden Filter wird die vorher beschriebene Faltung separat ausgeführt und die entstandenen Feature-Maps werden konkateniert. Somit ergibt sich für den Output eines Convolutional-Layer mit einer Stride von 1, Zero-Padding und 32 Filtern eine Dimension von $(N, M, 32)$. In einem Convolutional Neural Network können dann beliebige viele Layer hintereinander platziert werden. Zur Verarbeitung des letzten Convolutional-Layers wird in den meisten Fällen die letzte Layer in einen Vektor transformiert, um  durch ein Fully-Connected Layer weiterverarbeitet werden zu können (siehe Abbildung \ref{fig:cnn_archtitecture}. 

\begin{figure}[hh]
\centering
\includegraphics [scale=0.7]{images/cnn_architecture.png}
\caption{Beispielhafte Darstellung eines Convolutional Neural Networks. Bildquelle: \cite{ZeroPadding}}
\label{fig:cnn_archtitecture}
\end{figure}

Für diesen Beleg sind aufgrund der Eindimensionalität der Input-Daten 1D-Convolutional-Layer relevant. Bei einem 1D-Convolutional Layer sind die Filter eindimensional, das heißt, dass die Filter eine Höhe von 1 besitzen und der Filter nur entlang einer Dimension verschoben wird.. 

\subsection{Residual Strukturen}
Wie in Kapitel \ref{CNN} beschrieben, können beliebig viele Convolutional-Layers hintereinander platziert werden. Je mehr Layer verwendet werden, desto tiefer wird das Netz. Mit steigender Tiefe des Netzes erhöht sich das Problem kleiner werdender Gradienten  (Vanishing-Gradient Problem). Das Vanishing Gradient Problem ist auf die Eigenschaft der Backpropagation zurückzuführen, dass die Gradienten Neuronen-Gewichte in Abhängigkeit zu deren Einfluss auf den Net-Output stehen. Bei tieferen Netzstrukturen verringert sich dieser Einfluss. Um den Einfluss der Neuronen auf den Net-Output zu erhöhen, werden Skip-Connections, auch Residual Strukturen genannt, benutzt. Dazu wird der Output eines Layers auf den Input z.B. der übernächsten Schicht addiert. Es sind auch Skip-Connections mit einer höheren Schrittweite möglich \cite{ResNet}.

\begin{figure}[hh]
\centering
\includegraphics [scale=0.7]{images/ResNet.png}
\caption{Realisierung einer Skip-Connection in einem Neural Network. Bildquelle: \cite{ResNet}}
\label{fig:res_net_archtitecture}
\end{figure}




\chapter{Simulation} \label{Simulation}
\section{Motivation}
Um das Ergebnis des SAXS-Experiments bestmöglich zu verstehen und aufgrund einer geringen Anzahl von Experimentdaten, wurde im Rahmen der Master-Arbeit von Malte Zacharias mit dem Titel \grqq Model-Driven Parameter Reconstruction from Small Angle X-Ray Scattering Images\grqq \  eine Modellierung entwickelt. Die Modellierung beinhaltet das Design der Gitterstruktur (Elektronendichteverteilung), die Modellierung des Hochenergielasereinflusses, die Modellierung des Streuvorgangs und die Modellierung des Detektorbildes. Die durch Malte Zacharias erstellte Simulation wurde für diese Arbeit zur Generierung der Datenbasis genutzt. 

\section{Simulationsbeschreibung}
\subsection{Design der Gitterstruktur und Simulation des Hochenergielasereinflusses}
Wie in Kapitel 2 beschrieben sind die Targets des SAXS-Experiments als Gitter strukturiert, um eine analytische Beschreibung des Experiments zu ermöglichen. Der erste Simulationsschritt ist die Bestimmung der Gitterstruktur. Die Breite des Gratings ist auf N Pixel beschränkt. Die Struktur des Gratings ist über die drei Startparameter Pitch, Feature-Size und Sigma definiert. Der Parameter Feature-Size legt die Breite eines Features fest und der Parameter Pitch bestimmt die Periodizität eines Features, womit beide Parameter für die Struktur des Gratings ohne Einfluss des Hochintensitätslasers verantwortlich sind. Der Parameter Sigma  $\sigma$ bestimmt die Aufweichungsbreite des Gratings und modelliert den Einfluss des Hochenenintensitätslasers. 

Zur Modellierung eines Features mit Hochintensitätslasereinfluss. Dazu wird eine Rechteckfunktion (\( 1_{[0,\text{Feature-Size}]} \)), welche die Breite eines Features festlegt mit einer Gaussverteilung (\(\exp \left( - x ^ { 2 } / 2 \sigma ^ { 2 } \right) \)) gefaltet \cite{SAXS18}. Das Ergebnis der Faltung wird mit Hilfe der Errorfunktion (Gleichung \eqref{eq:erf}) dargestellt. 

\begin{equation}\label{eq:erf}
\text{erf(x)} = \frac{2}{\sqrt{\pi}} \int_{0}^{x} e^{-\xi^{2}}d\xi
\end{equation}


\begin{equation}\label{eq:feature}
	\tilde{\eta} = \frac{\sqrt{\pi}\sigma}{2}(\text{erf}(\frac{x}{\sqrt{2}\sigma}) - \text{erf}(\frac{x - \text{fsize}}{\sqrt{2}\sigma}))
\end{equation}

Das modellierte Feature wird durch eine weitere Faltung mit mehreren um Pitch verschobenen Impulsen periodisch fortgesetzt wird, um die Grating-Struktur zu komplettieren. 

\newpage
\subsection{Effekt der Startparameter auf die Gitterstruktur}

Die drei Startparameter Sigma (\( \sigma\)), Pitch  und Feature-Size, welche die Struktur des Gratings beschreiben, haben unterschiedliche Effekte auf die Gratingstruktur. Sigma ist der Parameter, welcher, wie bereits beschrieben, den Einfluss des Hochenergielasers auf ein Feature modelliert. Je höher Sigma gewählt wird, desto mehr wird die Kantenstruktur des Targets aufgeweicht. In Abbildung \ref{img:edge_sigma} ist dieser Effekt dargestellt. 

\begin{figure}[hh]
\centering
\includegraphics[width=0.7\textwidth]{images/edge_sigma.png} 
\caption{Vergleich der Kantenstruktur unter variierenden Sigma-Werten bei gleichbleibenden Werten für Pitch und Feature-Size}
\label{img:edge_sigma}
\end{figure}

Der Parameter Pitch bestimmt die Periodizität der Kantenstruktur.  Daraus folgt, dass mit steigendem Pitch-Wert die Anzahl der Features sinkt. Dieser Effekt ist in der Abbildung \ref{img:edge_pitch_fsize} in der rechten Spalte dargestellt. Der dritte Startparamter Feature-Size bestimmt die Größe der Features. Dabei kann die Feature-Size nicht größer als Pitch gewählt werden, da sonst keine Kantenstruktur mehr erkennbar wäre. Der Effekt der Feature-Size wird in Abbildung \ref{img:edge_pitch_fsize} in der linken Spalte dargestellt.


\begin{figure}[hh]
	\centering 
	\includegraphics[scale=0.35]{images/pitch_fsize_edge.png} 
	\caption{Vergleich der Kantenstruktur unter variierenden Pitch-Werten (rechte Spalte) und variierenden Feature-Size-Werten (linke Spalte)} 
	\label{img:edge_pitch_fsize}
\end{figure} 
\FloatBarrier



\subsection{Simulation der Streuung}

Wie im Kapitel \ref{Experiment} beschrieben, skaliert das aufgenommene Detektorbild zum Betragsquadrat der  Fouriertransformation der Elektronendichte $\eta $.  Im Fall der Simulation ist die Elektronendichte eine diskrete eindimensionale Elektronendichteverteilung. Deswegen wird zur Bildung des Detektorbildes eine eindimensionale diskrekte Fouriertransformation  \eqref{eq:fft} verwendet.

\begin{equation}\label{eq:fft}
\hat { a } _ { k } = \sum _ { j = 0 } ^ { N - 1 } e ^ { - 2 \pi \mathrm { i } \cdot \frac { j k } { N } } {\eta} _{ k} \text { für } k = 0 , \ldots , N - 1
\end{equation}

Das entstandene Produkt der Fouriertransformation ist im Raum der Komplexen Zahlen und weist den gleichen Informationsgehalt wie die Elektronendichteverteilung auf. Das heißt die Amplituden- und Phaseninformationen sind nach wie vor vorhanden. Wie in Kapitel 1 beschrieben, ist der Detektor Zeit integrierend und die Phase geht verloren, weswegen die Phaseninformation im weiteren Simulationsverlauf nicht weiter verwendet wird. Um schlussendlich die aufgenommenen Intensitäten des Detektors (siehe Abbildung \ref{img:detector}) zu erhalten, wird das Betragsquadrat des Amplitudenspektrums gebildet ($ \Phi = | \hat { a } _ { k }| ^{2}$)

\begin{figure}[hh]
\centering
\includegraphics[scale=0.3]{images/endproduct.png} 
\caption{Resultierendes Detektorbild als Endprodukt der Simulation}
\label{img:detector}
\end{figure}
\FloatBarrier

\subsection{Auswirkung der Startparameter auf das Simulationsergebnis}
In diesem Kapitel werden die Auswirkungen der Startparameter auf das Detektorbild untersucht. In der Abbildung \ref{img:pitch_fsize_ratio} ist der Einfluss der Parameter Pitch und Feature-Size auf das Detektorbild dargestellt. Es ist zu erkennen, dass die Anzahl der Peaks (Intensitäten größer 0) maßgeblich durch das Verhältnis von Pitch und Feature-Size bestimmt werden. Auch die maximale Intensität wird durch das Verhältnis von Pitch und Feature-Size beeinflusst. Des Weiteren ist zu beobachten, dass mit steigendem Pitch-Wert sich die Abstände der Peaks verkleinert. Wird der Feature-Size-Wert erhöht, ist zu erkennen, dass die Anzahl der Peaks sich verringert und die maximale Intensität steigt. Der Effekt des Feature-Size-Wertes auf die maximale Intensität kann ebenfalls im Plot in Abbildung \ref{img:fsize-max} beobachtet werden. Der letzte Startparameter Sigma hat mit steigenden Wert ähnliche Auswirkungen auf die Detektorbilder wie Feature-Size. Bei steigendem Sigma-Wert steigt das Intensitätsmaximum und die Anzahl der Peaks verringert sich. Und es kommt zu einer Glättung der Randpeaks(Peaks werden kleiner oder verschwinden). Feature-Size zeigt ähnliche Effekte, jedoch skaliert der Parameter Sigma anders als Feature-Size. Kleinere Unterschiede im Sigma-Wert können große Auswirkungen auf die Anzahl der Peaks haben. Auch der Anstieg des Intensitätsmaximums in Abhängigkeit zu Sigma ist geringer im Vergleich zur Abhängigkeit zu Feature-Size. Zusätzlich ist zu bemerken, dass es einen Schwellwert gibt, bis der Effekt von Sigma Auswirkungen auf die maximale Intensität hat.  Der Effekt von Sigma auf die maximale Intensität im Detektorbild ist in Abbildung \ref{img:sigma-max} zu sehen. Auswirkungen auf das Detektorbild sind in Abbildung \ref{img:sigma_detektor} dargestellt.

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{images/sigma_endproduct.png} 
\caption{Auswirkung des Parameter Sigma auf das Detektorbild}
\label{img:sigma_detektor}
\end{figure}
\FloatBarrier

\begin{figure}[]
\centering
\includegraphics[width=0.85\textwidth]{images/sigma_maxintensity.png} 
\caption{Auswirkung des Parameters Sigma auf die maximale Intensität im Detektorbild} 
\label{img:sigma-max}
\end{figure}
\FloatBarrier

\begin{figure}[ht]
\centering
\includegraphics[width=.95\textwidth]{images/pitch_fsize_ratio.png} 
\caption{Auswirkung der Parameter Pitch und Feature-Size auf das Detektorbild. In der Tabelle wurde der Pitch-Wert zeilenweise erhöht. In jeder Spalte wurde der Feature-Size-Wert in Relation zum Pitch-Wert geändert. 1.Spalte: $\frac{1}{2} $ Pitch, 2.Spalte: $\frac{1}{4} $ Pitch, 3.Spalte: $\frac{1}{8} $ Pitch}
\label{img:pitch_fsize_ratio}
\end{figure}


 
\begin{figure}[hh]
\centering
\includegraphics[width=0.85\textwidth]{images/fsize_maxintensity.png} 
\caption{Auswirkung des Feature-Size-Wertes auf die maximale Intensität im Detektorbild.}
\label{img:fsize-max}
\end{figure}
\FloatBarrier


\subsubsection{Mathematische Erklärung der Starparametereffekte}
Wie in Kapitel \ref{Simulation} beschrieben, ergibt sich die Gitterstruktur des Gratings aus einer Faltung aus Gauss-Verteilung ($g$), Impulsverteilung ($h$) und Rechteckimpuls($f$). Diese Faltung wird dann fouriertransformiert um das Detektorbild zu erzeugen. Eine wichtige Eigenschaft der Fouriertransformation $F$ ist, dass Fourier-Faltungs-Theorem, welches besagt, das die Fouriertransformation einer Faltung äquivalent zum Produkt der Fouriertransformationen der Faltungsfunktionen ist (Gleichung \eqref{eq:fft_convolve})\cite{FOURIERDEF}. Für die Faltung der drei Faltungskomponenten $f$ , $g$, und $h$ ergibt sich :

\begin{equation}\label{eq:fft_convolve}
 F( f * g * h) = F(f) \cdot F(g)  \cdot F(h)
\end{equation}

Die Fouriertransformation einer Rechteckimpulses der Breite $2T$ wird laut \cite{Rectangle_FFT} folgend beschrieben:
\glqq Als Fourier-Transformierte ergibt sich eine oszillierende Funktion [...] Je schmaler der Rechteckimpuls - desto breiter die Frequenzverteilung [...] und umgekehrt.\grqq \ Aus dieser Eigenenschaft kann geschlussfolgert werden, dass bei steigendem Feature-Size-Wert die Frequenzverteilung $F(f)$  schmaler wird. Augrund der Muliplikation in \eqref{eq:fft_convolve} kann geschlussfolgert werden, dass durch eine Erhöhung des Feature-Size-Wertes die maximale Intensität und die Intensitäten der Peaks im Zentrum erhöht werden. Dieser Effekt ist auch in Abbildung \ref{img:pitch_fsize_ratio} festzustellen.

\begin{figure}[h]
\centering
\includegraphics[width=0.5 \textwidth]{images/fft_rectangle.png} 
\caption{Fourier-Transformation des Rechteckimpules. Bildquelle: \cite{Rectangle_FFT}}
\label{img:rectangle_fft}
\end{figure}

Die zweite Komponente der Faltung ist die Impulsverteilung $h$ oder Dirac-Kamm. \glqq Unter einem Dirac-Kamm versteht man [...]
eine Folge von äquidistanten Deltafunktionen \grqq ( \cite{SpringerFFT}, Seite 18). 

\begin{equation}
\operatorname { comb } ( t ) = \sum _ { n = - \infty } ^ { + \infty } \delta ( t - n \Delta t )\  mit \ 
\delta(t) = 1
\end{equation}

Das Ergebnis der Fouriertransformation $\mathcal { F }$ des Dirac-Kamms ist ebenfalls ein Dirac-Kamm, dessen Periodizität sich reziprok zum
ursprünglichen Dirac-Kamm verhält \cite{SpringerFFT}:

\begin{equation}
\mathcal { F } \{ \operatorname { comb } ( t ) \} = \operatorname { COMB } ( f ) = \frac { 1 } { \Delta t } \sum _ { n = - \infty } ^ { + \infty } \delta ( f - n / \Delta t )
\end{equation}

Diese Eigenschaft spiegelt sich auch bei der Erhöhung des Pitch-Wertes wieder (siehe Abbildung \ref{img:pitch_fsize_ratio}. Durch die Erhöhung des Pitch-Wertes kommt es zu einer Verringerung der maximalen Intensität und die Abstände zwischen den Peaks verringern sich. Der letzte Bestandteil der Faltung ist die Faltung mit der Gauss-Verteilung. Eine Erhöhung des Sigma-Wertes führt zu einer Steigerung der maximalen Intensität und einer Glättung der Randpeaks. Betrachtet man die Fouriertransformation einer Gauss-Verteilung \eqref{eq:fftgauss}, dann ist zu erkennen, dass die Abweichung $\sigma$ im Zähler des Exponenten steht. Daraus kann ein reziprokes Verhalten der Abweichung in der Fouriertransformation geschlussfolgert werden (siehe Abbildung \ref{img:fft_gauss}. Für das Detektorbild bedeutet dies mit Hinblick auf das Fourier-Faltungs-Theorem, dass mit steigendem Sigma-Wert die Intensitäten im Zentrum erhöht werden und Peaks am Rand geglättet werden (siehe Abbildung \ref{img:sigma_detektor}). 

\begin{equation}\label{eq:fftgauss}
F(g) = G ( \omega ) = e ^ { - \frac { \omega ^ { 2 } \sigma ^ { 2 } } { 2 } }
\end{equation}

\begin{figure}
\centering
\begin{subfigure}{}
  \includegraphics[width=.4\textwidth]{images/gauss.png}
  \label{fig:gauss}
\end{subfigure}%
\begin{subfigure}{}
  \includegraphics[width=.4\textwidth]{images/fft_gauss.png}
  \label{fig:fft_gaus}
\end{subfigure}
\caption{Vergleich der Gauss-Verteilung (links) und deren Fourier-Transformation (rechts)}
\label{img:fft_gauss}
\end{figure}


\chapter{Lösungsansatz}\label{Ansatz}
In diesem Kapitel wird der Lösungsansatz für die Parameterrekonstruktion beschrieben. Dabei wird auf die Gesamtarchitektur, der konzeptionelle Aufbau der einzelnen Komponenten und auf den Aufbau der Neural Networks und deren Training eingegangen. 

\section{Gesamtarchitektur}
Wie in Kapitel \ref{Simulation} beschrieben, ergibt sich die Gitterstruktur des Targets aus einer Faltung von Impulsfunktion, Gauss-Verteilung und Rechteckfunktion. Laut Faltungstheorem, welches besagt, dass die Faltung zweier Funktionen durch die Fouriertransformation $\mathcal { F }$ in ein Produkt überführt wird, sind die Fouriertransformationen der einzelnen Komponenten der Faltung im Fourierbild vorhanden.
Aufgrund des Faltungstheorems wurde die Parameterrekonstruktion als Zweischrittverfahren konstruiert. Die Architektur besteht aus zwei Neural Networks. Das erste Neural Network ist ein Convolutional Neural Network, welches versucht anhand des Detektorbildes den Pitch-Wert zu schätzen. Der geschätzte Pitch-Wert wird anschließend dafür genutzt die Impulsverteilung zu rekonstruieren. Dafür wird folgender funktionaler Zusammenhang verwendet: 

\begin{equation}
\delta_{pitch}(x) = \begin{cases}
1 & \text{\ für \ } x \text{\ mod \ } pitch = 0 \\
0 &  \text{\ sonst} 
\end{cases}
\end{equation}

Die generierte Impulsverteilung dient als Support für das zweite Neural Network (Fully-Connected Neural Network), um eine genauere Schätzung des Feature-Size- und Sigma-Wertes zu ermöglichen. Dabei wird der durch das CNN erstellte Support mit dem Detektorbild konkateniert. Die Konkatenation zwischen Detekorbild und Support wird als Input in das Fully-Connected Neural Network gegeben. In Abbildung \ref{img:complete_architecture} ist ein schematischer Aufbau des gesamten Architektur zu sehen. Der Output ist dabei nicht als Komponente zu betrachten, sondern nur als Verbindungsstück der Schätzungen der beiden Neural Networks. Aufgrund verschiedener Peak-Pattern bei verschiedenen Pitch-Werten wurde für die Schätzung des Pitch-Wertes ein CNN gewählt. Unterschiedlichen Feature-Size- und Sigma-Werten haben globale Auswirkung auf das Detektorbild. Deshalb wurde für die Schätzung des Feature-Size und Sigma-Wertes ein Fully-Connected Neural Network gewählt.

\begin{figure}[hh]
\centering
\includegraphics[scale=0.5]{images/complete_architecture.png} 
\caption{Schematische Beschreibung der Gesamtarchitektur}
\label{img:complete_architecture}
\end{figure}
\section{Convolutional Neural Network}
\subsection{Bayes'sche Optimierung}
Das Finden der geeigneten Hyperparameter für ein Neural Network  ist eine große Herausforderung. Der Suchraum wird durch zahlreiche Parameter wie Tiefe des Netzes, Anzahl der Filter, Größe der Filter usw. sehr groß. Ansätze wie Random- oder Gridsearch sind bekannte Ansätze für das Finden geeigneter Hyperparameter. Jedoch beziehen diese Ansätze die bisher evaluierten Hyperparameter nicht für die Wahl des als nächstes zu evaluierten Hyperparameters ein. In diesem Bezug ist eine Evaluierung das Training eines Neuronalen Netzes, welches unter festgelegten Hyperparametern erstellt wurde und dieses nach einem festgelegten Qualitätsmaß bewertet wurde. Im Gegensatz zu den eben erwähnten Optimierungsverfahren verfolgt die Bayes'sche Optimierung den Ansatz bereits evaluierte Hyperparametersätze in die Optimierung mit einzubeziehen. Die Grundidee der Bayes'schen Optimierung ist das Erstellen einer Wahrscheinlichkeitverteilung $p(L | \theta)$ mit $L$ der Qualität eines Neural Networks, da s in Abhängigkeit eines Hyperparamtersatzes $\theta$ erstellt wurde. Zu Beginn der Bayes'schen Optimierung werden bereits bekannte Evaluierungspunkte verwendet oder ein festgelegter Hyperparametersatz evaluiert, um ein erstes Wahscheinlichkeitsmodell mit Hilfe der Maximum Likelihood-Methode \cite{Likelihood} zu erstellen. Das erstellte Wahrscheinlichkeitsmodell wird dann benutzt, um den nächsten Evaluierungspunkt aus dem definierten Suchraum zu bestimmen. Nach dessen Evaluierung wird erneut das Wahrscheinlichkeitsmodell angepasst und ein neuer Evaluierungspunkt gefunden. Dieser Prozess wird solange durchgeführt, bis eine bestimmt Anzahl von Iterationen erreicht wurde. Die genauere Beschreibung des Algorithmus kann \cite{BayesOptimization} entnommen. Um eine Bayes'sche Optimierung für das CNNs vorzunehmen, wurde die Implementierung von Scikit-learn verwendet. Dabei wurden die Hyperparameter: Anzahl der Convolutional Layer, Anzahl der Filter pro Convolutional Layer, Filtergröße und die Learning-Rate des Optimizers über die Bayes'scher Optimierung gefunden. Die Bayes'sche Optmierung wurde durch den  Suchraum aus Tabelle \ref{tab:bayes} eingeschränkt. Die Einschränkungen wurden aus Erfahrungswerten vorheriger Experimente getroffen. Ein Evaluierungschritt ist die Erstellung des CNN anhand des festgelegten Hyperparametersatzes, das Trainieren des CNNs mit 1024 Bildern über 3000 Epochen und die Bestimmung der Qualität. Als Qualitätsmaß wurde der beste erreichte Mean-Squared-Error auf dem Validierungsdatensatz verwendet. Insgesamt wurden 50 Evaluierungsschritte ausgeführt. Zusätzlich wurden Residual Strukturen mit einer Sprungweite von 2 dem erstellten CNN hinzugefügt. 

\begin{table}[]
\centering 
\begin{tabular}{|l|l|l|}
\hline
Variable   & Minimum & Maximum  \\ \hline
Learning-Rate               & 1e-15   & 1e-5    \\
Anzahl Convolutional Layer  & 3       & 12      \\
Filtergröße                 & 4       & 20      \\
Anzahl der Filter pro Layer & 16      & 64    \\ \hline
\end{tabular}
\caption{\label{tab:bayes} Definition des Suchraums für die Bayes'sche Optimierung}
\end{table}

\subsection{Architektur}

Das Ergebnis der Bayes'schen Optimierung ist ein CNN mit einem Block von Convolutional Layers. Die Größe des Blockes, die Anzahl der Filter und die Größe der Filter pro Convolutional Layer wurden durch die Bayes'sche Optmierung bestimmt. Nach dem Block von Convolutional Layers wurde zusätzlich ein Convolutional-Layer mit einem Filter und der Filtergröße 1 hinzugefügt. Dieser Layer hat eine Dimensionreduktion zu folge, um beim anschließenden Dense-Layer( Fully-Connected Layer) nicht zu viele Verbindungen zu erzeugen. Zwischen dem Regressions-Layer und dem ersten Dense-Layer befindet sich ein weiterer Hidden-Layer, der eine weitere Dimensionreduktion erzeugt. Als letzte Layer wurde eine weitere Dense-Layer mit linearer Aktivierungsfunktion hinzugefügt. Die Entscheidung für eine lineare Aktivierungsfunktion wurde aus den Erfahrungen vorheriger Experimente getroffen. Wurde die Ausgabe-Layer mit einer ReLu-Aktivierungsfunktion versehen, starb das Output-Neuron während des Trainings frühzeitig und es wurden ausschließlich Pitch-Werte mit dem Wert 0 geschätzt. In Tabelle \ref{tab:cnn} ist die komplette Architektur des CNNs dargestellt. 

\begin{table}[hht]

\begin{tabular}{|l|l|c|c|c|l|}
\hline
Layer           & Input            & \multicolumn{1}{l|}{Anzahl Filter} & \multicolumn{1}{l|}{Filtergröße} & \multicolumn{1}{l|}{Anzahl der Neuronen} & Aktivierungssf. \\ \hline
1DConv          & Detektorbild     & 32                                 & 16                               & -                                        & ReLU                 \\
1DConv          & Layer 1          & 32                                 & 16                               & -                                        & ReLU                 \\
1DConv          & Layer 2 + Layer1 & 32                                 & 16                               & -                                        & ReLU                 \\
1DConv          & Layer3           & 32                                 & 16                               & -                                        & ReLU                 \\
1DConv          & Layer4 + Layer3  & 32                                 & 16                               & -                                        & ReLU                 \\
1DConv          & Layer5           & 32                                 & 16                               & -                                        & ReLU                 \\
1DConv          & Layer6 + Layer5  & 32                                 & 16                               & -                                        & ReLU                 \\
1DConv          & Layer7           & 32                                 & 16                               & -                                        & ReLU                 \\
1DConv          & Layer8 + Layer7  & 32                                 & 16                               & -                                        & ReLU                 \\
1DConv          & Layer9           & 32                                 & 16                               & -                                        & ReLU                 \\
1DConv          & Layer10          & 1                                  & 1                                & -                                        & ReLU                 \\
Dense           & Layer11          & -                                  & -                                & 64                                       & ReLU                 \\
Regression-Layer & Layer12          & -                                  & -                                & 1                                        & Linear            \\ \hline  
\end{tabular}
\caption{\label{tab:cnn} Architektur des Convolutional Neural Networks}
\end{table}

\section{Fully-Connected Neural Network}
Das Fully-Connected Neural Network besteht ausschließlich aus Dense-Layern. Die Aufgabe des Fully-Connected Neural Networks ist die Schätzung des Sigma- und Feature-Size-Wertes. Der erste Layer bekommt die Konkatenation des Detektorbildes und der Impulsverteilung, welche aus dem vom CNN geschätzten Pitch-Wert erstellt wurde, als Input. Die Architektur des  Fully-Connected Neural Networks wurde aus Zeitgründen nicht mit der Bayes'schen Optimierung optimiert, sondern aus Erkenntnissen mehrerer Experimenten gebildet. In Tabelle \ref{tab:fcnn} ist die Architektur des Fully-Connected Neural Networks dargestellt.

\begin{table}[hh]
\centering
\begin{tabular}{|l|c|c|c|}
\hline
Layer            & Input                            & Anzahl Neuronen & Aktivierungsfunktion \\ \hline
Dense-Layer      & (Detektorbild, Impulsverteilung) & 4096            & ReLu                 \\
Dense-Layer      & Layer1                           & 2048            & ReLu                 \\
Dense-Layer      & Layer2                           & 2048            & Relu                 \\
Dense-Layer      & Layer3                           & 64              & ReLu                 \\
Regression-Layer & Layer4                           & 2               & Linear              \\ \hline
\end{tabular}
\caption{\label{tab:fcnn} Architektur des Fully-Connected Neural Networks}
\end{table}
\section{Training} \label{Training}

Das Training der beiden beschriebenen Neural Networks erfolgt getrennt. Als erstes wird der Schätzer des Pitch-Wertes trainiert(CNN), da dieser die Grundlage für das Training des Fully-Connected Neural Networks bildet. Anschließend wird der Schätzer für den Sigma- und Feature-Size-Wert trainiert. Für die Generierung der Impulsverteilung, welche für das Training des Fully-Connected Neural Networks benötigt wird, wird ein festes CNN verwendet. Das heißt, dass sich die Architektur bzw. die Gewichte des CNN's während des Trainings des Fully-Connected Neural Networks nicht verändern.

Für das Training beider Neural Networks wurde der Adam-Optimizer verwendet. Der Adam-Optimizer ist eine Erweiterung des klassischen Gradientenabstiegsverfahren. Der Adam-Optimizer verknüpft die Vorteile zwei weiterer bekannter Optimierungsverfahren: Adaptive Gradient Algorithm (AdaGrad) und Root Mean Square Propagation (RMSProp) \cite{AdamOptimizer}. Der Adaptive Gradient Algorithmus hat den Vorteil, dass er für jeden Parameter eine unterschiedliche Learning-Rate festlegt, dadurch ist es möglich kleinen Gradienten entgegenzuwirken \cite{Optimizer}\cite{AdamOptimizer}. Die Root Mean Square Propagation stellt ebenfalls für jede Variable unterschiedliche Learning-Rates bereit, jedoch werden diese Learning-Rates hinsichtlich des Trainingsverlaufs angepasst. Zum Beispiel können zu schnell propagierende Variablen durch eine geringere Learning-Rate ausgebremst werden \cite{Optimizer}\cite{AdamOptimizer}. 

Für jedes Neural Network steht wie in Kapitel \ref{Database} eine eigene Datenbasis zu Verfügung, welche mit Hilfe von Batch-Processing trainiert wurde. Beim Batch-Processing werden dem Neural Network mehrere Inputdaten gleichzeitig zur Verfügung gestellt und durch das Netz propagiert \cite{Kriesel2007NeuralNetworks}.

 Um die Qualität der Gesamtarchitektur zu überprüfen, wurde der Pitch- und Feature-Size-Schätzer auf zwei verschiedene Weisen trainiert. Der erste Trainingsansatz ist das Training des Netzwerk mit Hilfe der Impulsverteilungen, welche durch die Pitch-Werte des CNN's generiert wurden. Im zweiten Trainingsansatz werden die Impulsverteilungen durch das Pitch-Label generiert. Für beide Neural Networks wurde MSE \eqref{eq:mse} als Errorfunktion verwendet.
 
 Der gesamte Trainingsprozess, wurde mit Tensorflow realisiert und mit Hilfe des Tracking-Tools Tensorboard überwacht und alle 50 Epochen mit Hilfe des Validierung-Datensatzes evaluiert. 

\chapter{Datenbasis}
\section{Generator}
Um einen Machine-Learning-Ansatz auszuführen, muss eine ausreichend große Datenbasis existieren. Dazu wurde im Rahmen dieser Arbeit ein  Generator entwickelt, welcher mit Hilfe der vorher beschriebenen Simulation ausreichend viele Trainings-, Validierungs- und Testsdaten(Evaluierung) produzieren kann. Der erste Schritt der Genierierung der Datenbasis ist die Festlegung der Menge $P$ von Startparametern, wobei ein Startparamter ein Tripel (Feature-Size, Pitch, Sigma) ist. Um die Berechung der Simulationsdaten, welche aus P resultieren, zu beschleunigen wurde die Simulation aus Kapitel \ref{Simulation} mit Hilfe des Message Parsing Interfaces (MPI) parallisiert. MPI dupliziert auszuführenden Code auf N beliebige Prozesse, welche mit Hilfe von vordefinierten Routinen miteinander kommunizieren können \cite{MPI}. Wurde die Menge von Startparametern festgelegt, wird diese Menge über MPI-Routinen auf $N$ Prozesse aufgeteilt. Jeder Prozess führt für seine zugewiesene Menge von Startparametern die in Kapitel \ref{Simulation} beschriebene Simulation aus und schreibt deren Ausgabe als Dateien in den Speicher des Rechenclusters. Zusätzlich zum Simulationsergebnis wird die Menge der Startparameter, welche als Labels für das Training des Neural Networks vorgesehen sind, gespeichert. 
\begin{figure}[hh]
\centering
\includegraphics[scale=0.4]{images/generator_schema.png} 
\caption{Schematischer Aufbau des Generators}

\label{img:generator}
\end{figure}

\section{Wahl der Eingangsparameter}
 Um einen validen Datensatz zu erstellen, müssen diese Abhängigkeiten berücksichtigt werden.  Der erste Startparameter Pitch ist der  Parameter, welcher den Definitionsbereich der anderen beiden Parametern Feature-Size und Sigma signifikant bestimmt. Wie in Kapitel \ref{Simulation} bemerkt, bestimmt Pitch die Periodizität der Gitterstruktur. Um aussagekräftige Detektorausgaben zu produzieren, wurde festgelegt, dass jedes Target mindestens vier und maximal 32 Features besitzt. Das bedeutet im Umkehrschluss, dass bei einer festen Targetbreite von 2048 Pixeln sich ein minimaler Pitch-Wert bei 64 und der maximaler Pitch-Wert bei 512 Pixeln ergibt. Je nach Wahl des Pitch-Wertes, ergeben sich die Definitionsbereiche für Sigma und Feature-Size. Um zu kleine Features zu vermeiden, wurde der minimale Feature-Size-Wert auf 25 \% des Pitch-Wertes festgelegt. Für ausreichend große Abstände zwischen den Features, wurde der maximale Feature-Size-Wert auf 75 \% des Pitch-Wertes beschränkt. Nach der Bestimmung von Pitch und Feature Size kann der Definitionsbereich von Sigma festgesetzt werden. Der minimale Sigma-Wert ist auf $ 10^{-9} $ festgelegt, um auch Simulationsergebnisse ohne Hochintensitätslasereinfluss zu generieren. Zur Bestimmung des maximalen Sigma-Wertes ist der Abstand zwischen zwei Features notwendig. Der Abstand zwischen zwei Features ergibt sich aus Pitch - Feature-Size. Da der Aufweichungseffekt gleichmäßig auf das Feature wirkt, muss für den maximalen Sigma-Wert der Feature-Abstand halbiert werden. Um keine zu hohen Aufweichungseffekte zu erhalten, wurde die obere Grenze des Sigma-Wertes auf (Pitch - Fsize) / 4 festgesetzt. Für die Umsetzung der voneinander abhängigen Wertebereichen, werden Folgen konstruiert, dessen Elemente zu Startparameter Tripeln konkateniert werden. Eine Beispielhafte Implementierung ist in der Abbildung \ref{code:P} zu sehen, welche jeweils eine Folge mit 64 Elementen (Anzahl der Prozessoren) erstellt.

\begin{figure}[htbp]\label{code:P}
\centering 
\begin{lstlisting}[frame=trbl][language=Python]
num_pitches = 64
num_fsizes = 64
num_sigmas = 64
for pitch in np.linspace(64, 512, num=num_pitches):
    for feature_size in np.linspace(0.25*pitch, 0.75*pitch, num=num_fsizes):
        for sigma in np.linspace(1e-9, (pitch-feature_size)/4, num=num_sigmas):
            add_to_P(sigma, pitch, feature_size, number))
\end{lstlisting}
\caption{Umsetzung der Definitionsbereiche mit Hilfe drei verschachtelter Schleifen, welche voneinander Abhängig sind}
\end{figure}


\section{Performance}
Die Erstellung der Datenbasis wurde auf dem Rechencluster Hypnos des Helmholtz Zentrums Dresden Rossendorf auf 64 AMD 16-Kern Opteron Prozessoren ausgeführt. Die Parallelisierung der Simulation hat einen großen Speedup zur Folge, so dass 100.000 Bilder in knapp zwei Stunden anstatt in ca. 50 h Stunden(* lineare Regression aus Rechenzeiten kleinerer Datensätze) generiert werden können. Diese kurze Rechendauer ermöglicht ein schnelleres Validieren und Korrigieren des erstellten Datensatzes. Die Rechenzeiten für kleinere Datensätze sind der Tabelle \ref{tab:generator} zu sehen. Bei kleineren Datensätzen ist der Speedup nicht signifikant, da durch die Parallelisierung ein Kommunikationsoverhead entsteht.
\begin{table}[hh]
\centering
\begin{tabular}{|l|l|l|l|l|}
\hline
            & 1 Bild    & 100 Bilder  & 1000 Bilder  & 100.000 Bilder   \\ \hline
sequentiell & 1,889 s & 187,613 s & 1870,095 s & 186940,286 s * \\
Generator   & 1,917 s & 4,531 s   & 42,831 s   & 6900,243 s   \\ \hline
\end{tabular}
\caption{\label{tab:generator} Vergleich der Berechnungsdauer für verschieden große Datensätze}
\end{table}

\section{Trainings-, Validierungs- und Testdatensatz}\label{Database}
Für das Training von Pitch, Feature-Size und Sigma stehen zwei verschiedene Datensätze zur Verfügung. Der erste Datensatz wurde für das Training des Neural Networks erstellt, welches Pitch schätzen soll.  Dieser Datensatz hat die Besonderheit, dass die Folge vom minimalen Pitch-Wert bis zum maximalen Pitch-Wert deutlich höher abgetastet ist, um dem Neural Network eine möglichst aussagekräftige Verteilung von Pitch-Werten und deren Auswirkung auf das Detektorbild zu geben. Die Feature-Size- und Sigma-Folgen wurden deutlich geringer abgetastet, jedoch steht aufgrund der verschachtelten Schleifen zur Generierung der Startparameter (Abbildung \ref{code:P}) eine ausreichend große Verteilung von Sigma und Feature-Size-Werten für das Training von Pitch zur Verfügung (Tabelle \ref{tab:label-distribution}). 

\begin{table}[ht]
\centering
\begin{tabular}{|l|c|c|c|}
\hline
Dataset                & Anzahl Pitch & Anzahl Feature-Size & Anzahl Sigma \\ \hline
CNN                  & 368          & 23                  & 23           \\
Fully-Connected & 46           & 46                  & 46  \\ \hline
\end{tabular}
\caption{\label{tab:label-distribution} Abtastwerte für die jeweiligen Startparameter. Diese Werte werden wie in Abbildung \ref{code:P} verarbeitet}
\end{table}

Der Datensatz für das Training des Neural Networks weißt eine andere Verteilung wie der Pitch-Datensatz auf. In diesem Datensatz wurden die Folgen für Pitch, Sigma und Feature-Size gleich abgetastet, jedoch ist die Verteilung der Sigma- und Feature-Size-Werte aufgrund der Implementierung der Parametergenerierung deutlich ausgeprägter. In der Tabelle \ref{tab:label-distribution} sind die Abtastwerte der jeweiligen Folgen zu sehen. Für das Training, die Validierung des Trainingsprozesses und die Evaluierung des Neural Networks wurde der jeweilige Datensatz zufällig umsortiert und in Trainings, Validierung- und Test- Datensatz aufgespaltet. Um die Länge nicht zu groß zu gestalten, wurde der Trainingsdatensatz bei beiden Datensätzen auf 16384 Detektorbilder beschränkt. Für die Validierung stehen jedem Neural Network 64 Bilder zur Verfügung. Die restlichen Bilder wurde komplett für eine aussagekräftige Evaluierung verwendet. In Tabelle \ref{tab:traintestval} ist die Verteilung der Samples auf Trainings-, Validierungs- und Testdatensatz zu sehen. Aufgrund der höheren Abtastung von Pitch imd Pitch-Datensatz (siehe Tabelle \ref{tab:label-distribution}) besitzt dieser mehr Detektorbilder und somit mehr Samples zur Evaluierung. 

\begin{table}[hh]
\centering 
\begin{tabular}{|l|c|c|c|}
\hline
Datensatz              & \multicolumn{1}{l|}{Training} & \multicolumn{1}{l|}{Validierung} & \multicolumn{1}{l|}{Test} \\\hline
Pitch                  & 16384                         & 64                              & 178224                    \\
Feature-Size und Sigma & 16384                         & 64                              & 80888      \\ \hline              
\end{tabular}
\caption{\label{tab:traintestval} Verteilung der Samples auf Trainings, Validierungs- und Testdatensatz}
\end{table}

\chapter{Ergebnisse und Diskussion}
\section{Trainingsprozess}
\subsection{Convolutional Neural Network}
Der Trainingsverlauf des CNNs wurde mit Hilfe der Tensorboard-Bibliothek überwacht. Parallel zum Trainingsprozess 		wurde, in einem Abstand von 50 Epochen, der Trainingsprozess mit Hilfe des Validierungsdatensatzes evaluiert. Um die Qualität des CNNs zu bestimmen, wurde Mean Squared Error als Qualitätsmaß eingesetzt (Gleichung \eqref{eq:mse}). Das CNN wurde über 3000 Epochen trainiert. Der Verlauf des Trainings- und Validierungsfehlers während des Trainingsprozesses ist in Abbildung \ref{img:train_cnn} dargestellt.

	
	\begin{figure}[hh]
	\centering
	\includegraphics[width=.75\textwidth]{images/learn_curve_cnn.png} 
	\caption{Verlauf des Trainings- und Validierungsfehlers des CNNs in Anhängigkeit der Epoche}
	\label{img:train_cnn}
	\end{figure}

In Abbildung \ref{img:train_cnn} ist bis zur tausendsten Epoche ein starker Abfall des Fehlers zu erkennen. Ab der tausendsten Epoche ist ein schwächeres Konvergenzverhalten zu beobachten. Der Verlauf des Trainings- und des Validierungsfehlers ist sehr ähnlich. Somit können nicht trainierte Samples mit nahezu gleicher Qualität wie trainierte Samples geschätzt werden. Dies spiegelt sich auch im ähnlichen minimalen Trainings- und Validierungsfehler wieder. Während des Trainings konnte ein minimaler Trainingsfehler von 20910.45 und ein minimaler Validierungsfehler 23247.19 von erreicht werden.
\subsection{Fully-Connected Neural Network}
In Kapitel \ref{Ansatz} wurde beschrieben, dass das Fully-Connected Neural Network auf zwei verschiedene Weisen trainiert wurde. Im ersten Experiment wurde das Fully-Connected Neural Network mit der Impulsverteilung ,welche aus dem Pitch-Wert des CNNs generiert wurde, trainiert. Im zweiten Experiment wurde die Impulsverteilung aus dem Pitch-Label generiert. In beiden Experimenten wurde das Network 500 Epochen trainiert. Die kleinere Epochenanzahl resultiert aus dem schnelleren Konvergenzverhalten des Fully-Connected Neural Networks. Bei einer Epochenzahl von 1000  konnten keine besseren Ergebnisse erzielt werden. Für das Fully-Connected Neural Network wurde ebenfalls Mean Squared Error als Qualitätsmaß verwendet. In Abbildung \ref{img:train_fc1} ist die Lernkurve des ersten Experimentes dargestellt. Während des Trainings konnte ein minimaler Trainingfehler von 75.80 und ein minimaler Validierungssfehler von 163.74 erreicht werden. Der Verlauf des Training- und des Validierungsfehlers zeigt ähnliches Konvergenzverhalten, das für Generalisierung spricht. Dennoch gibt es im minimal erreichten Trainings und Validierungsfehlers einen Unterschied von einem Faktor zwei. Somit ist die Qualität des Fully-Connected Neural Networks auf den Trainingsdaten deutlich höher als die der Validierungsdaten. 

	\begin{figure}[hh]
	\centering
	\includegraphics[width=.75\textwidth]{images/learn_curve_fc1.png} 
	\caption{Verlauf des Trainings- und Validierungsfehlers in Anhängigkeit der Epoche im ersten Experiment}
	\label{img:train_fc1}
	\end{figure}

Das zweite Experiment (Abbildung \ref{img:train_fc2}) zeigt ähnliches Konvergenzverhalten wie beim ersten Experiment. Jedoch kommt es bei einer höheren Epochenzahl zu weniger oszillation des Fehlers. Der minimale Trainingsfehler liegt bei 100.98 und der minimale Validierungsfehler liegt bei 190.72. Somit konnte eine ähnliche Qualität auf den Trainings- und Validierungsdaten erreicht werden wie beim ersten Experiment. 
	\begin{figure}[hh]
	\centering
	\includegraphics[width=.75\textwidth]{images/learn_curve_fc2.png} 
	\caption{Verlauf des Trainings- und Validierungsfehlers in Anhängigkeit der Epoche im zweiten Experiment}
	\label{img:train_fc2}
	\end{figure}
	\FloatBarrier
	\section{Evaluierung}
	
	\subsection{Convolutional Neural Network}
Um die Qualität des CNNs zu evaluieren, wurden die nicht trainierten Samples des Testdatensatzes zur Qualitätsbestimmung genutzt. Es konnte eine durchschnittliche absolute Abweichung von 109.73 und eine durchschnittliche relative Abweichung von 37\% erreicht werden. Aus der durchschnittlichen relativen und absoluten Abweichung kann eine schlechte Qualität des CNNs geschlussfolgert werden.
	
 Eine wichtige Beobachtung der Analyse des CNNs ist, dass mit steigendem Pitch-Label die Qualität der Pitch-Schätzung sich verringert (siehe Abbildung \ref{img:experiment1}). Im Kapitel \ref{Simulation} wurde bereits analysiert, dass mit steigendem Pitch-Wert die Abstände der Peaks kleiner werden und somit ein dichteres Detektorbild entsteht.  Daraus kann geschlussfolgert werden, dass bei höherer Peakdichte Pitch schlechter geschätzt werden kann. Zusätzlich ist in Abbildung \ref{img:experiment1} zu erkennen, dass bei höheren Feature-Size-Werten Pitch besser geschätzt werden kann.  

	\begin{figure}[hh!]
	\centering
	\includegraphics[width=0.85\textwidth]{images/experiment1.png} 
	\caption{Qualität der Pitch-Schätzung in Abhängigkeit des Startparameters Feature-Size}
	\label{img:experiment1}
	\end{figure} 
 
Eine wichtige Eigenschaft von CNNs bzw der Convolutional-Layer ist, dass sie Lokalität der Input-Daten nicht berücksichtigen, somit können globale Änderungen, wie zum Beispiel eine Verdichtung des Detekorbildes durch ein CNN schwerer erfasst werden. Dies spiegelt sich auch in den Detektorbildern in Abbildung \ref{img:bad_experiment1} wieder, welche alle im Zentrum des Bildes sehr dicht besetzt sind. Bilder mit niedrigerem Pitch-Wert können besser geschätzt werden,wie die Detektorbilder in Abbildung \ref{img:good_experiment1}. Sie weisen eine geringere Peak-Dichte auf, womit das CNN scheinbar besser umgehen kann. 

	\begin{figure}[hh]
	\centering
	\includegraphics[width=0.78\textwidth]{images/experiment1_bad_predictions.png} 
	\caption{Detektorbilder zu schlechten Pitch-Schätzungen. Alle drei Detektorbilder weisen mit einer Absolute Abweichung über 100 eine überdurchschnittliche schlechte Qualität auf. }
	\label{img:bad_experiment1}
	\end{figure}
	
	\begin{figure}[hh]
	\centering
	\includegraphics[width=0.75\textwidth]{images/experiment1_good_predictions.png} 
	\caption{Detektorbilder zu guten Pitch-Schätzungen}
	\label{img:good_experiment1}
	\end{figure}
Ein höheres Sampling der Fouriertransformation könnte die Qualität der Pitchschätzung steigern. In der Simulation wurde das 2048 Pixel große Grating mit einer Fouriertransformation mit 2048 Stützstellen (Sampling) implementiert, dies hat zur Folge, dass Peaks im Detektorbild nur durch einen Wert dargestellt werden und Zwischenwerte komplett verloren gehen. In Abbildung \ref{img:oversampling} ist ein Vergleich der Simulation mit höherer Sampling-Rate(links) und einem Sampling von 1:1. Die Abbildung zeigt außerdem, dass zwischen den höheren Peaks im Zentrum noch kleinere Peaks sind, welche durch die niedrigere Sampling-Rate nicht gemessen werden können. Diese Peaks können laut Fraunhofer-Diffraction dazu genutzt werden die Anzahl der Features und im Umkehrschluss Pitch zu bestimmen \cite{Multiple_Slits}. Denn die Anzahl der Minima zwischen dem Intensitäsmaximum und dem nächsten höheren Peak entspricht der Anzahl der Features plus eins \cite{Multiple_Slits}. Somit können nur Parameter des Detektorbildes wie Intensitäten, Peakabstände und Anzahl der Peaks benutzt werden, um Pitch zu schätzen. .
	\begin{figure}[]
	\centering
	\includegraphics[width=0.75\textwidth]{images/oversampling.png} 
	\caption{Unterschied des Detektorbildes bei einem höheren Sampling(links) und einem Sampling von 1:1 (rechts). Die gelben Punkte signalisieren die jeweiligen Sampling-Punkte}
	\label{img:oversampling}
	\end{figure}	
	\FloatBarrier

	\subsection{Fully-Connected Neural Network}
Für das Fully-Connected Neural Network wurde ebenfalls der Testdatensatz zur Evaluierung genutzt. Wie bereits im Trainings-Kapitel (Kapitel \ref{Training})	beschrieben, wurde das Fully-Connected Neural Network auf zwei verschiedene Weisen trainiert. Wie in Kapitel \ref{Ansatz} beschrieben, wurde mit Hilfe des geschätzten Pitch-Wertes des CNNs eine Intensitätsverteilung bestimmt, welche die Schätzung des Feature-Size- und Pitch-Wertes verbessern soll.  Um diesen Ansatz zu evaluieren, wurde das gleiche Fully-Connected Neural Network mit Impulsverteilungen, welche vom Pitch-Label generiert wurden, trainiert. Der Parameter Feature-Size konnte mit beiden Netzen mit einer durchschnittlichen absoluten Abweichung von 13.043 (CNN) und 13,743(Label) geschätzt werden. Die prozentualen Abweichung liegen 12,46 Prozent (CNN) und 13,713 (Label). 

\begin{table}[]
\centering 
\begin{tabular}{|l|l|l|}
\hline
                        & Feature-Size & Sigma   \\ \hline
Fully-Connected (CNN)   & 13,043       & 13,174 \\ 
Fully-Connected (Label) & 13,713       & 12,641 \\ \hline
\end{tabular}
\caption{\label{tab:relative_results} Absolute Abweichung  bei der Schätzung von Sigma und Feature-Size auf den Testdaten}
\end{table}

\begin{table}[]
\centering 
\begin{tabular}{|l|l|l|}
\hline
                         & Feature-Size & Sigma \textgreater 1 \\ \hline
Fully-Connected (CNN)    & 12,46 \%     & 184,43 \%            \\
Fully-Connected (Label) & 13,50 \%     & 176,75 \%       \\ \hline    
\end{tabular}
\caption{\label{tab:relative_results} Prozentuale Abweichung von Sigma und Feature-Size auf den Testdaten}
\end{table}


Aus diesen Zahlen kann geschlussfolgert werden, dass Feature-Size mit einer relativ guten Qualität geschätzt werden kann. Des Weiteren kann geschlussfolgert werden, dass der Parameter Pitch und die generierte Impulsverteilung keinen Einfluss auf die Schätzung des Feature-Size-Wertes hat. Dies spiegelt sich auch in der Abbildung \ref{img:experiment_fsize} wieder. In dieser Abbildung ist zu erkennen, dass die Qualität der Feature-Size-Schätzung bei unterschiedlichen Pitch-Werten sehr ähnlich ist. Des Weiteren ist zu erkennen, dass mit steigendem Feature-Size-Wert bis zu einem bestimmten Schwellwert die Qualität gleichbleibend ist. Ab diesem Schwellwert kommt es zu einem starken Qualitätsabfall. Dies kann damit begründet werden, dass der Feature-Size-Wert so hoch ist, dass Randpeaks verschwunden ist und somit nur noch ein Peak für die Schätzung des Feature-Size-Wertes zur Verfügung steht. 


\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{images/experiment3_1.png} 
\caption{Absolute Abweichung der Feature-Size-Schätzung des Fully-Connected Neural Network (CNN) in Abhängigkeit von Pitch}
\label{img:experiment_fsize}
\end{figure}
\FloatBarrier
	
Der Startparameter Sigma kann vom Fully-Connected Neural Network deutlich schlechter geschätzt werden als Feature-Size. Es konnte eine durchschnittliche absolute Abweichung 13,174 (CNN) und 12,641 erreicht werden. Da der Wertebereich von Sigma deutlich kleinere ist, zeigt sich der Qualitätsunterschied zur Feature-Size-Schätzung in der prozentualen Abweichung. Es konnte eine prozentuale Abweichung von 184,43 Prozent (CNN) und 176,75 Prozent für Sigma größer 1 erreicht werden. Wobei der Median der Median der prozentualen Abweichung bei 55,09 Prozent (CNN) und 54,165(Label) liegt. Aus den Abweichungszahlen kann geschlussfolgert werden, dass eine bessere Pitch-Schätzung zu einer leicht besseren Sigma-Schätzung beiträgt. In Abbildung \ref{img:experiment_sigma} ist die absolute Abweichung in Abhängigkeit von Sigma und Feature-Size dargestellt. In dieser Abbildung ist zu erkennen, dass die Abweichung nahezu linear mit höheren Sigma-Wert steigt. Außerdem ist zu erkennen, dass der Sigma-Wert besser geschätzt werden kann, wenn der Feature-Size-Wert höher ist. Dieser Zusammenhang kann damit begründet werden, dass bei größeren Features Sigma größer sein muss, um einen Informationsverlust zu erzeugen. Zusätzlich besitzt der erstellte Datensatz sehr wenig Bilder mit hohen Sigma-Werten. Nur 2,3 Prozent der Bilder im Datensatz wurden mit einem Sigma-Wert größer 60 erstellt. Ein weiterer erschwerender Punkt ist, dass Sigma und Feature-Size gleiche Effekte auf das Detektorbild haben. Beide erhöhen das Intensitätsmaximums und verringern die Anzahl der Peaks im Detektorbild. Jedoch erkennt das Network eher den Effekt der Feature-Size auf das Detekorbild und erreicht eine bessere Qualität als für Sigma.

\begin{figure}[]
\centering
\includegraphics[width=0.9\textwidth]{images/experiment6_1.png} 
\caption{Absolute Abweichung der Sigma-Schätzung des Fully-Connected Neural Network (CNN) in Abhängigkeit von Feature-Size}
\label{img:experiment_sigma}
\end{figure}
\FloatBarrier

\section{Fazit}
In dieser Arbeit wurde ein Prototyp entwickelt, der die Modellparameter der Gitterstruktur anhand der zugehörigen Detektorbild schätzen soll. Es wurde eine umfangreiche Datenanalyse vorgenommen, um die Effekte der Startparameter auf das Detektorbild und auf die Network-Schätzungen zu verstehen. Aus den Ergebnissen kann bisher die Schlussfolgerung gezogen werden, dass die in diesem Beleg benutze Technik keine gute Qualität liefert, aber die Resultate für die weitere Arbeit an diesem Problem wertvoll sind. Nur der Startparameter Feature-Size konnte mit einer besseren Qualität geschätzt werden. Die Parameter Sigma und Pitch können nur mit einer unzureichenden Qualität geschätzt werden. Eine große Schwierigkeit sind die Effekte der Parameter auf das Detektorbild. Parameter wie Feature-Size und Sigma zeigen die gleichen Effekte auf das Detektorbild, nur unterschiedlich skaliert. Und auch der Parameter Pitch legt im Zusammenspiel mit dem Parameter Feature-Size die Grundstruktur des Detektorbildes fest. In dieser Arbeit konnten mehrere Schwachstellen der gewählten Architektur festgemacht werden. Der Pitch-Schätzer(CNN) kann nur mit lokalen Pattern umgehen und zeigt schwächen, wenn es globale Änderungen im Detektorbild gibt. Des Weiteren konnte festgestellt werden, dass der Parameter Feature-Size unabhängig des Parameters Pitch geschätzt werden kann. Auch die Generierung der Datenquelle hat Schwächen, welche während der Evaluierung deutlich geworden sind. Zum Beispiel existieren im Datensatz nur zwei Prozent der Detektorbildern einen höheren Sigma-Wert. Die Erkenntnisse dieser Arbeit können genutzt werden die Architektur zu verbessern und die Qualität der Schätzungen zu erhöhen. 
\newpage
\section{Ausblick}
Der in dieser entwickelte Prototyp hat in vielen Punkten Verbesserungspotential. Aus den Erkenntnissen dieser Arbeit sind bereits neue Ideen entstanden, wie man die Qualität des Prototyps noch steigern kann. Dabei ist ein möglicher Ansatz, dass die beiden Netze der Deep-Learning- Architektur gemeinsam trainiert werden und die Qualität für die Feature-Size und Sigma-Schätzung in das Training des Pitch-Schätzers einfließt. Bisher wurden beide Netzwerke getrennt trainiert und der Feature-Size und Sigma-Schätzer hat Impulsverteilungen eines festen Pitch-Schätzers bekommen. Ein weiterer Verbesserungsvorschlag ist die Modifizierung des Pitch-Schätzers. Die Auswirkung des Parameters Pitch auf das Detektorbild hat nicht nur lokale Auswirkungen, sondern auch globale Auswirkungen. Für den Pitch-Schätzer sollte deswegen eine Architektur gefunden werden, welche die globalen Änderungen des Detektorbildes besser erfassen kann bzw. mit deren Lokalität umgehen kann. Bisher wurde das Deep-Learning-Model mit einer eher geringen Datenmenge trainiert. Es sollte definitiv evaluiert werden, ob eine größere Datenmenge Einfluss auf die Qualität der Schätzer hat. Auch die Verteilung der Labels sollte überdacht werden. Ein letzter Verbesserungsvorschlag ist die Qualität der Simulation. Die gegebene Simulation nutzt eine niedrig aufgelöste Fourier-Transformation, welche wichtige Informationen verliert. Es sollte überprüft werden, ob ein Training des Deep-Learning-Models mit Detekorbildern mit höherer Auflösung eine höhere Qualität bei der Schätzung der Startparameter zur Folge hat. Zum Beispiel könnte ein weiteres Neural Network dazu genutzt werden die Auflösung der Fouriertransformation zu erhöhen. Im Verlauf dieser Arbeit konnten viele Erkenntnisse gesammelt werden und neue Ideen entwickelt werden. Diese Ideen müssen evaluiert auf ihre Machbarkeit geprüft werden. 

\end{document}