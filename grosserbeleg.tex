\documentclass[hyperref,german,beleg]{cgvpub}
\usepackage{subfigure}
%weitere Optionen zum Ergänzen (in eckigen Klammern):
% 
% female	weibliche Titelbezeichnung bei Diplom
% bibnum	numerische Literaturschlüssel
% final 	für Abgabe	
% lof			Abbildungsverzeichis
% lot			Tabellenverzeichnis
% noproblem	keine Aufgabenstellung
% notoc			kein Inhaltsverzeichnis
% twoside		zweiseitig
\author{Patrick Stiller}
\title{Parameter Reconstruction for Small Angle X-Ray Scattering with Deep Learning}
\birthday{8. Januar 1994}
\placeofbirth{Dresden}
\matno{3951290}
\betreuer{Dr. Dmitrij Schlesinger, Dr. Heide Meissner, Dr. Michael Bussmann}
\bibfiles{literatur}
\problem{Text der Aufgabenstellung...}
\copyrighterklaerung{Hier soll jeder Autor die von ihm eingeholten
Zustimmungen der Copyright-Besitzer angeben bzw. die in Web Press
Rooms angegebenen generellen Konditionen seiner Text- und
Bild"ubernahmen zitieren.}
\acknowledgments{Die Danksagung...}
\begin{document}

\chapter{Einleitung}

\chapter{Grundlagen}

\section{Small Angle X-Ray Scattering with free electron laser pulses}

\subsection{Motivation}
Das Small Angle X-Ray Scattering(SAXS) ist eine universelle Technik zur Untersuchung von Fest \- stoffen. Dabei liefert SAXS Informationen über die kristalline Struktur, chemische Komposition und die physikalische Eigenschaften des untersuchten Feststoffes \cite{THEORYSAXS}. Die Untersuchung von Feststoffen unter Einfluss von Kurzpulslasern ist eine wichtige Aufgabe der heutigen Physik. Wissen über das verhalten von Feststoffen unter  Einfluss von Kurzpulslasern kann offene Fragen in der Krebsforschung und in der Astrophysik beantworten\cite{SAXS18}. In diesem Beleg wurde SAXS für die Untersuchung von Plasma eingesetzt. 

\subsection{Experimentbeschreibung}

Das Experiment besteht aus vier Hauptkomponenten (siehe Abbildung \ref{fig:saxssetup}). Dem Target, dem Hochintensitätslaser (UHI), dem Röntgen-Freie-Elektronen-Laser(XFEL) und dem Detektor.  Während des Experiments wird das Target durch den Hochintensitätslaser in einem Winkel von 90° beschossen. Augrund des Elektrischen Feldes des Lasers entsteht Plasma. Bei Plasma handelt es sich um ein Gemisch aus freien Elektronen, positiven Ionen und neutralen Teilchen, welche unter ständiger Wechselwirkung untereinander und mit Photonen stehen. Dadurch kann es zu unterschiedlichen Energie- bzw. Anregungszuständen kommen. Der Plasmazustand eines Stoffes wird auch als vierter Aggregatzustand bezeichnet \cite{PLASMADEF}. Wurde Plasma erzeugt, soll es auf seine Struktur und Elektrodynamik untersucht werden. Dafür wird leicht zeitversetzt ein zweiter Laser benutzt. Dabei handelt es sich um einen Röntgen-Freie-Elektronen-Laser, welcher in einem Winkel von 45° mit einer Pulsdauer von 40 Femtosekunden auf das Target schießt. Dabei wird das Resultat, wie bei einer klassischen Röntgenaufnahme kennt, durch einen Detektor, welcher hinter dem Target platziert ist, aufgenommen \cite{SAXS18}. In den nächsten drei Unterkapiteln werden die Hauptkomponenten detaillierter untersucht und dessen Beitrag zum Experiment genauer beschrieben. 

\begin{figure}[ht]
	\centering
		\includegraphics [scale=0.6]{images/saxs_setup.png}
	\caption{Schematischer Aufbau des Experimentaufbaus. Die vier Hauptkomponenten sind durch die vorher eingeführten Abkürzungen notiert. Im 
	rechten Teil der Abbildung sind Detektorbilder in Abhängigkeit des Einsetzten des Röntgenlaserpulses dargestellt. Der dargestellte Effekt wird im  		übernächsten Kapitel genauer erklärt. Bildquelle: \cite{SAXS18}}
	\label{fig:saxssetup}
\end{figure}


\paragraph{Target}
Um das Target analytisch beschreiben zu können und das Experiment Resultat zu vereinfachen und somit besser verstehen zu können, wurden die Targets als regelmäßiges Gitter (Grating) designed. Dafür wurde das Target mit einer 2 $\mu$m breiten Siliziumschicht überzogen und das Grating in diese Schicht eingraviert. Der Effekt des gewählten Targetdesigns ist, dass das Grating einen eindimensionalen Informationsgehalt hat und somit auch durch eine eindimensionale Funktion in Abhängigkeit von drei Parametern beschrieben werden kann (siehe Abbildung \ref{fig:grating_structure}). Die drei Paramter sind Wellenlänge, Erhöhungsbreite und Aufweichungsbreite. Dabei beschreiben Wellenlänge, Erhöhungsbreite die Struktur des Gratings und die Aufweichungsbreite den Aufweichungseffekt des Hochenergielasers, auf den aber in einem späteren Kapitel eingegangen wirds.

\begin{figure}[ht]
	\centering
		\includegraphics [scale=0.5]{images/grating_structure.png}
	\caption{Analytische Beschreibung des Querschnittes des Targets. Dabei ist das Grating zu erkennen und dass es durch drei Parameter: Wellenlänge, Erhöhungsbreite und Aufweichungsbreite beschrieben werden kann. Bildquelle: \cite{ZACH17}}
	\label{fig:grating_structure}
\end{figure}

Der vorher erwähnte funktionale Zusammenhang wird im späteren Simulationskapitel genauer erläutert. Weiterhin müssen noch Begrifflichkeiten bezüglich des Targets geklärt werden. Die Erhöhungen des Gratings werden auch Features genannt und in diesem Kontext wird die Erhöhungsbreite auch Featuresize oder fsize genannt. Das Gitter wird in den meisten Fällen als Welle betrachtet, daher auch die Wahl des Parameternamen Wellenlänge. Weiterhin wird die Wellenlänge auch als Pitch bezeichnet. Ein letzter wichtiger Begriff ist die Elektronendichteverteilung $\eta $. Dabei ist das Grating ein Synonym für die Elektronendichteverteilung, dabei werden Features auch als Bereiche mit hoher Energiedichte bezeichnet. 


\paragraph{Small Angle X-Ray Scattering}
Um das Plasma auf seine Struktur zu untersuchen wird der Ansatz des Small Angle X-Ray Scatterings mit Hilfe eines X-ray Free Electron Lasers (XFEL) verwendet. Bei diesem  Small Angle X-Ray Scattering Ansatz wird ein Frei Elektronen Röntgenlaser in einem kleinen Winkel von 45° auf das Target geschossen (Abbildung \ref{fig:saxssetup}). Bei diesem Vorgang kommt es zu einem Streuvorgang des Lichts des Röntgenlasers an den Elektronen des Targets. Die Intensitäten des gestreuten Röntgenlasers werden durch einen Detektor, welches hinter dem Target platziert ist, gemessen.(Abbildung \ref{fig:saxssetup}). Beim Detektor handelt es sich um ein Raster von Lichtdetektoren, welche die ankommenden Lichtintensitäten messen. Dabei ist der Lichtdetektor zeitintgrierend, dass heißt, das ankommende Lichtintensitäten über die Zeit summiert werden. Diesen Effekt ist in der Abbildung \ref{fig:electron_scattering} zu erkennen, welche den Steuprozess an zwei Elektronen zeigt. 

\begin{figure}[hh]
	\centering
		\includegraphics [scale=0.4 ]{images/electron_scattering.png}
	\caption{Beispielhafte Darstellung einer Streuung an zwei Elektronen. Die Röngenlaserpulse treffen geradlinig auf die Elektronen und werden dann bei den Elektronen gestreut. Der Detektor dahinter misst die ankommenden Intensitäten der kreiförmigen Wellen und summiert diese über die Zeit.  Bildquelle: \cite{ZACH17}}
	\label{fig:electron_scattering}
\end{figure}

Durch die Zeitintegrität des Detektors, gehen die zeitlichen Abstände der Wellen verloren (Phase) zusätzlich kann es dazu kommen, dass ankommende Wellen mehrere Detektorzellen gleichzeitig treffen, dabei kommt es zu einem Verschmierungseffekt im Detektorbild. Der funktionale Zusammenhang für den Streuvorgang ist in Gleichung \ref{eq:xrayscattering} definiert.


\begin{equation}\label{eq:xrayscattering}
\Phi = \phi _{0} \cdot \Delta \Omega  \cdot  T \cdot  \epsilon  \cdot | r _{0} \cdot \int \eta _{e}(\vec r) \cdot e^{i\vec q \vec r} d \vec r|^2
\end{equation}

Der wichtigste Aspekt ist der hintere Teil der Gleichung. Denn in diesem Teil werden die Intensitäten des Detektorbildes $\Phi $, welches äquivalent zum Betragsquadrat der Fouriertransformation der Elektronendichte $ \eta $ ist. 


\paragraph{Hochintensitätslaser}

Die letzte wichtige Komponente ist der Hochintensitätslaser, welcher zur Generierung von Plasma aus den Targets zuständig ist. Der Hochintensitätslaser hat Einfluss sowohl auf das Target sowie auf das Detektorbild, welcher in diesem Kapitel untersucht wird. Der Hochintensitätslaser (UHI) ,welcher im 90° Winkel auf das Target schießt(Abbildung \ref{fig:saxssetup}, reißt mit seinem elektrischen Feld die Elektronen aus den Atomkernen des Targets. Dabei entsteht in einem Sekundenbruchteil Plasma. Zeitgleich kommt es zu einen Temperaturanstieg, welcher zu einem Schmelzprozess des Targets und somit zu einer Veränderung der Elektronendichteverteilung $\eta $  führt \cite{SAXS18}. Diesen Schmelzprozess ist in Abbildung \ref{fig:melting_grating} erkennbar. 

\begin{figure}[hh]
\centering
\includegraphics [scale=0.95]{images/melting_grating.png}
\caption{Veränderung der Elektronendichteverteilung nach einer Bestrahlungsdauer von 60 Femtosekunden Bildquelle: \cite{SAXS18}}
\label{fig:melting_grating}
\end{figure}

Ein Nebeneffekt des Schmelzvorgangs ist der Informationsverlust der ursprünglichen Kantenstruktur, welcher sich auch im Detektorbild bemerkbar macht. Im rechen Teil der Abbildung \ref{fig:saxssetup} ist erkennbar, dass mit späterem Einsätzen des Röntgenlasers, was äquivalent zu längeren Bestrahlungsdauer des Hochintensitätslaser ist, Informationspunkte am Rand des Detektorbildes verloren gehen. 

\section{Problemidentifikation}
Beim beschriebenen Experiment ist das größte Problem die Zeitintegrität des Detektors. Diese Detektoreigenschaft ruft den Verlust der Phase hervor, sodass eine Rekonstruktion der Elektronendichteverteilung $ \eta $ mit Hilfe einer inversen Fouriertransformation (IFT) nicht möglich ist. Um dieses Problem zu lösen werden iterative Algorithmen, sogenannte Phaseretrieval-Algorithmen verwendet. Beispiele für solche Algorithmen sind : Error-Reduction Algorithm, Gradient Search Methods und der Input Output Algorithmus. Probleme bei diesen Algorithmen ist, dass erstens bei allen Algorithmen keine Konvergenz garantiert ist und zweitens sehr viele Iterationen notwendig sind um eine Optimierung der errechneten Phase zu erzeugen  \cite{Fienup:82}. Diese Algorithmeneigenschaften führen dazu, dass eine hohe Bildraten im Megahertz im Experiment verweht bleibt. Deswegen soll Versucht werden mit Hilfe von Deep Learning die Phase bzw. die Eigenschaften (drei Parameter zur Beschreibung der Welle) der Elektronendichteverteilung $ \eta $ rekonstruiert werden. Der gewählte Deep Learning Ansatz ist ein neuronales Netz. Ein neuronales Netz hat den Vorteil, dass es über mehrere GPUs parallelisierbar ist und dass es die Phaseninformation bzw. die Parameter der Elektronendichte nicht-iterativ bestimmt. 



\section{Fouriertransformation}
Die Fouriertransformation (benannt nach Jean Baptiste Joseph Fourier) ist eine Transformation, welche zeitbezogene Welle im Ortsraum in ihre freuqenzmä\ss igen Spektralanteile zerlegt. Bei der Fouriertransformation wird die Welle in Teilwellen zerlegt (Abbildung \ref{fig:fourier_example}). Diese Teilwellen ergeben summiert wieder die ursprüngliche Welle (Gleichung \eqref{eq:fourier-series}) \cite{FOURIERDEF}. So ergibt sich die Fouriertransformation einer stückweise stetig differenzierbaren und T- periodischen Funktion $ f_{T}: \mathbb{R} \longrightarrow \mathbb{R}$ durch folgenden Funktionalen Zusammenhang : 

\begin{equation}\label{eq:fourier-series}
f _ { T } ( t ) = \sum _ { k = - \infty } ^ { \infty } \gamma _ { k } e ^ { i k \omega t }  \textrm{ mit } \omega = \frac { 2 \pi } { T } 
\end{equation}

die Fourier-Koeffizienten $\gamma_{k}$  werden wie bei einem Basiswechsel durch ein Integral bestimmt( Gleichung \eqref{eq:fourier_coefficients}). Dabei ist das Ergebnis des Integrals die Länge der Projektion in Richtung der Basis des Frequenzraumes. 

\begin{equation}\label{eq:fourier_coefficients}
\gamma _ { \mathrm { k } } = \frac { 1 } { T } \int _ { 0 } ^ { \top } f _ { \mathrm { T } } ( \tau ) e ^ { - i k \omega \tau } \mathrm { d } \tau
\end{equation}

Somit ergibt sich als Resultat der Fouriertransformation eine Folge von Komplexenzahlen $u$ mit zugehörigen Koeffizienten $ \gamma_{k}$. Jede Komplexe Zahl kodiert eine Welle, welche über die Euler Identität $e ^ { i k x } = \cos ( k x ) + i \cdot \sin ( k x )$ errechnet werden kann. Zusätzlich kann noch das Amplituden- und das Phasenspektrum bestimmt werden.  Dabei bestimmt das Amplitude die Maxima und Minima der zugehörigen Welle und das Phase die Verschiebung der Welle. Das Amplitudenspektrum $| F ( u ) | $ und das Phasenspektrum $\phi ( u )$ ergeben sich durch die folgende Gleichungen \cite{FOURIER2}.

\begin{equation}
| F ( u ) | = \sqrt { R ^ { 2 } ( u ) + I ^ { 2 } ( u ) }
\end{equation}

\begin{equation}
\phi ( u ) = \tan ^ { - 1 } \frac { I ( u ) } { R ( u ) }
\end{equation}

\begin{figure}[hh]
	\centering
		\includegraphics [scale=0.5]{images/example_fourier.png}
	\caption{Überlagerung mehrerer Wellen um eine Rechteckfunktion zu approximieren. Bildquelle: \cite{Gallagher2008AnIT}}
	\label{fig:fourier_example}
\end{figure}


\section{Filter}

Ein Filter ist eine Operation, welche auf einem Signal verwendet wird um Signale zu glätten, Signalstörungen zu vermeiden oder um Rauschen zu verhindern. In den meisten Fällen wird die Filteroperation mit Hilfe von Faltung realisiert. Dabei wird die Faltung zweier Funktionen (f * g) durch folgenden funktionalen Zusammenhang in Formel \eqref{eq:convolution} beschrieben. Dabei ist f die Funktion, welche das Signal beschreibt und g die Funktion, welche den Filter beschreibt. Im diskreten Fall wird das Integral durch eine Summe bis zur entsprechenden Filtergröße ersetzt. 

\begin{equation}\label{eq:convolution}
( f * g ) ( x ) : = \int _ { \mathbb { R } ^ { n } } f ( \tau ) g ( x - \tau ) \mathrm { d } \tau
\end{equation}



\section{Neuronale Netze}
\subsection{Aufbau}
Neuronale Netze sind eine mathematische Adaption des realen menschlichen Gehirns. Ein neuronales Netz besteht aus vielen kleinen Komponenten, Neuronen, welche durch gerichtete und gewichtete Verbindungen verbunden sind.  Mathematisch definiert ist ein neuronales Netz ein Tripel (N,V,w) mit den Beiden Mengen N und V und der Funktion w.  N ist die Menge aller Neuronen und V = $\{ (i,j) | i, j \epsilon \mathbb{N}\}$  die Menge der  Verbindungen zwischen Neuron i und Neuron j . Die Funktion $w : V \longrightarrow \mathbb{R} $  beschreibt die Gewichte des Neuronalen Netzes. Wobei w(i,j) das Gewicht zwischen dem Neuron i und Neuron j beschreibt. Im Allgemeinen wird anstatt der Funktionsnotation die Notation $w_{i,j}$ für die Gewichte zwischen zwei Neuronen verwendet.  \cite{Kriesel2007NeuralNetworks} Die nächste wichtige Komponente ist die Propagierungsfunktion $net_{j}$  eines Neurons, welche einen wichtigen Teil des Informationsflusses in einem Neuronalen Netz definiert. Dabei wird der Input des Neurons j durch dessen Propagierungsfunktion $net_{j}$ bestimmt. Die Propagierungsfunktion $net_{j}$ nimmt den Output aller Neuronen welche eine ausgehende Verbindung zum Neuron j besitzen als Input.  So wird die Propagierungsfunktion $net_{j}$ durch folgenden funktionalen Zusammenhang beschrieben : 

\begin{equation}\label{eq:propagation_function}
 net_ { j } = \sum _ { i \in I_{j}} ( o _ { i }\cdot w _ { i , j }) \textrm{ mit } I_{j} = \{ i \epsilon N | (i,j) \epsilon V \}
\end{equation}

Der Output  $o_{j} $ eines Neuronen j wird mit Hilfe der Aktivierungsfunktion $a_{j}$ und der der Propagierungsfunktion berechnet. Dazu wird noch der Schwellwert $ \theta_{j} $ zur Hemmung des Aktivierungszustand des Neurons zur Hilfe genommen. Somit ergibt sich für den Output des Neurons folgender funktionaler Zusammenhang : 

\begin{equation}
o_{j} = a_{j}(net_{j} - \theta_{j}) = f(x)
\end{equation}

Die Wahl der Aktivierungsfunktion ist von Anwendungsfall von Anwendungsfall unterschiedlich. In den meisten Fällen werden differenzierbare Aktivierungsfunktionen benutzt, da sie den Lernprozess, des neuronalen Netzes erleichtern. Das erste Beispiel für eine Aktivierungsfunktion ist die Heaviside-Funktion(Step-Funktion), welche auf 0 oder 1 abbildet(Abbildung \ref{fig:activations}a). Diese Funktion ist an der Stelle 0 nicht differenzierbar und im generellen für moderne Optimierungsansätze für neuronale Netze nicht geeignet, da die Ableitung der Step-Funktion an allen Stellen 0 ist. Beispiel für gängige und differenzierbare Funktionen sind die Sigmoid-(Abbildung \ref{fig:activations}b, Formel \eqref{eq:sigmoid}), Tangens Hyperbolicus-(Abbildung \ref{fig:activations}c, Formel \eqref{eq:tanh}) und die Rectified Linear Units- Aktivierungsfunktion(Abbildung \ref{fig:activations}d, Formel \eqref{eq:relu})

\begin{equation}\label{eq:sigmoid}
f(x)= \frac { 1 } { 1 + e ^ { - x } }
\end{equation}

\begin{equation}\label{eq:tanh}
f(x)= tanh(x) = 1 - \frac { 2 } { \mathrm { e } ^ { 2 x } + 1 }
\end{equation}

\begin{equation}\label{eq:relu}
f(x)= max(0,x)
\end{equation}

\begin{figure}[hh]
	\subfigure[Heavisidefunction]{\includegraphics[width=0.5\textwidth]{images/step.png}}
    \subfigure[Sigmoid]{\includegraphics[width=0.5\textwidth]{images/sigmoid.png}} 
     \subfigure[Tanh]{\includegraphics[width=0.5\textwidth]{images/tanh.png}} 
    \subfigure[Relu]{\includegraphics[width=0.5\textwidth]{images/relu.png}} 
    \caption{Übersicht Aktivierungsfunktionen, Bildquelle:  \cite{Kriesel2007NeuralNetworks}}
\label{fig:activations}
\end{figure} 

Jeder der genannten Aktivierungsfunktion hat auf Hinsicht seiner Berechnungsdauer, Wertebereich und Ableitung Vor- und Nachteile. Die Sigmoid und die Tangens Hyperbolicus  Aktivierungsfunktion haben einen eingeschränkten Wertebereich, dadurch kann es mit diesen Aktivierungsfunktionen zu keinen zu hohen Werten im Neuronalen Netz kommen und negative Werte werden im Gegensatz zu ReLu noch berücksichtigt. Jedoch sind beide langsamer zu berechnen als die Rectified Linear Units und bieten für den Lernprozess kleinere Gradienten. Rectified Linear Units(ReLu) ist im Vergleich zu Sigmoid und Tangens Hyperbolicus schneller zu berechnen und bietet größere Gradienten. Jedoch können Neuronen, welche einen negativen Input bekommen nur noch 0 Ausgeben. Man spricht in diesem Zusammenhang von einem totem Neuron. Ein weiterer Nachteil von ReLu ist der Wertebereich,denn dieser ist nicht eingeschränkt. Somit können im Neuronalen Netz sehr große Werte entstehen, welche den Wertebereich von Zahlenstandards wie zum Beispiel 32 Bit Float überschreiten und somit kein valider Datenfluss im Neuronalen Netz gegeben ist. 

\subsection{Feed-Forward-Neuronal  Networks}
Für ein Neuronales Netzwerk werden verschiedene Netzwerktopologien verwendet. Ein Beispiel dafür ist das Feed Forward Neuronal Network (Abbildung \ref{fig:ffnn}) Bei einem Feed Forward Neuronal Network werden die Neuronen als Schichten angeordnet. Diese Schichten sind miteinander verbunden. Dabei ist die Erste Schicht, welche die Input Daten bekommt, wird als Input-Layer bezeichnet. Und die letzte Schicht, welche die Netzberechnung ausgibt, als Output-Layer bezeichnet. Schichten, welche sich zwischen Input- und Output-Layer befinden und somit keinen Kontakt nach Außen haben, werden als Hidden Layer bezeichnet. Ein wichtiges Merkmal von Feed Forward Networks ist, dass der Datenfluss geradlinig ohne Rückkopplung von Input-Layer über die Hiddenlayer bishin zum Output-Layer verläuft. 

\begin{figure}[hh]
\centering
\includegraphics [scale=0.4]{images/feed_forward_neuronal_network.png}
\caption{Beispielhafte Darstellung für ein Feed-Forward-Neuronal-Network. Bildquelle: \cite{COMPMETHODS}}
\label{fig:ffnn}
\end{figure}

\subsection{Lernprozess}
Das Anlernen von Neuronalen Netzen wird in den meisten Fällen durch überwachtes Lernen (supervised Learning) realisiert. Im speziellen wird der Lernprozess durch den Backpropagation Algorithmus durchgeführt. Bei einem überwachten Lernansatz besteht der Datensatz zum Trainieren des Neuronalen Netzen aus zwei Teilen. Zu jedem Netzinput $x_{i}$ gibt es ein zugehöriges Label $y_{i}$ , welches den gewünschten Netzoutput definiert. Der Lernprozess eines neuronalen Netzes kann in drei Phasen aufgeteilt werden. Der Forward-Pass, Loss-Calculation und Backward Pass \cite{NeuronaleNetze}. Zu Beginn des Trainingsprozesses werden die Gewichte des Neuronalen Netzes mit Zufallszahlen initialisiert. Beim Forward Pass werden die Input Daten zur Kalkulation des derzeitigen Net-Outputs zum Input-Layer des neuronalen Netzes gegeben. Das Neuronale Netz bestimmt dann durch die Rechenvorschriften des Neuronalen Netzes den Net-Output $\hat { y } _ { i }$. Im zweiten Schritt wird dann die Qualität des Netouput $\hat { y } _ { i }$ bestimmt.. Dazu wird ein Fehlermaß benutzt, was den Grad des Unterschiedes zwischen $\hat { y } _ { i }$ und $y_{i}$  bestimmt. Eine beispielhafte Errorfunktion ist Mean-Squared Error \eqref{eq:mse}. 


\begin{equation}\label{eq:mse}
\mathrm { MSE } = \frac { 1 } { n } \sum _ { i = 1 } ^ { n } \left( Y _ { i } - \hat { Y } _ { i } \right) ^ { 2 }
\end{equation}

Im drittem Schritt, dem Backward-Pass, kommt es zur Optimierung des Neuronalen Netzes. Mithilfe des Fehlers, welcher bis zur Eingabeschicht zurück propagiert, werden die Gewichte, je nach ihrem Einfluss auf den Net-Output angepasst. Dazu wird ein Gradientenabstiegsverfahren verwendet. Dafür wird die partielle Ableitung des Fehlerterms benötigt. Somit ergibt sich für die Gewichtsveränderung $\Delta w _ { i j }$ des Gewichts zwischen Neuron i und Neuron j durch folgenden Funktionalen Zusammenhang : 

\begin{equation}\label{eq: deltaw}
\Delta w _ { i j } = - \eta \frac { \partial E } { \partial w _ { i j } } = - \eta \delta _ { j } o _ { i }
\end{equation}

Dabei ist E die Errorfunktion. $\delta _ { j }$ das Fehlersignal des bzw. der Gradient Neurons j und $o _ { i }$ die Ausgabe des Neuron i. Der letzte wichtige Parameter ist $\eta $ welche die Learning-Rate des Gradientenabstiegsverfahren bestimmt. Schlussendlich fehlt die Definition des Gradienten. Dieser ist davon abhängig, wie stark das Neuron den Output des Neuronalen Netz beeinträchtigt. Deswegen wird eine Unterscheidung getroffen, ob das Neuron sich im Output-Layer oder darunter befindet. In der folgenden Gleichung \eqref{eq:gradient} ist die Definition des Gradienten und die zugehörige Propagierung des Fehlers. 


\begin{equation}\label{eq:gradient}
\delta _ { j } = \left\{ \begin{array} { l l } { a_{j}  \left( \text { net } _ { j } \right) \left( o _ { j } - t _ { j } \right) } & { \text { falls } j \text { Ausgabeneuron ist } } \\ { a_{j}  \left( \text { net } _ { j } \right) \sum _ { k } \delta _ { k } w _ { j k } } & { \text { falls } j \text { verdecktes Neuron ist. } } \end{array} \right.
\end{equation}

Dabei ist die Gleichung \eqref{eq:gradient} in Abhängigkeit von den Variablen $o_{j}$ dem Output des Neurons j , $t_{j}$ die Soll-Ausgabe des Neurons j und der Aktivierungsfunktion $a_{j} $ des Neuron j angegeben. Und somit ergibt sich die Veränderung des neuem Gewicht durch eine Addition des alten Gewichts. 

\begin{equation}
w _ { i j } ^ { \text { neu } } = w _ { i j } ^ { \text { alt } } + \Delta w _ { i j }
\end{equation} 

Der Backpropagation wird iterativ solange angewandt, bis eine bestimmte Anzahl von Iterationen erreicht ist, oder andere Kriterien erfüllt sind.  \cite{wiki:Backpropagation}


\chapter{Simulation}
\section{Motivation}
Um das Ergebniss des SAXS-Experimentes bestmöglich zu verstehen und aufgrund mangelnder Anzahl von Experimentdaten, wurde im Rahmen der Master Arbeit von Malte Zacharias mit dem Titel: \grqq Model-Driven Parameter Reconstruction from Small Angle X-Ray Scattering Images \grqq eine Simulation entwickelt. Die Simulation beinhaltet das Design der Gitterstruktur (Elektronendichteverteilung), die Simulation des Hochenergielasereinflusses, die Simulation des Streuvorgangs und die Simulation des Detektorbildes. \cite{Zach17}.

\section{Simulationsbeschreibung}
\subsection{Design der Gitterstruktur und Simulation des Hochenergielasereinflusses}
Wie in Kapitel 2 beschrieben sind die Targets des SAXS-Experiments sind als Gitter strukturiert, um eine analytische Beschreibung des Targets zu ermöglichen. Der erste Simulationsschritt ist die Bestimmung der Gitterstruktur. Dazu wird eine feste Targetbreite N in Pixeln festgelegt. Und es werden zum Start der Simulation die drei Startparameter Pitch, Feature-size und Sigma festgelegt, welche die Eleketronendichteverteilung beschreiben.  In der Simulation wird die Gitterstruktur mithilfe der Errorfunktion \eqref{eq:erf} erstellt. 

\begin{equation}\label{eq:erf}
\text{erf(x)} = \frac{2}{\sqrt{\pi}} \int_{0}^{x} e^{-\xi^{2}}d\xi
\end{equation}

Im speziellen wird die Verwandschaft der Errorfunkton zur Normalverteilung ausgenutzt. So wird die Elektronendichteverteilung durch partiell definierte Normalverteilungen in Abhängigkeit der drei Startparameter Sigma (\( \sigma\)), Pitch(p) und Feature-Size(f) konstruiert. 



\begin{equation}\label{eq:edge}
edge_{\sigma,f,p}(x) =
	\begin{cases}
		\frac{1}{2} (1 + \text{erf} (\frac{(x \mod p)}{\sigma \sqrt{2}}) &  \text{,falls x (mod p)}  \leq \frac{1}{2} f \\
		\frac{1}{2} (1 + \text{erf} (\frac{(-x + f \mod p)}{\sigma  \sqrt{2}}) &  \text{,falls  x  (mod p)} > \frac{1}{2} f 
	\end{cases} \\
	,x < nx
\end{equation}

Essentiell dabei sind die drei Startparameter Sigma (\( \sigma\)), Pitch(p) und Feature-Size(f), welche für die Beschreibung der Kantenstrukur benötigt werden.  Die Variable \textit{x} dient als Positionsvariable und ist durch den Parameter \textit{nx} beschränkt. Der Parameter \textit{nx}bestimmt die Breite der Elektronendichte-Matrix \( \eta\). Sigma ist der Parameter, welcher den Einfluss des Hochenergielasers auf ein Feature beschreibt. Desto höher Sigma gewählt wird, desto mehr wird die Kantenstruktur des Targets aufgeweicht. In Abbildung \ref{img:edge_sigma} ist dieser Effekt dargestellt. Es ist erkennbar, dass die maximalen Elektronendichten sich verkleinern und auch die Features schmaler werden. 

\begin{figure}[hh]
\centering
\includegraphics[scale=0.55]{images/edge_sigma.png} 
\caption{Vergleich der Kantenstruktur unter variierenden Sigma-Werten bei gleichbleibenden Pitch- und Feature-Size- Werten}
\label{img:edge_sigma}
\end{figure}

Der Parameter Pitch(p) bestimmt die Wellenlänge der Kantenstruktur und bestimmt somit auch die Periodizität der Kantenstruktur \eqref{eq:edge}. Indirekt bestimmt Pitch auch die Anzahl der vorkommenden Features des Targets, da in in der Simulation von einer gleichbleibend großen Targetbreite ausgegangen wird. Daraus folgt, dass mit steigendem Pitch die Anzahl der Features sinkt. Dieser Effekt ist in der Abbildung \ref{img:edge_pitch_fsize} in der linken Spalte dargestellt.

\begin{figure}[hh]
  \subfigure[Pitch]{\includegraphics[width=0.49\textwidth]{images/edge_pitch.png}} 
   \subfigure[Feature-Size]{\includegraphics[width=0.5\textwidth]{images/edge_fsize.png}}   	 
	\caption{Vergleich der Kantenstruktur unter variierenden Pitch-Werten(linke Spalte) und variierenden Feature-Size-Werten(rechte Spalte)} 
	\label{img:edge_pitch_fsize}
\end{figure} 

Der dritte Startparamter Feature-Size(f) bestimmt die Größe der Gitterstäbe (Features). Dabei kann die Feature-Size nicht größer als Pitch gewählt werden, da sonst keine Kantenstruktur mehr erkennbar wäre. Der Effekt der Feature Size wird in Abbildung \ref{img:edge_pitch_fsize} in der rechten Spalte dargestellt. Die Kanteninformation, welche durch die drei Startparamter generiert wurde, ist eindimensional. Um eine zweidimensionale Elektronendichteverteilung \( \eta \)  zu generieren, wird die eindimensionale Kanteninformation \textit{ny}-fach dupliziert. Dabei bestimmt der Parameter \textit{ny} die Höhe der Elektronendichte-Matrix. Somit ergibt sich die  zweidimensionale Elektronendichte \( \eta\) :

\begin{equation}\label{eq:eta}
\eta _{i,j} = edge_{\sigma,f,p}(j) , 0 \leq i \leq ny , 0 \leq j \leq nx
\end{equation}

\subsection{Simulation des Detektorinputs}

Wie im Kapitel zur Experimentbeschreibung beschrieben, ist das aufgenommene Detektorbild äquivalent zum Betragsquadrat der  Fouriertransformation der Elektronendichte $\eta $.  Im Fall der Simulation ist die Elektronendichte eine diskrete zwei dimensionale Elektronendichteverteilung. Deswegen wird zur Bildung des Detektorbildes eine zweidimensionale diskrekte Fouriertransformation verwendet \cite{WIKI_DFT}. Dabei ist es meistens der Fall, dass das Fourierbild die gleiche Höhe und Breite aufweist,wie die Elektronendichteverteilung. 
Um den Informationsverlust durch die Fouriertransformation zu verringern, wird die Elektronendichteverteilung oversampled und dann das Fourierbild dann wieder auf die normale Größe skaliert. 

\begin{equation}
\hat { a } _ { k , l } = \sum _ { m = 0 } ^ { M - 1 } \sum _ { n = 0 } ^ { N - 1 } \eta _ { m , n } \cdot \mathrm { e } ^ { - 2 \pi i \cdot \frac { m k } { M } } \mathrm { e } ^ { - 2 \pi \mathrm { i } - \frac { n l } { N } } \text { fur } k = 0 , \ldots , M - 1 \text { und } l = 0 , \ldots , N - 1
\end{equation}

Das entstandene Fourierbild ist im Raum der Komplexen Zahlen und weißt den gleichen Informationsgehalt wie die Elektronendichteverteilung auf. Das heißt Amplituden- und Phaseninformationen(Abbildung \ref{img:phase_amplitude}) sind nach wie vor vorhanden. Wie in Kapitel 1 beschrieben, ist der Detektor nicht in der Lage Phaseninformation zu speichern, deswegen wird diese Information im weiteren Simulationsverlauf nicht weiter verwendet. 

\begin{figure}[hh]
 	\subfigure[log(Amplitude(FFT($\eta$)))]{\includegraphics[width=0.55\textwidth]{images/amplitude.png}} 
    \subfigure[Phase(FFT($\eta$)))]{\includegraphics[width=0.55\textwidth]{images/phase.png}} 
\caption{Fouriertransformierte Elektronendichte und dessen Abbildung auf dem Detektor} 
\label{img:phase_amplitude}
\end{figure} 

Im Amplituden- und Phasenbild Fourier-Bild(Abbildung \ref{img:phase_amplitude})ist erkennbar, dass nur Frequenzen,welche auf der mittleren Achse des Bildes liegen, für die Kodierung des Bildes benutzt wurden. Das liegt daran, dass die Gitterstruktur nur eine horizontale Ausrichtung hat, sowie der Laser auch nur einen horizontalen Schmelzprozess hervorruft. Um das Detektorbild zu erhalten, wird das Betragsquadrat des Amplitudenbildes gebildet.



\subsubsection{Simulation der Detektoreigenschaften}
Im letztem Schritt werden die Detektoreigenschaften auf das Betragsquadrat angewandt, dabei werden Beugungserscheinungen, Abbildungsfehler und der Einfluss der Sensorenfläche des Detektors mit der sogenannten Point Spread Function simuliert. Die Point Spread Function wird durch einen Faltung mit einem Gauss-Filter umgesetzt.\cite{WIKI_PSF} Außerdem werden Intensitätswerte, welche über dem Intensitätsmaximum des Detektors liegen auf dieses Maximum reduziert. Das finalisierte Detektorbild ist in Abbildung \ref{img:detector} sichtbar.

\begin{figure}[hh]
\centering
\includegraphics[scale=0.55]{images/detector_result.png} 
\caption{Resultierendes Detektorbild als Endprodukt der Simulation}
\label{img:detector}
\end{figure}






\chapter{Datenbasis}
\section{Generator}
	\subsection{Aufbau}
	\subsection{Wahl der Eingangsparameter}
\section{Training-, Validation- und Testdatensatz}

\chapter{Neuronales Netz}
\section{Architektur}
\section{Lossfunction}
\section{Optimizer}

\chapter{Ergebnisse und Diskussion}
	\section{Lernprozess}
	\section{Ergebnisse und statistische Auswertung}
	\section{Fazit}
	
\end{document}