\documentclass[hyperref,german,beleg]{cgvpub}
\usepackage{subfigure}
%weitere Optionen zum Ergänzen (in eckigen Klammern):
% 
% female	weibliche Titelbezeichnung bei Diplom
% bibnum	numerische Literaturschlüssel
% final 	für Abgabe	
% lof			Abbildungsverzeichis
% lot			Tabellenverzeichnis
% noproblem	keine Aufgabenstellung
% notoc			kein Inhaltsverzeichnis
% twoside		zweiseitig
\author{Patrick Stiller}
\title{Parameter Reconstruction for Small Angle X-Ray Scattering with Deep Learning}
\birthday{8. Januar 1994}
\placeofbirth{Dresden}
\matno{3951290}
\betreuer{Dr. Dmitrij Schlesinger, Dr. Heide Meissner, Dr. Michael Bussmann}
\bibfiles{literatur}
\problem{Text der Aufgabenstellung...}
\copyrighterklaerung{Hier soll jeder Autor die von ihm eingeholten
Zustimmungen der Copyright-Besitzer angeben bzw. die in Web Press
Rooms angegebenen generellen Konditionen seiner Text- und
Bild"ubernahmen zitieren.}
\acknowledgments{Die Danksagung...}
\begin{document}

\chapter{Einleitung}


\chapter{Small Angle X-Ray Scattering with free electron laser pulses}

\section{Motivation}
Das Small Angle X-Ray Scattering(SAXS) ist eine universelle Technik zur Untersuchung von Fest \- stoffen. Dabei liefert SAXS Informationen über die kristalline Struktur, chemische Komposition und die physikalische Eigenschaften des untersuchten Feststoffes \cite{THEORYSAXS}. Die Untersuchung von Feststoffen unter Einfluss von Kurzpulslasern ist eine wichtige Aufgabe der heutigen Physik. Wissen über das verhalten von Feststoffen unter  Einfluss von Kurzpulslasern kann offene Fragen in der Krebsforschung und in der Astrophysik beantworten\cite{SAXS18}. In diesem Beleg wurde SAXS für die Untersuchung von Plasma eingesetzt. 

\section{Experimentbeschreibung}

Das Experiment besteht aus vier Hauptkomponenten (siehe Abbildung \ref{fig:saxssetup}). Dem Target, dem Hochintensitätslaser (UHI), dem Röntgen-Freie-Elektronen-Laser(XFEL) und dem Detektor.  Während des Experiments wird das Target durch den Hochintensitätslaser in einem Winkel von 90° beschossen. Augrund des Elektrischen Feldes des Lasers entsteht Plasma. Bei Plasma handelt es sich um ein Gemisch aus freien Elektronen, positiven Ionen und neutralen Teilchen, welche unter ständiger Wechselwirkung untereinander und mit Photonen stehen. Dadurch kann es zu unterschiedlichen Energie- bzw. Anregungszuständen kommen. Der Plasmazustand eines Stoffes wird auch als vierter Aggregatzustand bezeichnet \cite{PLASMADEF}. Wurde Plasma erzeugt, soll es auf seine Struktur und Elektrodynamik untersucht werden. Dafür wird leicht zeitversetzt ein zweiter Laser benutzt. Dabei handelt es sich um einen Röntgen-Freie-Elektronen-Laser, welcher in einem Winkel von 45° mit einer Pulsdauer von 40 Femtosekunden auf das Target schießt. Dabei wird das Resultat, wie bei einer klassischen Röntgenaufnahme kennt, durch einen Detektor, welcher hinter dem Target platziert ist, aufgenommen \cite{SAXS18}. In den nächsten drei Unterkapiteln werden die Hauptkomponenten detaillierter untersucht und dessen Beitrag zum Experiment genauer beschrieben. 

\begin{figure}[ht]
	\centering
		\includegraphics [scale=0.6]{images/saxs_setup.png}
	\caption{Schematischer Aufbau des Experimentaufbaus. Die vier Hauptkomponenten sind durch die vorher eingeführten Abkürzungen notiert. Im 
	rechten Teil der Abbildung sind Detektorbilder in Abhängigkeit des Einsetzten des Röntgenlaserpulses dargestellt. Der dargestellte Effekt wird im  		übernächsten Kapitel genauer erklärt. Bildquelle: \cite{SAXS18}}
	\label{fig:saxssetup}
\end{figure}


\subsection{Target}
Um das Target analytisch beschreiben zu können und das Experiment Resultat zu vereinfachen und somit besser verstehen zu können, wurden die Targets als regelmäßiges Gitter (Grating) designed. Dafür wurde das Target mit einer 2 $\mu$m breiten Siliziumschicht überzogen und das Grating in diese Schicht eingraviert. Der Effekt des gewählten Targetdesigns ist, dass das Grating einen eindimensionalen Informationsgehalt hat und somit auch durch eine eindimensionale Funktion in Abhängigkeit von drei Parametern beschrieben werden kann (siehe Abbildung \ref{fig:grating_structure}). Die drei Paramter sind Wellenlänge, Erhöhungsbreite und Aufweichungsbreite. Dabei beschreiben Wellenlänge, Erhöhungsbreite die Struktur des Gratings und die Aufweichungsbreite den Aufweichungseffekt des Hochenergielasers, auf den aber in einem späteren Kapitel eingegangen wirds.

\begin{figure}[ht]
	\centering
		\includegraphics [scale=0.5]{images/grating_structure.png}
	\caption{Analytische Beschreibung des Querschnittes des Targets. Dabei ist das Grating zu erkennen und dass es durch drei Parameter: Wellenlänge, Erhöhungsbreite und Aufweichungsbreite beschrieben werden kann. Bildquelle: \cite{ZACH17}}
	\label{fig:grating_structure}
\end{figure}

Der vorher erwähnte funktionale Zusammenhang wird im späteren Simulationskapitel genauer erläutert. Weiterhin müssen noch Begrifflichkeiten bezüglich des Targets geklärt werden. Die Erhöhungen des Gratings werden auch Features genannt und in diesem Kontext wird die Erhöhungsbreite auch Featuresize oder fsize genannt. Das Gitter wird in den meisten Fällen als Welle betrachtet, daher auch die Wahl des Parameternamen Wellenlänge. Weiterhin wird die Wellenlänge auch als Pitch bezeichnet. Ein letzter wichtiger Begriff ist die Elektronendichteverteilung $\eta $. Dabei ist das Grating ein Synonym für die Elektronendichteverteilung, dabei werden Features auch als Bereiche mit hoher Energiedichte bezeichnet. 


\subsection{Small Angle X-Ray Scattering}
Um das Plasma auf seine Struktur zu untersuchen wird der Ansatz des Small Angle X-Ray Scatterings mit Hilfe eines X-ray Free Electron Lasers (XFEL) verwendet. Bei diesem  Small Angle X-Ray Scattering Ansatz wird ein Frei Elektronen Röntgenlaser in einem kleinen Winkel von 45° auf das Target geschossen (Abbildung \ref{fig:saxssetup}). Bei diesem Vorgang kommt es zu einem Streuvorgang des Lichts des Röntgenlasers an den Elektronen des Targets. Die Intensitäten des gestreuten Röntgenlasers werden durch einen Detektor, welches hinter dem Target platziert ist, gemessen.(Abbildung \ref{fig:saxssetup}). Beim Detektor handelt es sich um ein Raster von Lichtdetektoren, welche die ankommenden Lichtintensitäten messen. Dabei ist der Lichtdetektor zeitintgrierend, dass heißt, das ankommende Lichtintensitäten über die Zeit summiert werden. Diesen Effekt ist in der Abbildung \ref{fig:electron_scattering} zu erkennen, welche den Steuprozess an zwei Elektronen zeigt. 

\begin{figure}[hh]
	\centering
		\includegraphics [scale=0.4 ]{images/electron_scattering.png}
	\caption{Beispielhafte Darstellung einer Streuung an zwei Elektronen. Die Röngenlaserpulse treffen geradlinig auf die Elektronen und werden dann bei den Elektronen gestreut. Der Detektor dahinter misst die ankommenden Intensitäten der kreiförmigen Wellen und summiert diese über die Zeit.  Bildquelle: \cite{ZACH17}}
	\label{fig:electron_scattering}
\end{figure}

Durch die Zeitintegrität des Detektors, gehen die zeitlichen Abstände der Wellen verloren (Phase) zusätzlich kann es dazu kommen, dass ankommende Wellen mehrere Detektorzellen gleichzeitig treffen, dabei kommt es zu einem Verschmierungseffekt im Detektorbild. Der funktionale Zusammenhang für den Streuvorgang ist in Gleichung \ref{eq:xrayscattering} definiert.


\begin{equation}\label{eq:xrayscattering}
\Phi = \phi _{0} \cdot \Delta \Omega  \cdot  T \cdot  \epsilon  \cdot | r _{0} \cdot \int \eta _{e}(\vec r) \cdot e^{i\vec q \vec r} d \vec r|^2
\end{equation}

Der wichtigste Aspekt ist der hintere Teil der Gleichung. Denn in diesem Teil werden die Intensitäten des Detektorbildes $\Phi $, welches äquivalent zum Betragsquadrat der Fouriertransformation der Elektronendichte $ \eta $ ist. 


\subsection{Hochintensitätslaser}

Die letzte wichtige Komponente ist der Hochintensitätslaser, welcher zur Generierung von Plasma aus den Targets zuständig ist. Der Hochintensitätslaser hat Einfluss sowohl auf das Target sowie auf das Detektorbild, welcher in diesem Kapitel untersucht wird. Der Hochintensitätslaser (UHI) ,welcher im 90° Winkel auf das Target schießt(Abbildung \ref{fig:saxssetup}, reißt mit seinem elektrischen Feld die Elektronen aus den Atomkernen des Targets. Dabei entsteht in einem Sekundenbruchteil Plasma. Zeitgleich kommt es zu einen Temperaturanstieg, welcher zu einem Schmelzprozess des Targets und somit zu einer Veränderung der Elektronendichteverteilung $\eta $  führt \cite{SAXS18}. Diesen Schmelzprozess ist in Abbildung \ref{fig:melting_grating} erkennbar. 

\begin{figure}[hh]
\centering
\includegraphics [scale=0.95]{images/melting_grating.png}
\caption{Veränderung der Elektronendichteverteilung nach einer Bestrahlungsdauer von 60 Femtosekunden Bildquelle: \cite{SAXS18}}
\label{fig:melting_grating}
\end{figure}

Ein Nebeneffekt des Schmelzvorgangs ist der Informationsverlust der ursprünglichen Kantenstruktur, welcher sich auch im Detektorbild bemerkbar macht. Im rechen Teil der Abbildung \ref{fig:saxssetup} ist erkennbar, dass mit späterem Einsätzen des Röntgenlasers, was äquivalent zu längeren Bestrahlungsdauer des Hochintensitätslaser ist, Informationspunkte am Rand des Detektorbildes verloren gehen. 

\section{Problemidentifikation}
Beim beschriebenen Experiment ist das größte Problem die Zeitintegrität des Detektors. Diese Detektoreigenschaft ruft den Verlust der Phase hervor, sodass eine Rekonstruktion der Elektronendichteverteilung $ \eta $ mit Hilfe einer inversen Fouriertransformation (IFT) nicht möglich ist. Um dieses Problem zu lösen werden iterative Algorithmen, sogenannte Phaseretrieval-Algorithmen verwendet. Beispiele für solche Algorithmen sind : Error-Reduction Algorithm, Gradient Search Methods und der Input Output Algorithmus. Probleme bei diesen Algorithmen ist, dass erstens bei allen Algorithmen keine Konvergenz garantiert ist und zweitens sehr viele Iterationen notwendig sind um eine Optimierung der errechneten Phase zu erzeugen  \cite{Fienup:82}. Diese Algorithmeneigenschaften führen dazu, dass eine hohe Bildraten im Megahertz im Experiment verweht bleibt. Deswegen soll Versucht werden mit Hilfe von Deep Learning die Phase bzw. die Eigenschaften (drei Parameter zur Beschreibung der Welle) der Elektronendichteverteilung $ \eta $ rekonstruiert werden. Der gewählte Deep Learning Ansatz ist ein neuronales Netz. Ein neuronales Netz hat den Vorteil, dass es über mehrere GPUs parallelisierbar ist und dass es die Phaseninformation bzw. die Parameter der Elektronendichte nicht-iterativ bestimmt. 

\chapter{Grundlagen}

\section{Fouriertransformation}
Die Fouriertransformation (benannt nach Jean Baptiste Joseph Fourier) ist eine Transformation, welche zeitbezogene Welle im Ortsraum in ihre freuqenzmä\ss igen Spektralanteile zerlegt. Bei der Fouriertransformation wird die Welle in Teilwellen zerlegt (Abbildung \ref{fig:fourier_example}). Diese Teilwellen ergeben summiert wieder die ursprüngliche Welle (Gleichung \eqref{eq:fourier-series}) \cite{FOURIERDEF}. So ergibt sich die Fouriertransformation einer stückweise stetig differenzierbaren und T- periodischen Funktion $ f_{T}: \mathbb{R} \longrightarrow \mathbb{R}$ durch folgenden Funktionalen Zusammenhang : 

\begin{equation}\label{eq:fourier-series}
f _ { T } ( t ) = \sum _ { k = - \infty } ^ { \infty } \gamma _ { k } e ^ { i k \omega t }  \textrm{ mit } \omega = \frac { 2 \pi } { T } 
\end{equation}

die Fourier-Koeffizienten $\gamma_{k}$  werden wie bei einem Basiswechsel durch ein Integral bestimmt( Gleichung \eqref{eq:fourier_coefficients}). Dabei ist das Ergebnis des Integrals die Länge der Projektion in Richtung der Basis des Frequenzraumes. 

\begin{equation}\label{eq:fourier_coefficients}
\gamma _ { \mathrm { k } } = \frac { 1 } { T } \int _ { 0 } ^ { \top } f _ { \mathrm { T } } ( \tau ) e ^ { - i k \omega \tau } \mathrm { d } \tau
\end{equation}

Somit ergibt sich als Resultat der Fouriertransformation eine Folge von Komplexenzahlen $u$ mit zugehörigen Koeffizienten $ \gamma_{k}$. Jede Komplexe Zahl kodiert eine Welle, welche über die Euler Identität $e ^ { i k x } = \cos ( k x ) + i \cdot \sin ( k x )$ errechnet werden kann. Zusätzlich kann noch das Amplituden- und das Phasenspektrum bestimmt werden.  Dabei bestimmt das Amplitude die Maxima und Minima der zugehörigen Welle und das Phase die Verschiebung der Welle. Das Amplitudenspektrum $| F ( u ) | $ und das Phasenspektrum $\phi ( u )$ ergeben sich durch die folgende Gleichungen \cite{FOURIER2}.

\begin{equation}
| F ( u ) | = \sqrt { R ^ { 2 } ( u ) + I ^ { 2 } ( u ) }
\end{equation}

\begin{equation}
\phi ( u ) = \tan ^ { - 1 } \frac { I ( u ) } { R ( u ) }
\end{equation}

\begin{figure}[hh]
	\centering
		\includegraphics [scale=0.5]{images/example_fourier.png}
	\caption{Überlagerung mehrerer Wellen um eine Rechteckfunktion zu approximieren. Bildquelle: \cite{Gallagher2008AnIT}}
	\label{fig:fourier_example}
\end{figure}


\section{Filter}

Ein Filter ist eine Operation, welche auf einem Signal verwendet wird um Signale zu glätten, Signalstörungen zu vermeiden oder um Rauschen zu verhindern. In den meisten Fällen wird die Filteroperation mit Hilfe von Faltung realisiert. Dabei wird die Faltung zweier Funktionen (f * g) durch folgenden funktionalen Zusammenhang in Formel \eqref{eq:convolution} beschrieben. Dabei ist f die Funktion, welche das Signal beschreibt und g die Funktion, welche den Filter beschreibt. Im diskreten Fall wird das Integral durch eine Summe bis zur entsprechenden Filtergröße ersetzt. 

\begin{equation}\label{eq:convolution}
( f * g ) ( x ) : = \int _ { \mathbb { R } ^ { n } } f ( \tau ) g ( x - \tau ) \mathrm { d } \tau
\end{equation}



\section{Neuronale Netze}
\subsection{Aufbau}
Neuronale Netze sind eine mathematische Adaption des realen menschlichen Gehirns. Ein neuronales Netz besteht aus vielen kleinen Komponenten, Neuronen, welche durch gerichtete und gewichtete Verbindungen verbunden sind.  Mathematisch definiert ist ein neuronales Netz ein Tripel (N,V,w) mit den Beiden Mengen N und V und der Funktion w.  N ist die Menge aller Neuronen und V = $\{ (i,j) | i, j \epsilon \mathbb{N}\}$  die Menge der  Verbindungen zwischen Neuron i und Neuron j . Die Funktion $w : V \longrightarrow \mathbb{R} $  beschreibt die Gewichte des Neuronalen Netzes. Wobei w(i,j) das Gewicht zwischen dem Neuron i und Neuron j beschreibt. Im Allgemeinen wird anstatt der Funktionsnotation die Notation $w_{i,j}$ für die Gewichte zwischen zwei Neuronen verwendet.  \cite{Kriesel2007NeuralNetworks} Die nächste wichtige Komponente ist die Propagierungsfunktion $net_{j}$  eines Neurons, welche einen wichtigen Teil des Informationsflusses in einem Neuronalen Netz definiert. Dabei wird der Input des Neurons j durch dessen Propagierungsfunktion $net_{j}$ bestimmt. Die Propagierungsfunktion $net_{j}$ nimmt den Output aller Neuronen welche eine ausgehende Verbindung zum Neuron j besitzen als Input.  So wird die Propagierungsfunktion $net_{j}$ durch folgenden funktionalen Zusammenhang beschrieben : 

\begin{equation}\label{eq:propagation_function}
 net_ { j } = \sum _ { i \in I_{j}} ( o _ { i }\cdot w _ { i , j }) \textrm{ mit } I_{j} = \{ i \epsilon N | (i,j) \epsilon V \}
\end{equation}

Der Output  $o_{j} $ eines Neuronen j wird mit Hilfe der Aktivierungsfunktion $a_{j}$ und der der Propagierungsfunktion berechnet. Dazu wird noch der Schwellwert $ \theta_{j} $ zur Hemmung des Aktivierungszustand des Neurons zur Hilfe genommen. Somit ergibt sich für den Output des Neurons folgender funktionaler Zusammenhang : 

\begin{equation}
o_{j} = a_{j}(net_{j} - \theta_{j}) = f(x)
\end{equation}

Die Wahl der Aktivierungsfunktion ist von Anwendungsfall von Anwendungsfall unterschiedlich. In den meisten Fällen werden differenzierbare Aktivierungsfunktionen benutzt, da sie den Lernprozess, des neuronalen Netzes erleichtern. Das erste Beispiel für eine Aktivierungsfunktion ist die Heaviside-Funktion(Step-Funktion), welche auf 0 oder 1 abbildet(Abbildung \ref{fig:activations}a). Diese Funktion ist an der Stelle 0 nicht differenzierbar und im generellen für moderne Optimierungsansätze für neuronale Netze nicht geeignet, da die Ableitung der Step-Funktion an allen Stellen 0 ist. Beispiel für gängige und differenzierbare Funktionen sind die Sigmoid-(Abbildung \ref{fig:activations}b, Formel \eqref{eq:sigmoid}), Tangens Hyperbolicus-(Abbildung \ref{fig:activations}c, Formel \eqref{eq:tanh}) und die Rectified Linear Units- Aktivierungsfunktion(Abbildung \ref{fig:activations}d, Formel \eqref{eq:relu})

\begin{equation}\label{eq:sigmoid}
f(x)= \frac { 1 } { 1 + e ^ { - x } }
\end{equation}

\begin{equation}\label{eq:tanh}
f(x)= tanh(x) = 1 - \frac { 2 } { \mathrm { e } ^ { 2 x } + 1 }
\end{equation}

\begin{equation}\label{eq:relu}
f(x)= max(0,x)
\end{equation}

\begin{figure}[hh]
	\subfigure[Heavisidefunction]{\includegraphics[width=0.5\textwidth]{images/step.png}}
    \subfigure[Sigmoid]{\includegraphics[width=0.5\textwidth]{images/sigmoid.png}} 
     \subfigure[Tanh]{\includegraphics[width=0.5\textwidth]{images/tanh.png}} 
    \subfigure[Relu]{\includegraphics[width=0.5\textwidth]{images/relu.png}} 
    \caption{Übersicht Aktivierungsfunktionen, Bildquelle:  \cite{Kriesel2007NeuralNetworks}}
\label{fig:activations}
\end{figure} 

Jeder der genannten Aktivierungsfunktion hat auf Hinsicht seiner Berechnungsdauer, Wertebereich und Ableitung Vor- und Nachteile. Die Sigmoid und die Tangens Hyperbolicus  Aktivierungsfunktion haben einen eingeschränkten Wertebereich, dadurch kann es mit diesen Aktivierungsfunktionen zu keinen zu hohen Werten im Neuronalen Netz kommen und negative Werte werden im Gegensatz zu ReLu noch berücksichtigt. Jedoch sind beide langsamer zu berechnen als die Rectified Linear Units und bieten für den Lernprozess kleinere Gradienten. Rectified Linear Units(ReLu) ist im Vergleich zu Sigmoid und Tangens Hyperbolicus schneller zu berechnen und bietet größere Gradienten. Jedoch können Neuronen, welche einen negativen Input bekommen nur noch 0 Ausgeben. Man spricht in diesem Zusammenhang von einem totem Neuron. Ein weiterer Nachteil von ReLu ist der Wertebereich,denn dieser ist nicht eingeschränkt. Somit können im Neuronalen Netz sehr große Werte entstehen, welche den Wertebereich von Zahlenstandards wie zum Beispiel 32 Bit Float überschreiten und somit kein valider Datenfluss im Neuronalen Netz gegeben ist. 

\subsection{Feed-Forward-Neuronal  Networks}
Für ein Neuronales Netzwerk werden verschiedene Netzwerktopologien verwendet. Ein Beispiel dafür ist das Feed Forward Neuronal Network. Bei einem Feed Forward Neuronal Network werden die Neuronen als Schichten angeordnet. Diese Schichten sind miteinander verbunden. Dabei ist die Erste Schicht, welche die Input Daten bekommt, wird als Input-Layer bezeichnet. Und die letzte Schicht, welche die Netzberechnung ausgibt, als Output-Layer bezeichnet. Schichten, welche sich zwischen Input- und Output-Layer befinden und somit keinen Kontakt nach Außen haben, werden als Hidden Layer bezeichnet. Ein wichtiges Merkmal von Feed Forward Networks ist, dass der Datenfluss geradlinig ohne Rückkopplung von Input-Layer über die Hiddenlayer bishin zum Output-Layer verläuft. 

\begin{figure}[hh]
\centering
\includegraphics [scale=0.4]{images/feed_forward_neuronal_network.png}
\caption{Beispielhafte Darstellung für ein Feed-Forward-Neuronal-Network. Bildquelle: \cite{COMPMETHODS}}
\label{fig:ffnn}
\end{figure}



\subsection{Lernprozess}


\chapter{Simulation}
\section{Motivation}
\section{Simulationsbeschreibung}
\subsection{Gitterbeschreibung}
\subsection{Simulation des Detektorinputs}
\subsection{Simulation der Detektoreigenschaften}

\chapter{Datenbasis}
\section{Generator}
	\subsection{Aufbau}
	\subsection{Wahl der Eingangsparameter}
\section{Training-, Validation- und Testdatensatz}

\chapter{Neuronales Netz}
\section{Architektur}
\section{Lossfunction}
\section{Optimizer}

\chapter{Ergebnisse und Diskussion}
	\section{Lernprozess}
	\section{Ergebnisse und statistische Auswertung}
	\section{Fazit}
	
\end{document}