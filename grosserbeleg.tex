\documentclass[hyperref,german,beleg]{cgvpub}
\usepackage{subfigure}
\usepackage{pdfpages}
\usepackage{array}
\usepackage{listings}
%weitere Optionen zum Ergänzen (in eckigen Klammern):
% 
% female	weibliche Titelbezeichnung bei Diplom
% bibnum	numerische Literaturschlüssel
% final 	für Abgabe	
% lof			Abbildungsverzeichis
% lot			Tabellenverzeichnis
% noproblem	keine Aufgabenstellung
% notoc			kein Inhaltsverzeichnis
% twoside		zweiseitig
\author{Patrick Stiller}
\title{Parameterrekonstruktion für Röntgen-Kleinwinkelstreuung mit Deep Learning}
\birthday{8. Januar 1994}
\placeofbirth{Dresden}
\matno{3951290}
\betreuer{Dr. Dmitrij Schlesinger(TU Dresden), Dr. Heide Meißner(HZDR), Dr. Michael Bussmann(HZDR)}
\bibfiles{literatur}
\problem{\includepdf[pages=-]{Aufgabenstellung.pdf}}
\copyrighterklaerung{Hier soll jeder Autor die von ihm eingeholten
Zustimmungen der Copyright-Besitzer angeben bzw. die in Web Press
Rooms angegebenen generellen Konditionen seiner Text- und
Bild"ubernahmen zitieren.}
\acknowledgments{Die Danksagung...}
\begin{document}

\chapter{Einleitung}

\chapter{Grundlagen}

\section{Physikalischer Hintergrund}

\subsection{Kleinwinkelstreuung}
Die Kleinwinkelstreuung in Englisch Small Angle X-Ray Scattering (SAXS) ist eine universelle Technik zur Untersuchung von Feststoffen. Dabei kann SAXS Informationen über die kristalline Struktur, chemische Komposition und die physikalische Eigenschaften eines untersuchten Feststoffes liefern \cite{THEORYSAXS}. Die Untersuchung von Feststoffen unter Einfluss von Hochintensitätslasern ist ein Schwerpunkt der heutigen Physik. Wissen über das Verhalten von Feststoffen unter Einfluss von Hochintensitätslasern kann offene Fragen in der Krebsforschung und in der Astrophysik beantworten. Dieser große Beleg bezieht sich auf die Publikation von Thomas Kluge, welche 2018 mit dem Titel:\grqq Observation of ultrafast solid-density plasma dynamics using femtosecond X-ray pulses from a free-electron laser\grqq veröffentlicht wurde. In der angesprochenen Publikation wurde SAXS für die Untersuchung von Plasma eingesetzt \cite{SAXS18}. Bisher konnte die Plasmadynamik, welche bei der Interaktion eines Feststoffes und eines Hochintensitätslasern entsteht, nur durch Simulationen erfasst werden mit Hilfe von SAXS gibt es neue Möglichkeiten, die Laser-Plasma-Interaktion auf einem Feststoff zu charakterisieren. SAXS erreicht außerdem eine räumliche Auflösung im Femtosekunden-Bereich und eine zeitliche Auflösung im Nanosekunden-Bereich. Mit SAXS ist es möglich anhand der Einstrahlung auf den Detektor mit Hilfe von numerischen Simulationen Aussagen über die Elektronendynamik im Plasma zu treffen \cite{SAXS18}.
 
\begin{figure}[ht]
	\centering
		\includegraphics [scale=0.5]{images/saxs_setup.png}
	\caption{Links: Schematischer Aufbau des Experimentaufbaus. Rechts: der Abbildung sind Detektorbilder in Abhängigkeit der 					Bestrahlungsdauer des Hochintensitätslasern dargestellt. Bildquelle: \cite{SAXS18}}
	\label{fig:saxssetup}
\end{figure}

\subsection{Experimentbeschreibung} \label{Experiment}

Das in \cite{SAXS18} beschriebene Experiment besteht aus vier Hauptkomponenten (siehe Abbildung \ref{fig:saxssetup} links): Dem Target(Mitte), dem Hochintensitätslasern (UHI) (Links), dem Röntgen-Freie-Elektronen-Laser (XFEL) (Links Unten) und dem Detektor (Rechts Oben). Der Hauptbestandteil des Targets ist Kupfer. Um eine analytische Beschreibung des Experimentausgangs zu ermöglichen, wurde eine Gitterstruktur in das Kupfertarget eingraviert. Zusätzlich wurde das Taget mit einer 2 $\mu$m breiten Siliziumschicht überzogen. Durch die eingravierte Gitterstruktur besitzt das Target einen eindimensionalen Informationsgehalt und kann somit durch drei Parameter vollständig beschrieben werden. Die drei Paramter sind Pitch, Feature-Size und die Aufweichungsbreite Sigma($ \sigma $). Dabei beschreiben Pitch und Feature-Size die Struktur des Targets und Sigma($ \sigma $) den Aufweichungseffekt des Hochintensitätslasers (siehe Abbildung \ref{fig:grating_structure}). Die Gesamtheit des Targets wird auch als Grating bezeichnet. Erhebungen des Gratings werden als Features bezeichnet. Im weiteren Verlauf dieser Arbeit wird der Begriff Elektronendichteverteilung $\eta$ verwendet, welcher oft im Zusammenfang des SAXS-Ansatzes fällt. Der Begriff Elektronendichteverteilung $\eta$ wird in dieser Arbeit als Synonym für das Grating verwendet. 

\begin{figure}[hh]
	\centering
		\includegraphics [scale=0.5]{images/grating_structure.png}
	\caption{Analytische Beschreibung des Querschnittes des Targets. Dabei ist das Grating zu erkennen und dass es durch drei Parameter: Pitch, Feature-Size und Sigma beschrieben werden kann. Bildquelle: \cite{Zach17}}
	
	\label{fig:grating_structure}
\end{figure}
Während des Experiments wird das Target durch einen Hochintensitätslasers in einem Winkel von 90° beschossen. Augrund des elektrischen Feldes des Lasers entsteht Plasma. Bei Plasma handelt es sich um ein Gemisch aus freien Elektronen, positiven Ionen und neutralen Teilchen, welche unter ständiger Wechselwirkung miteinander und mit Photonen stehen. Dadurch kann es zu unterschiedlichen Energie- bzw. Anregungszuständen kommen. Der Plasmazustand eines Stoffes wird auch als vierter Aggregatzustand bezeichnet \cite{PLASMADEF}. Während des Beschusses durch den Hochintensitätslasers ist außerdem ein Schmelzprozess und somit eine Aufweichung der Gitterstruktur des Targets wahrzunehmen (siehe Abbildung \ref{fig:melting_grating}). Das durch den Hochintensitätslasers erzeugte Plasma soll auf seine Struktur und Elektrodynamik mit Hilfe von SAXS untersucht werden. Dafür wird leicht zeitversetzt ein zweiter Laser benutzt. Dabei handelt es sich um einen Röntgen-Freie-Elektronen-Laser, welcher in einem Winkel von 45° mit einer Pulsdauer von 40 Femtosekunden auf das Target schießt. Bei diesem Vorgang kommt es zu einer Streuung des Lichts des Röntgenlasers an den Elektronen des Targets. Die Lichtintensitäten des gestreuten Röntgenlasers werden durch einen Detektor, welches hinter dem Target platziert ist, gemessen (Abbildung \ref{fig:saxssetup} links). 

\begin{figure}[hh]
\centering
\includegraphics [scale=0.7]{images/melting_grating.png}
\caption{Veränderung des Gratings nach einer Bestrahlungsdauer von 60 Femtosekunden Bildquelle: \cite{SAXS18}}
\label{fig:melting_grating}
\end{figure}

Beim Detektor handelt es sich um ein Raster von Lichtdetektoren, welche die ankommenden Lichtintensitäten messen. Dabei integriert der Detektor über die Zeit, das heißt, dass ankommende Lichtintensitäten über die Zeit summiert werden. Dieser Effekt ist in der Abbildung \ref{fig:electron_scattering} zu erkennen, welche einen beispielhaften Streuprozess an zwei Elektronen zeigt. 

\begin{figure}[hh]
	\centering
		\includegraphics [scale=0.4 ]{images/electron_scattering.png}
	\caption{Beispielhafte Darstellung einer Streuung an zwei Elektronen. Die Röntgenlaserpulse treffen geradlinig auf die Elektronen und werden dann bei den Elektronen gestreut. Der Detektor dahinter misst die ankommenden Intensitäten der kreisförmigen Wellen und summiert diese über die Zeit.  Bildquelle: \cite{Zach17}}
\label{fig:electron_scattering}
\end{figure}

Durch die Zeitintegration des Detektors, gehen die zeitlichen Abstände der Wellen verloren (Phase). Das entstandene Detektorsignal skaliert mit dem  Betragsquadrat der Fouriertransformation der Gitterstruktur $\eta $ (siehe Gleichung \eqref{eq:xrayscattering}) \cite{SAXS18}.


\begin{equation}\label{eq:xrayscattering}
\Phi  \propto | \int \eta (\vec r) \cdot e^{i\vec q \vec r} d \vec r|^2
\end{equation}


\section{Problemidentifikation }
Eine der Herausforderungen des beschriebenen Experimentes ist die Zeitintegration des Detektors. Diese Detektoreigenschaft ruft den Verlust der Phase hervor, sodass eine Rekonstruktion der Elektronendichteverteilung $ \eta $ mit Hilfe einer inversen Fouriertransformation (IFT) nicht möglich ist. Um dieses Problem zu lösen, werden iterative Algorithmen, sogenannte Phaseretrieval-Algorithmen verwendet. Beispiele für solche Algorithmen sind \cite{Fienup:82}: Error-Reduction Algorithm, Gradient Search Methods und der Input-Output Algorithmus. Probleme bei diesen Algorithmen sind, dass erstens bei allen Algorithmen keine Konvergenz garantiert ist und zweitens sehr viele Iterationen notwendig sind um eine Optimierung der errechneten Phase zu erzeugen. Diese Eigenschaften führen dazu, dass eine hochfrequente Verarbeitung von Experimentergebnissen verwehrt bleibt. Deswegen soll mit Hilfe von Deep Learning die Charakterisierung der Elektronendichteverteilung $ \eta $ (Parameter zur Beschreibung der Gitterstruktur) rekonstruiert werden. Neuronale Netze haben den Vorteil, dass sie sich im Gegensatz zu iterativen Verfahren parallelisieren und durch GPUs beschleunigen lassen und die Parameter der Elektronendichtenverteilung nicht-iterativ bestimmt werden (Einschrittverfahren). 

\section{Fouriertransformation}
Die Fouriertransformation (benannt nach Jean Baptiste Joseph Fourier) ist eine Transformation, welche zeitbezogene Wellen im Ortsraum in ihre frequenzmä\ss igen Spektralanteile zerlegt (Abbildung \ref{fig:fourier_example}). Die Fouriertransformation wird auch als Transformation vom Orts- in den Frequenzraum bezeichnet. Die Fouriertransformation F(u) einer Welle f(x) ist folgendermaßen definiert:

\begin{equation}\label{eq:fourier-series}
F ( u ) = \int _ { - \infty } ^ { \infty } f ( x ) e ^ { - 2 \pi i x u } d x
\end{equation}


Die Spektralanteile \textit{F(u)} werden wie bei einem Basiswechsel durch ein Integral bestimmt. Dabei ist das Ergebnis des Integrals die Länge der Projektion in Richtung der durch $ u $ kodierten Frequenz. Im endlich-diskreten Fall wird das Integral durch eine Summe bis zur Anzahl der zu verwendeten Wellen ersetzt.  Jede Stelle u der Fouriertransformation kodiert eine Welle $e ^ { - 2 \pi i x u }$, welche über die Euler-Identität $e ^ { i k x } = \cos ( k x ) + i \cdot \sin ( k x )$ auch in ihren Kosinus- und Sinusanteilen beschrieben werden kann. Der Funktionswert der Fouriertransformation \textit{F(u)} kodiert mit welchem Anteil die durch \textit{u} kodierte Frequenz verwendet wird. Das Ergebnis der Fouriertransformation kann auch durch das Amplituden- und durch das Phasenspektrum beschrieben werden.. Dabei bestimmt die Amplitude das Maximum und das Minimum der jeweiligen Welle und die Phase die Verschiebung der jeweiligen Welle.  Um die Amplituden- $| F ( u ) | $ und die  Phaseninformation $\phi ( u )$ einer komplexen Zahl $ u $ zu errechnen, werden folgende Gleichungen verwendet \cite{FOURIER2}:

\begin{equation}
| F ( u ) | = \sqrt { R ^ { 2 } ( u ) + I ^ { 2 } ( u ) }
\end{equation}

\begin{equation}
\phi ( u ) = \tan ^ { - 1 } \frac { I ( u ) } { R ( u ) }
\end{equation}


\section{Filter}

Ein Filter ist eine Operation, welche auf einem Signal verwendet wird, um Signale zu glätten, Signalstörungen zu vermeiden, oder um Rauschen zu verhindern. In den meisten Fällen wird die Filteroperation mit Hilfe von Faltung realisiert. Die Faltung zweier Funktionen $(f * g)$ durch den funktionalen Zusammenhang in Formel \eqref{eq:convolution} beschrieben. Dabei ist $f$ die Funktion, welche das Signal beschreibt und $g$ die Funktion, welche den Filter beschreibt. Im diskreten Fall wird das Integral durch eine Summe bis zur entsprechenden Filtergröße ersetzt \cite{CONV}. 

\begin{equation}\label{eq:convolution}
( f * g ) ( x ) : = \int _ { \mathbb { R } ^ { n } } f ( \tau ) g ( x - \tau ) \mathrm { d } \tau
\end{equation}



\section{Neuronal Networks}
Neuronal Networks sind eine mathematische Adaption des realen menschlichen Gehirns. Wie im realen menschlichen Gehirn sind Neuronen miteinander verbunden, um einen Informationsfluss zu gewährleisten. Die ersten Ansätze für neuronale Netze wurden bereits 1943 von Warren McCulloch und Walter Pitts entwickelt \cite{Kriesel2007NeuralNetworks}. Heute sind Neuronale Netze der Schwerpunkt des Machine Learnings und werden auf großen Datenmengen angewendet, um ein gewünschtes Verhalten zu trainieren . 

\subsection{Aufbau}
Ein Neuronal Network besteht aus vielen kleinen Komponenten, Neuronen, welche durch gerichtete und gewichtete Verbindungen verbunden sind.  Sämtliche Beschreibungen und Notationen beziehen sich auf \cite{Kriesel2007NeuralNetworks}. Mathematisch definiert ist ein Neuronal Network als ein Tripel $(N,V,w)$ mit den Beiden Mengen $N$ und $V$ und der Funktion $w$.  $N$ ist die Menge aller Neuronen und $V$ = $\{ (i,j) |  i, j \epsilon \mathbb{N}\}$ die Menge der Verbindungen zwischen Neuron i und Neuron j. Die Funktion $w : V \longrightarrow \mathbb{R} $  beschreibt die Gewichte des Neuronalen Netzes. Wobei w(i,j) das Gewicht zwischen dem Neuron i und Neuron j beschreibt. Im Allgemeinen wird anstatt der Funktionsnotation die Notation $w_{i,j}$ für die Gewichte zwischen zwei Neuronen verwendet. Die nächste wichtige Komponente ist die Propagierungsfunktion $net_{j}$  eines Neurons, welche einen wichtigen Teil des Informationsflusses in einem Neuronalen Netz definiert. Dabei wird der Input des Neurons j durch dessen Propagierungsfunktion $net_{j}$ bestimmt. Die Propagierungsfunktion $net_{j}$ nimmt den Output aller Neuronen welche eine ausgehende Verbindung zum Neuron j besitzen als Input.  So wird die Propagierungsfunktion $net_{j}$ durch folgenden funktionalen Zusammenhang beschrieben : 

\begin{equation}\label{eq:propagation_function}
 net_ { j } = \sum _ { i \in I_{j}} ( o _ { i }\cdot w _ { i , j }) \textrm{ mit } I_{j} = \{\ i \ \epsilon \  N\ |\ (i,j) \  \epsilon \  V\ \}
\end{equation}

Der Output  $o_{j} $ eines Neurons $j$ wird mit Hilfe der Aktivierungsfunktion $a_{j}$ und der der Propagierungsfunktion  $net_{j}$  berechnet. Dazu wird noch der Schwellwert $ \theta_{j} $ zur Hemmung des Aktivierungszustandes des Neurons zur Hilfe genommen. Somit ergibt sich für den Output des Neurons folgender funktionaler Zusammenhang: 

\begin{equation}
o_{j} = a_{j}(net_{j} - \theta_{j}) = f(x)
\end{equation}

In den meisten Fällen werden differenzierbare Aktivierungsfunktionen benutzt, da sie den Lernprozess des neuronalen Netzes erleichtern. Für diesen Beleg ist die Rectified Linear Units- Aktivierungsfunktion (Formel \eqref{eq:relu}) relevant.


\begin{equation}\label{eq:relu}
f(x)= max(0,x)
\end{equation}

Die ReLu-Aktivierungsfunktion ist im Vergleich anderen Aktivierungsfunktionen schneller zu berechnen und bietet größere Gradienten. Jedoch können Neuronen, welche einen negativen Input bekommen nur noch 0 Ausgeben. Es wird in diesem Zusammenhang von einem gestorbenen Neuron gesprochen. Ein weiterer Nachteil der ReLu-Aktivierungsfunktion ist der Wertebereich, denn dieser ist nach oben nicht eingeschränkt. Somit können in einem Neuronalen Netz sehr große Werte entstehen, welche den Wertebereich von Zahlenstandards wie zum Beispiel IEEE 754 (Single Precision Float 32-Bit) \cite{IEEE754} überschreiten, womit kein valider Datenfluss im Neuronalen Netz gegeben ist. 

\subsection{Feed-Forward Neuronal  Networks}
Für ein Neuronal Network können verschiedene Netzwerktopologien werden. Ein Beispiel dafür sind Feed Forward Neuronal Networks (Abbildung \ref{fig:ffnn}).Bei einem Feed Forward Neuronal Network werden die Neuronen als Schichten (Layer) angeordnet. Diese Layer sind miteinander verbunden. Die erste Layer, welche die Input Daten bekommt, wird als Input-Layer bezeichnet. Die letzte Schicht, welche die Netzberechnung ausgibt, wird als Output-Layer bezeichnet. Schichten, welche sich zwischen Input- und Output-Layer befinden und somit keinen Kontakt nach Außen haben, werden als Hidden Layer bezeichnet. Ein wichtiges Merkmal von Feed-Forward Neuronal Networks ist, dass der Datenfluss geradlinig  vom Input-Layer über die Hidden-Layer zum Output-Layer ohne Rückkopplung verläuft. Eine wichtige Komponente von Feed-Forward Neuronal Networks sind die Fully-Connected Layer. Bei einem Fully-Connected Layer ist jedes Neuron des Fullyconnected Layer mit jedem Neuron des vorherigen Layers verbunden. In Abbildung \ref{fig:ffnn} sind die Verbindungen eines Fully-Connected Layer dargestellt.  

\begin{figure}[hh]
\centering
\includegraphics [scale=0.4]{images/feed_forward_neuronal_network.png}
\caption{Beispielhafte Darstellung eines Feed-Forward Neuronal Networks. Bildquelle: \cite{COMPMETHODS}}
\label{fig:ffnn}
\end{figure}

\subsection{Lernprozess}
Das Anlernen von Neuronalen Netzen wird in den meisten Fällen durch überwachtes Lernen (supervised Learning) realisiert. Im Speziellen wird der Lernprozess durch den Backpropagation-Algorithmus und Gradientenabstiegsverfahren durchgeführt. Bei einem überwachten Lernansatz besteht der Datensatz zum Trainieren des Neuronalen Netzen aus zwei Teilen. Zu jedem Netzinput $x_{i}$ gibt es ein zugehöriges Label $y_{i}$, welches den gewünschten Netzoutput definiert. Der Lernprozess eines neuronalen Netzes kann in drei Phasen eingeteilt werden: Dem Forward-Pass, die Loss-Calculation und dem Backward Pass \cite{NeuronaleNetze}. Zu Beginn des Trainingsprozesses werden die Gewichte des Neuronalen Netzes mit Zufallszahlen initialisiert. In vielen Implementationen werden die Gewichte zufällig und normal verteilt initialisiert. Beim Forward Pass werden die Input-Daten zur Kalkulation des derzeitigen Netz-Outputs zum Input-Layer des Neuronalen Netzes gegeben. Das Neuronale Netz bestimmt dann durch die Rechenvorschriften des Neuronalen Netzes den Netz-Output $\hat { y } _ { i }$. Im zweiten Schritt wird die Qualität des Netz-Ouputs $\hat { y } _ { i }$ bestimmt.. Dazu wird ein Fehlermaß benutzt, das den Grad des Unterschiedes zwischen $\hat { y } _ { i }$ und $y_{i}$  bestimmt. Eine beispielhafte Errorfunktion ist Mean-Squared Error \eqref{eq:mse}. 


\begin{equation}\label{eq:mse}
\mathrm { MSE } = \frac { 1 } { n } \sum _ { i = 1 } ^ { n } \left( Y _ { i } - \hat { Y } _ { i } \right) ^ { 2 }
\end{equation}

Im dritten Schritt, dem Backward-Pass, kommt es zur Optimierung des Neuronalen Netzes. Mithilfe des Fehlers, welcher bis zur Eingabeschicht zurück propagiert wird, werden die Gewichte entsprechend ihres Einflusses auf den Net-Output \eqref{eq:gradient} mittels Gradientenabstiegsverfahrens angepasst. Für die Anwendung des Gradientenabstiegsverfahrens werden die partiellen Ableitungen des Fehlerterms benötigt. Die Gewichtsveränderung $\Delta w _ { i j }$ des Gewichts zwischen Neuron $i$ und Neuron $j$  ergibt sich durch folgenden funktionalen Zusammenhang : 

\begin{equation}\label{eq: deltaw}
\Delta w _ { i j } = - \eta \frac { \partial E } { \partial w _ { i j } } = - \eta \delta _ { j } o _ { i }
\end{equation}

Dabei ist \textit{E} die Errorfunktion, $\delta _ { j }$ des Gradient Neurons j,  $o _ { i }$ die Ausgabe des Neurons i. Der Parameter $\eta $ , welcher die Learning-Rate des Gradientenabstiegsverfahren bestimmt. Schlussendlich fehlt die Definition des Gradienten. Dieser ist davon abhängig, wie stark ein Neuron den Output des Neuronalen Netzes beeinträchtigt. Deswegen wird eine Unterscheidung getroffen, ob ein Neuron sich im Output-Layer oder dem Hidden- bzw. Input-Layer befindet. In der folgenden Gleichung \eqref{eq:gradient} ist die Definition des Gradienten und die zugehörige Propagierung des Fehlers. 


\begin{equation}\label{eq:gradient}
\delta _ { j } = \left\{ \begin{array} { l l } { a_{j}  \left( net_{ j } \right) \left( o _ { j } - t _ { j } \right) } & { \text { falls } j \text { sich in der Output-Layer befindet} } \\ { a_{j}  \left( net_{ j } \right) \sum _ { k } \delta _ { k } w _ { j k } } & { \text { falls } j \text { verdecktes Neuron oder ein Input-Neuron ist } } \end{array} \right.
\end{equation}

Dabei ist die Gleichung \eqref{eq:gradient} in Abhängigkeit von den Variablen $o_{j}$ , dem Output des Neurons j, $t_{j}$, die Soll-Ausgabe des Neurons $j$ und der Aktivierungsfunktion $a_{j} $ des Neurons $j$ angegeben. Somit ergibt sich das neue Gewicht durch eine Addition des alten Gewichts mit der errechneten Gewichtsveränderung. 

\begin{equation}
w _ { i j } ^ { \text { neu } } = w _ { i j } ^ { \text { alt } } + \Delta w _ { i j }
\end{equation} 

Der Backpropagation-Algorithmus wird iterativ solange angewandt, bis eine bestimmte Anzahl von Iterationen erreicht ist oder andere Kriterien erfüllt sind \cite{wiki:Backpropagation}.

\subsection{Convolutional Neuronal Networks} \label{CNN}
Klassische Neuronal Networks besitzen die Einschränkung, dass deren Inputs als Vektoren geliefert werden müssen. Soll ein klassisches Neuronal Network zum Beispiel ein Bild der Größe $N   \times M \times C$ (C steht für Kanäle) verarbeiten, muss das Bild in einen Vektor der Größe $ N * M * C $ transformiert werden (Flatten). Convolutional Neuronal Networks (CNNs) besitzen im Gegensatz zu klassischen Neuronal Networks Convolutional Layer, und können somit Inputs höherer Dimension verarbeiten. Dazu sind die Neuronen als Filter $k$ der Größe $ H \times  W \times D $ (Höhe Breite,Tiefe) angeordnet. In diesem Kapitel wird von einem Filter mit quadratischer Grundfläche ausgegangen ($ H = W$). Zur Berechnung des Layer-Outpus führt ein Filter $k$ an einer Position $(x,y)$ des Inputs $I$  eine zweidimensionale diskrete Faltung \eqref{eq:2Dconv} \cite{2DCONV} durch und berechnet somit einen Datenpunkt der Feature-Map $I ^{*} $ (Ergebnis eines Filters des Convolutional Layers).  Der Parameter $a$ in der Faltungsformel \eqref{eq:2Dconv} steht für die Koordinate des Mittelpunktes des Filters. Ist der Filter die Grundfläche des Filters zum Beispiel $5 \times 5$, so ist der Wert von $a$ drei \cite{cnn_basics}.


\begin{equation}\label{eq:2Dconv}
 	I ^ { * } ( x , y ) = \sum _ { i = 1 } ^ { H} \sum _ { j = 1 } ^ { W } I ( x - i + a , y - j + a ) k ( i , j )
\end{equation}

Zur Berechnung des nächsten Datenpunktes der Feature Map $I ^{*} $ wird der Filter um eine Schrittweite   (\textit{stride}) auf dem Input  verschoben. Sollte für die Berechnung von $ I ^ { * } ( x , y )$ Datenpunkte benötigt werden, welche über den Rand des Inputs hinaus liegen, müssen diese Punkte auf eine andere Weise bestimmt werden. Eine mögliche Strategie ist das vernachlässigen dieser Punkte, was je nach Größe des Filters eine Verkleinerung der Feature-Map $I ^ { * }$ zur Folge hätte. Die zweite mögliche Strategie, welche die fehlenden Datenpunkte zur Verfügung stellt, ist das Zero-Padding , welches die fehlenden Datenpunkte mit dem Wert Null ersetzt. Außerdem besteht als dritte Möglichkeit, dass die fehlenden Datenpunkte mit dem dazugehörigen Randwert ersetzt wird \cite{ZeroPadding} . 

Nach Ausführung der Faltung wird die errechnete Feature-Map durch eine ausgewählte Aktivierungsfunktion verarbeitet. Ein Convolutional-Layer besteht nicht nur aus einem Filter, sondern kann mehrere Filter enthalten. Für jeden Filter wird die vorher beschriebene Faltung separat ausgeführt und die entstandenen Feature-Maps werden konkateniert. Somit ergibt sich für den Output eines Convolutional-Layer mit einer Stride von 1, Zero-Padding und 32 Filtern eine Dimension von $(N, M, 32)$. In einem Convolutional Neuronal Network können dann beliebige viele Layer hintereinander platziert werden. Zur Verarbeitung des letzten Convolutional Layers wird in den meisten Fällen die letzte Layer in einen Vektor transformiert, um  durch ein Fully-connected Layer weiterverarbeitet werden zu können (siehe Abbildung \ref{fig:cnn_archtitecture}. 

\begin{figure}[hh]
\centering
\includegraphics [scale=0.7]{images/cnn_architecture.png}
\caption{Beispielhafte Darstellung eines Convolutional Neuronal Networks. Bildquelle: \cite{ZeroPadding}}
\label{fig:cnn_archtitecture}
\end{figure}

Für diesen Beleg sind aufgrund der Eindimensionalität der Input-Daten 1D-Convolutional-Layer relevant. Bei einem 1D-Convolutional Layer sind die Filter eindimensional, das heißt, dass die Filter eine Höhe ($H$) von 1 besitzen und der Filter nur entlang einer Dimension verschoben werden. 

\subsection{Residual Strukturen}
Wie in Kapitel \ref{CNN} beschrieben, können beliebig viele Convolutional Layers hintereinander platziert werden. Je mehr Layer verwendet werden, desto tiefer wird das Netz. Mit steigender Tiefe des Netzes erhöht sich das Problem kleiner werdender Gradienten  (Vanishing-Gradient Problem). Das Vanishing Gradient Problem ist auf die Eigenschaft der Backpropagation zurückzuführen, dass die Gradienten Neuronen-Gewichte in Abhängigkeit zu dessen Einfluss auf den Net-Output stehen. Bei tieferen Netzstrukturen verringert sich dieser Einfluss. Um den Einfluss der Neuronen auf den Net-Output zu erhöhen, werden Skip-Connections, auch Residual Strukturen, genannt. Dazu wird der Output eines Layers auf den Input z.B. der übernächsten Schicht addiert. Es sind auch Skip-Connections mit einer höheren Schrittweite möglich \cite{ResNet}.

\begin{figure}[hh]
\centering
\includegraphics [scale=0.5]{images/ResNet.png}
\caption{Realisierung einer Skip-Connection in einem Neuronal Network. Bildquelle: \cite{ResNet}}
\label{fig:cnn_archtitecture}
\end{figure}




\chapter{Simulation} \label{Simulation}
\section{Motivation}
Um das Ergebnis des SAXS-Experiments bestmöglich zu verstehen und aufgrund einer geringen Anzahl von Experimentdaten, wurde im Rahmen der Master-Arbeit von Malte Zacharias mit dem Titel \grqq Model-Driven Parameter Reconstruction from Small Angle X-Ray Scattering Images\grqq \  eine Modellierung entwickelt. Die Modellierung beinhaltet das Design der Gitterstruktur (Elektronendichteverteilung), die Modellierung des Hochenergielasereinflusses, die Modellierung des Streuvorgangs und die Modellierung des Detektorbildes. Das ganze Kapitel bezieht sich auf die Master-Arbeit von Malte Zacharias \cite{Zach17}. 

\section{Simulationsbeschreibung}
\subsection{Design der Gitterstruktur und Simulation des Hochenergielasereinflusses}
Wie in Kapitel 2 beschrieben sind die Targets des SAXS-Experiments als Gitter strukturiert, um eine analytische Beschreibung des Targets zu ermöglichen. Der erste Simulationsschritt ist die Bestimmung der Gitterstruktur. Die Breite des Gratings ist auf N Pixel beschränkt. Die Struktur des Gratings ist über die drei Startparameter Pitch, Feature-Size und Sigma definiert. Der Parameter Feature-Size legt die Breite eines Features fest und der Parameter Pitch bestimmt die Periodizität eines Features, womit beide Parameter für die Struktur des Gratings ohne Einfluss des Hochintensitätslasers verantwortlich sind. Der Parameter Sigma  $\sigma$ bestimmt die Aufweichungsbreite des Gratings und modelliert den Einfluss des Hochenenintensitätslasers. 

Der erste Schritt der Simulation ist die Modellierung eines Features mit Hochintensitätslasereinfluss. Dazu wird eine Rechteckfunktion (\( 1_{[0,\text{Feature-Size}]} \)), welche die Breite eines Features festlegt mit einer Gaussverteilung (\(\exp \left( - x ^ { 2 } / 2 \sigma ^ { 2 } \right) \)) gefaltet \cite{SAXS18}. Das Ergebnis der Faltung wird mit Hilfe der Errorfunktion (Gleichung \eqref{eq:erf}) dargestellt. 

\begin{equation}\label{eq:erf}
\text{erf(x)} = \frac{2}{\sqrt{\pi}} \int_{0}^{x} e^{-\xi^{2}}d\xi
\end{equation}

Das Ergebnis der Faltung des Rechteckimpulses und der Gauss-Verteilung ist die Modellierung eines Features:

\begin{equation}\label{eq:feature}
	\tilde{\eta} = \frac{\sqrt{\pi}\sigma}{2}(\text{erf}(\frac{x}{\sqrt{2}\sigma}) - \text{erf}(\frac{x - \text{fsize}}{\sqrt{2}\sigma}))
\end{equation}

Das modellierte Feature wird durch eine weitere Faltung mit mehreren um Pitch verschobenen Impulsen\cite{beucher_2011} periodisch fortgesetzt wird, um die Grating-Struktur zu komplettieren. 


\subsection{Effekt der Startparameter auf die Gitterstruktur}

Die drei Startparameter Sigma (\( \sigma\)), Pitch  und Feature-Size, welche die Struktur des Gratings beschreiben, haben unterschiedliche Effekte auf die Gratingstruktur. Sigma ist der Parameter, welcher, wie bereits beschrieben, den Einfluss des Hochenergielasers auf ein Feature modelliert. Je höher Sigma gewählt wird, desto mehr wird die Kantenstruktur des Targets aufgeweicht. In Abbildung \ref{img:edge_sigma} ist dieser Effekt dargestellt. 

\begin{figure}[hh]
\centering
\includegraphics[scale=0.30]{images/edge_sigma.png} 
\caption{Vergleich der Kantenstruktur unter variierenden Sigma-Werten bei gleichbleibenden Pitch- und Feature-Size- Werten}
\label{img:edge_sigma}
\end{figure}

Der Parameter Pitch bestimmt die Periodizität der Kantenstruktur.  Daraus folgt, dass mit steigendem Pitch-Wert die Anzahl der Features sinkt. Dieser Effekt ist in der Abbildung \ref{img:edge_pitch_fsize} in der rechten Spalte dargestellt. Der dritte Startparamter Feature-Size bestimmt die Größe der Features. Dabei kann die Feature-Size nicht größer als Pitch gewählt werden, da sonst keine Kantenstruktur mehr erkennbar wäre. Der Effekt der Feature-Size wird in Abbildung \ref{img:edge_pitch_fsize} in der linken Spalte dargestellt.


\begin{figure}[hh]
	\centering 
	\includegraphics[scale=0.35]{images/pitch_fsize_edge.png} 
	\caption{Vergleich der Kantenstruktur unter variierenden Pitch-Werten (rechte Spalte) und variierenden Feature-Size-Werten (linke Spalte)} 
	\label{img:edge_pitch_fsize}
\end{figure} 



\subsection{Simulation der Streuung}

Wie im Kapitel zur Experimentbeschreibung beschrieben, ist das aufgenommene Detektorbild äquivalent zum Betragsquadrat der  Fouriertransformation der Elektronendichte $\eta $.  Im Fall der Simulation ist die Elektronendichte eine diskrete eindimensionale Elektronendichteverteilung. Deswegen wird zur Bildung des Detektorbildes eine eindimensionale diskrekte Fouriertransformation  \eqref{eq:fft} verwendet.

\begin{equation}\label{eq:fft}
\hat { a } _ { k } = \sum _ { j = 0 } ^ { N - 1 } e ^ { - 2 \pi \mathrm { i } \cdot \frac { j k } { N } } {\eta} _{ k} \text { für } k = 0 , \ldots , N - 1
\end{equation}

Das entstandene Produkt der Fouriertransformation ist im Raum der Komplexen Zahlen und weist den gleichen Informationsgehalt wie die Elektronendichteverteilung auf. Das heißt die Amplituden- und Phaseninformationen sind nach wie vor vorhanden. Wie in Kapitel 1 beschrieben, ist der Detektor Zeit integrierend und die Phase geht verloren, weswegen wird die Phaseninformation im weiteren Simulationsverlauf nicht weiter verwendet. Um schlussendlich die aufgenommenen Intensitäten des Detektors (siehe Abbildung \ref{img:detector}) zu erhalten, wird das Betragsquadrat des Amplitudenspektrums gebildet ($ \Phi = | \hat { a } _ { k }| ^{2}$)

\begin{figure}[hh]
\centering
\includegraphics[scale=0.3]{images/endproduct.png} 
\caption{Resultierendes Detektorbild als Endprodukt der Simulation}
\label{img:detector}
\end{figure}

\subsection{Auswirkung der Startparameter auf das Simulationsergebnis}
Die Startparameter des Simulation haben ebenfalls Auswirkungen auf das Endprodukt der Simulation. In der Abbildung \ref{img:pitch_fsize_ratio} ist der Einfluss der Parameter Pitch und Feature-Size auf das Detektorbild dargestellt. Es ist zu erkennen, dass die Anzahl der Peaks ( Intensitäten größer 0) maßgeblich durch das Verhältnis von Pitch und Feature-Size bestimmt werden. Auch die maximale Intensität wird durch das Verhältnis von Pitch und Feature-Size beeinflusst. Des Weiteren ist zu beobachten, dass mit steigendem Pitch-Wert sich die Abstände der Peaks verkleinert. Erhöht man den Feature-Size-Wert ist zu erkennen, dass die Anzahl der Peaks sich verringert und die maximale Intensität steigt. Der Effekt des Feature-Size-Wertes kann ebenfalls im Plot in Abbildung \ref{img:fsize-max} beobachtet werden. Der letzte Startparameter Sigma hat mit steigenden Wert ähnliche Auswirkungen  auf die Detektoraufnahmen wie Feature-Size. Bei steigendem Sigma-Wert steigt das Intensitätsmaximum und die Anzahl der Peaks verringert sich. Jedoch skaliert der Parameter Sigma anders als Feature-Size. Kleinere Unterschiede im Sigma-Wert können größere Auswirkungen auf die Anzahl der Peaks haben. Auch der Anstieg des Intensitätsmaximums in Abhängigkeit zu Sigma ist geringer im Vergleich zur Abhängigkeit zu Feature-Size. Zusätzlich ist zu bemerken, dass es einen Schwellwert gibt, bis der Effekt von Sigma Auswirkungen auf die inneren Peaks hat.  Der Effekt von Sigma ist in Abbildung \ref{img:pitch_fsize_ratio} zu sehen. 

\begin{figure}[]
\centering
\includegraphics[width=0.85\textwidth]{images/pitch_fsize_ratio.png} 
\caption{Auswirkung der Parameter Pitch und Feature-Size auf das Detektorbild. In der Tabelle wurde der Pitch-Wert zeilenweise erhöht. In jeder Spalte wurde der Feature-Size-Wert in Relation zum Pitch-Wert geändert. 1.Spalte: $\frac{1}{8} $ Pitch, 2.Spalte: $\frac{1}{4} $ Pitch, 3.Spalte: $\frac{1}{2} $ Pitch}
\label{img:pitch_fsize_ratio}
\end{figure}

\begin{figure}[]
\centering
\includegraphics[width=0.85\textwidth]{images/sigma_fsize_ratio.png} 
\caption{Auswirkung der Parameter Feature-Size und Sigma auf das Detektorbild. In der Tabelle wurde der Feature-Size-Wert zeilenweise erhöht. In jeder Spalte wurde der Sigma-Wert in Relation zum Feature-Size-Wertt geändert. 1.Spalte: $\frac{1}{8} $ Feature-Size, 2.Spalte: $\frac{1}{4} $ Feature-Size 3.Spalte: $\frac{1}{2} $ Feature-Size}
\label{img:pitch_fsize_ratio}
\end{figure}\newpage


\begin{figure}[hh]
\centering
\includegraphics[width=0.7\textwidth]{images/fsize_maxintensity.png} 
\caption{Auswirkung des Feature-Size-Wertes auf die maximale Intensität im Detektorbild.}
\label{img:fsize-max}
\end{figure}


\subsubsection{Effekt von Sigma}
Wie in Kapitel \ref{Simulation} beschrieben, ergibt sich die Gitterstruktur des Gratings aus einer Faltung aus Gauss-Verteilung, Impulsverteilung und Rechteckimpuls. Diese Faltung wird dann fouriertransformiert um das Detektorbild. Eine wichtige Eigenschaft der Fouriertransformation $F$ ist, dass Fourier-Faltungs-Theorem, welches besagt, dass die Fouriertransformation einer Faltung äquivalent zum Produkt der Fouriertransformationen der Faltungsfunktionen ist (Gleichung \eqref{eq:fft_convolve})\cite{FOURIERDEF} .

\begin{equation}\label{eq:fft_convolve}
 F( f * g) = F(f) \cdot F(g)
\end{equation}

Das Fourier-Faltungs-Theorem kann dazu genutzt werden, den Effekt von Sigma auf das Detektorbild zu erklären. In Abbildung \ref{img:gaussian_fft} sind verschiedene Gauss-Verteilungen (linke Seite) und deren zugehörige Fouriertransformationen(rechte Seite) dargestellt. Hinweis: Alle Werte im FFT-Bild sind über 0.  Aufgrund des Fourier-Faltungstheorems kommt es zu einer Multiplikation mit den Gaussverteilungen. Die Multiplikation stärkt die   Intensitäten im zentralen Bereich und glättet die Intensitäten am Rand. Dieser Effekt ist ebenfalls in der Simulation zu beobachten (siehe Abbildung \ref{img:sigma_detector}). 

\begin{figure}[hh]
\centering
\includegraphics[width=\textwidth]{images/fft_gauss.png} 
\caption{Linke Seite: Gauss-Verteilungen mit unterschiedlichen Sigma-Werten Rechte Seite: Fouriertransformationen der Gauss-Verteilungen}
\label{img:gaussian_fft}
\end{figure}



\chapter{Datenbasis}
\section{Generator}
Um einen Machine-Learning-Ansatz auszuführen, muss eine ausreichend große Datenbasis existieren. Dazu wurde im Rahmen dieser Arbeit ein  Generator entwickelt, welcher mit Hilfe der vorher beschriebenen Simulation ausreichend viele Trainings-, Validierungs- und Testsdaten produzieren kann. Der erste Schritt der Genierierung der Datenbasis ist die Festlegung der Menge $P$ von Startparametern, wobei ein Startparamter ein Tripel (Feature-Size, Pitch, Sigma) ist. Um die Berechung der Simulationsdaten, welche aus P resultieren, zu beschleunigen wurde die Simulation aus Kapitel \ref{Simulation} mit Hilfe des Message Parsing Interfaces (MPI) parallisiert. MPI dupliziert auszuführenden Code auf N beliebige Prozesse, welche mit Hilfe von vordefinierten Routinen miteinander kommunizieren können \cite{MPI}. Wurde die Menge von Startparametern festgelegt, wird diese Menge über MPI-Routinen auf $N$ Prozesse aufgeteilt. Jeder Prozess führt für seine zugewiesene Menge von Startparametern die In Kapitel \ref{Simulation} beschriebene Simulation aus und schreibt deren Ausgabe als Dateien in den Speicher des Rechenclusters. Zusätzlich zum Simulationsergebnis wird die Menge der Startparameter, welche als Labels für das Training des Neuronal Networks vorgesehen sind, gespeichert. 
\begin{figure}[hh]
\centering
\includegraphics[scale=0.4]{images/generator_schema.png} 
\caption{Schematischer Aufbau des Generators}
\label{img:generator}
\end{figure}

\section{Wahl der Eingangsparameter}
Anhand der Auswertung der Simulation in Kapitel \ref{Simulation} sind Abhängigkeiten zwischen den Startparametern Pitch, Feature-Size und Sigma festzustellen. Um einen validen Datensatz zu erstellen, müssen diese Abhängigkeiten berücksichtigt werden.  Der erste Startparameter Pitch ist der  Parameter, welcher den Wertebereich der anderen beiden Parametern Feature-Size und Sigma signifikant bestimmt. Wie in Kapitel \ref{Simulation} bemerkt, bestimmt Pitch die Periodizität der Gitterstruktur. Um aussagekräftige Detektorausgaben zu produzieren, wurde festgelegt, dass jedes Target mindestens vier und maximal 32 Features besitzt. Das bedeutet im Umkehrschluss, dass bei einer festen Targetbreite von 2048 Pixeln sich ein minimaler Pitch-Wert bei 64 und der maximaler Pitch-Wert bei 512 Pixeln ergibt. Je nach Wahl des Pitch-Wertes, ergeben sich die Definitionsbereiche für Sigma und Feature-Size. Um zu kleine Features zu vermeiden, wurde der minimale Feature-Size-Wert auf 25 \% des Pitch-Wertes festgelegt. Für ausreichend große Abstände zwischen den Features, wurde der maximale Feature-Size-Wert auf 75 \% des Pitch-Wertes beschränkt. Nach der Bestimmung von Pitch und Feature Size kann der Definitionsbereich von Sigma festgesetzt werden. Der minimale Sigma-Wert ist auf $ 10^{-9} $ festgelegt, um Simulationsergebnisse ohne Hochintensitätslasereinfluss zu generieren. Zur Bestimmung des maximalen Sigma-Wertes ist der Abstand zwischen zwei Features notwendig. Der Abstand zwischen zwei Features ergibt sich aus Pitch - FeatureSize. Da der Aufweichungseffekt gleichmäßig auf das Feature wirkt, muss für den maximalen Sigma-Wert der Feature-Abstand halbiert werden. Um keine zu hohen Aufweichungseffekte zu erhalten, wurde die obere Grenze des Sigma Wertes auf (Pitch - Fsize) / 4 festgesetzt. Für die Umsetzung der voneinander abhängigen Wertebereichen, werden Folgen konstruiert, dessen Elemente zu Startparameter Tripeln konkateniert werden. Eine Beispielhafte Implementierung ist in der Abbildung \ref{code:P} zu sehen, welche jeweils eine Folge mit 64 Elementen (Anzahl der Prozessoren) erstellt.

\begin{figure}[htbp]\label{code:P}
\centering 
\begin{lstlisting}[frame=trbl][language=Python]
num_pitches = 64
num_fsizes = 64
num_sigmas = 64
for pitch in np.linspace(64, 512, num=num_pitches):
    for feature_size in np.linspace(0.25*pitch, 0.75*pitch, num=num_fsizes):
        for sigma in np.linspace(1e-9, (pitch-feature_size)/4, num=num_sigmas):
            add_to_P(sigma, pitch, feature_size, number))
\end{lstlisting}
\caption{Umsetzung der Definitionsbereiche mit Hilfe drei verschachtelter Schleifen, welche voneinander Abhängig sind}
\end{figure}


\section{Performance}
Die Erstellung der Datenbasis wurde auf dem Rechencluster Hypnos des Helmholtz Zentrums Dresden Rossendorf auf 64 AMD 16-Kern Opteron Prozessoren ausgeführt. Die Parallelisierung der Simulation hat einen großen Speedup zur Folge, so dass 100.000 Bilder in knapp zwei Stunden anstatt in ca. 50 h Stunden(* lineare Regression aus Rechenzeiten kleinerer Datensätze) generiert werden können. Diese kurze Rechendauer ermöglicht ein schnelleres Validieren und Korrigieren des erstellten Datensatzes. Die Rechenzeiten für kleinere Datensätze sind der Tabelle \ref{tab:generator} zu sehen. Bei kleineren Datensätzen ist der Speedup nicht signifikant, da durch die Parallelisierung ein Kommunikationsoverhead entsteht.
\begin{table}[hh]
\centering
\begin{tabular}{|l|l|l|l|l|}
\hline
            & 1 Bild    & 100 Bilder  & 1000 Bilder  & 100.000 Bilder   \\ \hline
sequentiell & 1,889 sek & 187,613 sek & 1870,095 sek & 186940,286 sek * \\
Generator   & 1,917 sek & 4,531 sek   & 42,831 sek   & 6900,243 sek   \\ \hline
\end{tabular}
\caption{\label{tab:generator} Vergleich der Berechnungsdauer für verschieden große Datensätze}
\end{table}

\section{Trainings-, Validierungs- und Testdatensatz}\label{Database}
Für das Training von Pitch, Feature-Size und Sigma stehen zwei verschiedene Datensätze zur Verfügung. Der erste Datensatz wurde für das Training des Neuronal Networks erstellt, welches Pitch schätzen soll.  Dieser Datensatz hat die Besonderheit, dass die Folge vom minimalen Pitch-Wert bis zum maximalen Pitch-Wert deutlich höher abgetastet ist, um dem Neuronal Network eine möglichst aussagekräftige Verteilung von Pitch-Werten und deren Auswirkung auf das Detektorbild zu geben. Die Feature-Size- und Sigma-Folgen wurden deutlich geringer abgetastet, jedoch steht aufgrund der verschachtelten Schleifen zur Generierung der Startparameter (Abbildung \ref{code:P}) eine ausreichend große Verteilung von Sigma und Feature-Size-Werten für das Training von Pitch zur Verfügung (Tabelle \ref{tab:label-distribution}). 

\begin{table}[ht]
\centering
\begin{tabular}{|l|c|c|c|}
\hline
Dataset                & Anzahl Pitch & Anzahl Feature-Size & Anzahl Sigma \\ \hline
Pitch                  & 368          & 23                  & 23           \\
Feature-Size und Sigma & 46           & 46                  & 46  \\ \hline
\end{tabular}
\caption{\label{tab:label-distribution} Abtastwerte für die jeweiligen Startparameter. Diese Werte werden wie in Abbildung \ref{code:P} verarbeitet}
\end{table}

Der Datensatz für das Training des Neuronal Networks weißt eine andere Verteilung wie der Pitch-Datensatz auf. In diesem Datensatz wurden die Folgen für Pitch, Sigma und Feature-Size gleich abgetastet, jedoch ist die Verteilung der Sigma- und Feature-Size-Werte aufgrund der Implementierung der Parametergenerierung deutlich ausgeprägter. In der Tabelle \ref{tab:label-distribution} sind die Abtastwerte der jeweiligen Folgen zu sehen. Für das Training, die Validierung des Trainingsprozesses und die Evaluierung des Neuronal Networks wurde der jeweilige Datensatz geshuffled und in Trainings, Validierung- und Test- Datensatz aufgespaltet. Um die Länge nicht zu groß zu gestalten, wurde der Trainingsdatensatz bei beiden Datensätzen auf 16384 Detektorbilder beschränkt. Für die Validierung stehen jedem Neuronal Network 64 Bilder zur Verfügung. Die restlichen Bilder wurde komplett für eine aussagekräftige Evaluierung verwendet. In Tabelle \ref{tab:traintestval} ist die Verteilung der Samples auf Trainings-, Validierungs- und Testdatensatz zu sehen. Aufgrund der höheren Abtastung von Pitch im Pitch-Datensatz (siehe Tabelle \ref{tab:label-distribution}) besitzt dieser mehr Detektorbilder und somit mehr Samples zum evaluieren. 

\begin{table}[hh]
\centering 
\begin{tabular}{|l|c|c|c|}
\hline
Datensatz              & \multicolumn{1}{l|}{Training} & \multicolumn{1}{l|}{Validation} & \multicolumn{1}{l|}{Test} \\\hline
Pitch                  & 16384                         & 64                              & 178224                    \\
Feature-Size und Sigma & 16384                         & 64                              & 80888      \\ \hline              
\end{tabular}
\caption{\label{tab:traintestval} Verteilung der Samples auf Trainings, Validierungs- und Testdatensatz}
\end{table}
\chapter{Lösungsansatz}\label{Ansatz}
In diesem Kapitel wird der Lösungsansatz für die Parameterrekonstruktion beschrieben. Dabei wird auf die Gesamtarchitektur, der konzeptionelle Aufbau der einzelnen Komponenten und auf den Aufbau der Neuronal Networks und deren Training eingegangen. 

\section{Gesamtarchitektur}
Wie in Kapitel \ref{Simulation} beschrieben, ergibt sich die Gitterstruktur des Targets aus einer Faltung von Impulsfunktion, Gauss-Verteilung und Rechteckfunktion. Laut Faltungstheorem, welches besagt, dass die Faltung zweier Funktionen durch die Fouriertransformation $\mathcal { F }$ in ein Produkt überführt wird, sind die Fouriertransformationen der einzelnen Komponenten der Faltung im Fourierbild vorhanden.
Aufgrund des Faltungstheorems wurde die Parameterkonstruktion als Zweischrittverfahren konstruiert. Die Architektur besteht aus zwei Neuronal Networks. Das erste Neuronal Network ist ein Convolutional Neuronal Network, welches versucht anhand des Detektorbildes den Pitch-Wert zu schätzen. Der geschätzte Pitch-Wert wird anschließend dafür genutzt die Impulsverteilung zu rekonstruieren. Dafür wird folgender funktionaler Zusammenhang verwendet: 

\begin{equation}
\delta_{pitch}(x) = \begin{cases}
1 & \text{\ für \ } x \text{\ mod \ } pitch = 0 \\
0 &  \text{\ sonst} 
\end{cases}
\end{equation}

Die generierte Impulsverteilung dient als Support für das zweite Neuronal Network (Fully Connected Neuronal Network), um eine genauere Schätzung des Feature-Size- und Sigma-Wertes zu ermöglichen. Dabei wird der durch das CNN erstellte Support mit dem Detektorbild konkateniert. Die Konkatenation zwischen Detekorbild und Support wird als Input für das Fully Connected Neuronal Network gegeben. In Abbildung \ref{img:complete_architecture} ist ein schematischer Aufbau des gesamten Architektur zu sehen. Der Output ist dabei nicht als Komponente zu betrachten, sondern nur als Verbindungsstück der Schätzungen der beiden Neuronal Networks. Aufgrund lokaler Änderung im Detektorbild bei verschiedenen Pitch-Werten wurde für die Schätzung des Pitch-Wertes ein CNN gewählt. Das Gegenteil ist bei unterschiedlichen Feature-Size- und Sigma-Werten der Fall, diese haben globale Auswirkung auf das Detektorbild. Deshalb wurde für die Schätzung des Feature-Size und Sigma-Wertes ein Fully Connected Neuronal Network gewählt.


\begin{figure}[hh]
\centering
\includegraphics[scale=0.5]{images/complete_architecture.png} 
\caption{Schematische Beschreibung der Gesamtarchitektur}
\label{img:complete_architecture}
\end{figure}
\section{Convolutional Neuronal Network}
\subsection{Bayes'sche Optimierung}
Das Finden der geeigneten Hyperparameter für ein Neuronales Netz ist eine große Herausforderung. Der Suchraum wird durch Zahlreiche Parameter wie Tiefe des Netzes, Anzahl der Filter, Größe der Filter usw. sehr groß. Ansätze wie Random- oder Gridsearch sind bekannte Ansätze für das Finden geeigneter Hyperparameter. Jedoch beziehen diese Ansätze die bisher evaluierten Hyperparameter nicht für die Wahl des als nächstes zu evaluierten Hyperparameters ein. In diesem Bezug ist eine Evaluierung das Training eines Neuronalen Netzes, welches unter festgelegten Hyperparametern erstellt wurde und dieses nach einem festgelegten Qualitätsmaß bewertet wurde. Im Gegensatz zu den eben erwähnten Optimierungsverfahren verfolgt die Bayes'sche Optimierung den Ansatz bereits evaluierte Hyperparametersätze in die Optimierung mit einzubeziehen. Die Grundidee der Bayes'schen Optimierung ist das Erstellen einer Wahrscheinlichkeitverteilung $p(L | \theta)$ mit $L$ derQualität eines Neuronal Networks, dass in Abhängigkeit eines Hyperparamtersatzes $\theta$ erstellt wurde. Zu Beginn der Bayes'schen Optimierung werden bereits bekannte Evaluierungspunkte verwendet oder ein festgelegter Hyperparametersatz evaluiert, um ein erstes Wahscheinlichkeitsmodell mit Hilfe der Maximum Likelihood-Methode \cite{Likelihood} zu erstellen. Das erstellte Wahrscheinlichkeitsmodell wird dann benutzt, um den nächsten Evaluierungspunkt aus dem definierten Suchraum zu bestimmen. Nach dessen Evaluierung wird erneut das Wahrscheinlichkeitsmodell angepasst und ein neuer Evaluierungspunkt gefunden. Dieser Prozess wird solange durchgeführt, bis eine bestimmt Anzahl von Iterationen erreicht wurde. Die genauere Beschreibung des Algorithmus kann \cite{BayesOptimization} entnommen. Um eine Bayes'sche Optimierung für das CNN vorzunehmen, wurde die Implementierung von Scikit-learn verwendet. Dabei wurden die Hyperparameter: Anzahl der Convolutional Layer, Anzahl der Filter pro Convolutional Layer, Filtergröße und die Learning-Rate des Optimizers über die Bayes'scher Optimierung gefunden. Die Bayes'sche Optmierung wurde durch den  Suchraum aus Tabelle \ref{tab:bayes} eingeschränkt. Ein Evaluierungschritt ist die Erstellung des CNN anhand des festgelegten Hyperparametersatzes, das Trainieren des CNNs mit 1024 Bildern über 3000 Epochen und die Bestimmung der Qualität. Als Qualitätsmaß wurde der beste erreichte Mean-Squared-Error auf dem Validationdatensatz verwendet. Insgesamt wurden 50 Evaluierungsschritte ausgeführt. Zusätzlich wurden Residual Strukturen mit einer Sprungweite von 2 dem erstellten CNN hinzugefügt. 

\begin{table}[]
\centering 
\begin{tabular}{|l|l|l|}
\hline
Variable   & Minimum & Maximum  \\ \hline
Learning-Rate               & 1e-15   & 1e-5    \\
Anzahl Convolutional Layer  & 3       & 12      \\
Filtergröße                 & 4       & 20      \\
Anzahl der Filter pro Layer & 16      & 64    \\ \hline
\end{tabular}
\caption{\label{tab:bayes} Definition des Suchraums für die Bayes'sche Optimierung}
\end{table}

\subsection{Architektur}

Das Ergebnis der Bayes'schen Optimierung ist ein CNN mit einem Block von Convolutional Layer. Die Größe des Blockes, die Anzahl der Filter und die Größe der Filter pro Convolutional Layer wurden durch die Bayes'sche Optmierung bestimmt. Nach dem Block von Convolutional Layers wurde zusätzlich ein Convolutional-Layer mit einem Filter und der Filtergröße 1 hinzugefügt. Dieser Layer hat eine Dimensionreduktion zu folge, um beim anschließenden Dense-Layer( Fully Connected Layer) nicht zu viele Verbindungen zu erzeugen. Zwischen dem Regressions-Layer und dem ersten Dense-Layer befindet sich ein weiterer Hidden-Layer, der eine weitere Dimensionreduktion erzeugt. Als letzte Layer wurde eine weitere Dense-Layer mit linearer Aktivierungsfunktion hinzugefügt. Die Entscheidung für eine lineare Aktivierungsfunktion wurde aus den Erfahrungen vorheriger Experimente getroffen. Wurde die Ausgabe-Layer mit einer ReLu-Aktivierungsfunktion versehen, starb das Output-Neuron während des Trainings frühzeitig und es wurden ausschließlich Pitch-Werte mit dem Wert 0 geschätzt. In Tabelle \ref{tab:cnn} ist die komplette Architektur des CNN's dargestellt. 

\begin{table}[hht]

\begin{tabular}{|l|l|c|c|c|l|}
\hline
Layer           & Input            & \multicolumn{1}{l|}{Anzahl Filter} & \multicolumn{1}{l|}{Filtergröße} & \multicolumn{1}{l|}{Anzahl der Neuronen} & Aktivierungssf. \\ \hline
1DConv          & Detektorbild     & 32                                 & 16                               & -                                        & ReLU                 \\
1DConv          & Layer 1          & 32                                 & 16                               & -                                        & ReLU                 \\
1DConv          & Layer 2 + Layer1 & 32                                 & 16                               & -                                        & ReLU                 \\
1DConv          & Layer3           & 32                                 & 16                               & -                                        & ReLU                 \\
1DConv          & Layer4 + Layer3  & 32                                 & 16                               & -                                        & ReLU                 \\
1DConv          & Layer5           & 32                                 & 16                               & -                                        & ReLU                 \\
1DConv          & Layer6 + Layer5  & 32                                 & 16                               & -                                        & ReLU                 \\
1DConv          & Layer7           & 32                                 & 16                               & -                                        & ReLU                 \\
1DConv          & Layer8 + Layer7  & 32                                 & 16                               & -                                        & ReLU                 \\
1DConv          & Layer9           & 32                                 & 16                               & -                                        & ReLU                 \\
1DConv          & Layer10          & 1                                  & 1                                & -                                        & ReLU                 \\
Dense           & Layer11          & -                                  & -                                & 64                                       & ReLU                 \\
Regression-Layer & Layer12          & -                                  & -                                & 1                                        & Linear            \\ \hline  
\end{tabular}
\caption{\label{tab:cnn} Architektur des Convolutionl Neuronal Networks}
\end{table}

\newpage
\section{Fully-Connected Neuronal Network}
Das Fully-Connected Neuronal Network besteht ausschließlich aus Dense-Layern. Die Aufgabe des Fully-Connected Neuronal Networks ist die Schätzung des Sigma- und Feature-Size-Wertes. Der erste Layer bekommt die Konkatenation des Detektorbildes und der Impulsverteilung, welche aus dem vom CNN geschätzten Pitch-Wert erstellt wurde, als Input. Die Architektur des  Fully-Connected Neuronal Networks wurde aus Zeitgründen nicht mit der Bayes'schen Optimierung optimiert, sondern aus Erkenntnissen mehrerer Experimenten gebildet. In Tabelle ist die Architektur des Fully-Connected Neuronal Networks dargestellt.

\begin{table}[hh]
\centering
\begin{tabular}{|l|c|c|c|}
\hline
Layer            & Input                            & Anzahl Neuronen & Aktivierungsfunktion \\ \hline
Dense-Layer      & (Detektorbild, Impulsverteilung) & 4096            & ReLu                 \\
Dense-Layer      & Layer1                           & 2048            & ReLu                 \\
Dense-Layer      & Layer2                           & 2048            & Relu                 \\
Dense-Layer      & Layer3                           & 64              & ReLu                 \\
Regression-Layer & Layer4                           & 2               & Linear              \\ \hline
\end{tabular}
\end{table}
\section{Training}
%TODO

% 2 Experimente für das Fully-Connected Neuronal Network 
% Tablle für die Experimente 
% Anzahl der Trainingsdaten
% Anzahl der Iterationen
% Validierung des Trainings 
% Umsetzung mit Tensorflow 

Das Training der beiden beschriebenen Neuronal Networks erfolgt getrennt. Als erstes wird der Schätzer des Pitch-Wertes trainiert(CNN), da dieser die Grundlage für das Training des Fully-Connected Neuronal Networks bildet. Anschließend wird der Schätzer für den Sigma- und Feature-Size-Wert trainiert. Für die Generierung der Impulsverteilung, welche für das Training des Fully-Connected Neuronal Networks benötigt wird, wird ein festes CNN verwendet. Das heißt, dass sich die Architektur bzw. die Gewichte des CNN's während des Trainings des Fully-Connected Neuronal Networks nicht verändern.

Für das Training beider Neuronal Networks wurde der Adam-Optimizer verwendet. Der Adam-Optimizer ist eine Erweiterung des klassischen Gradientenabstiegsverfahren. Der Adam-Optimizer verknüpft die Vorteile zwei weiterer bekannter Optimierungsverfahren: Adaptive Gradient Algorithm (AdaGrad) und Root Mean Square Propagation (RMSProp) \cite{AdamOptimizer}. Der Adaptive Gradient Algorithmus hat den Vorteil, dass er für jeden Parameter eine unterschiedliche Learning-Rate festlegt, dadurch ist es möglich kleinen Gradienten entgegenzuwirken \cite{Optimizer}\cite{AdamOptimizer}. Die Root Mean Square Propagation stellt ebenfalls für jede Variable unterschiedliche Learning-Rates bereit, jedoch werden diese Learning-Rates hinsichtlich des Trainingsverlaufs angepasst. Zum Beispiel können zu schnell propagierende Variablen durch eine geringere Learning-Rate ausgebremst werden \cite{Optimizer}\cite{AdamOptimizer}. 

Für jedes Neuronal Network steht wie in Kapitel \ref{Database} eine eigene Datenbasis zu Verfügung, welche mit Hilfe von Batch-Processing trainiert wurde. Beim Batch-Processing werden dem Neuronal Network mehrere Inputdaten gleichzeitig zur Verfügung gestellt und durch das Netz propagiert \cite{Kriesel2007NeuralNetworks}.

 Um die Qualität der Gesamtarchitektur zu überprüfen, wurde der Pitch- und Feature-Size-Schätzer auf zwei verschiedene Weisen trainiert. Der erste Trainingsansatz ist das Training des Netzwerk mit Hilfe der Impulsverteilungen, welche durch die Pitch-Werte des CNN's generiert wurden. Im zweiten Trainingsansatz werden die Impulsverteilungen durch das Pitch-Label generiert. Für beide Neuronal Networks wurde MSE \eqref{eq:mse} als Errorfunktion verwendet.
 
 Der gesamte Trainingsprozess, wurde mit Tensorflow realisiert und mit Hilfe des Tracking-Tools Tensorboard überwacht und aller 50 Epochen mit Hilfe des Validierung-Datensatzes evaluiert. 


\chapter{Ergebnisse und Diskussion}
\section{Trainingsprozess}
\subsection{Convolutional Neuronal Network}
Der Trainingsverlauf des Convolutional Neuronal Networks wurde mit Hilfe der Tensorboard-Bibliothek überwacht. Parallel zum Trainingsprozess 		wurde, in einem Abstand von 50 Epochen, der Trainingsprozess mit Hilfe des Validierungsdatensatzes evaluiert. Um die Qualität des CNNs zu bestimmen, wurde Mean Squared Error als Qualitätsmaß eingesetzt (Gleichung \eqref{eq:mse}). Das CNN wurde über 3000 Epochen trainiert. Der Verlauf des Trainings- und Validierungsfehlers während des Trainingsprozesses ist in Abbildung \ref{img:train_cnn} dargestellt.

	
	\begin{figure}[hh]
	\centering
	\includegraphics[width=.75\textwidth]{images/learn_curve_cnn.png} 
	\caption{Verlauf des Trainings- und Validierungsfehlers des CNNs in Anhängigkeit der Epoche}
	\label{img:train_cnn}
	\end{figure}

In Abbildung \ref{img:train_cnn} sieht man bis zur tausendsten Epoche ein starker Abfall des Fehlers zu erkennen. Ab der tausendsten Epoche ist ein schwächeres Konvergenzverhalten zu beobachten. Der Verlauf des Trainings- und des Validierungsfehlers ist sehr ähnlich. Somit können nicht trainierte Samples mit nahezu gleicher Qualität wie trainierte Samples geschätzt werden. Während des Trainings konnte ein minimalerTrainingsfehler von 20910.45 und ein minimaler Validierungsfehler 23247.19 von erreicht werden.
\subsection{Fully-Connected Neuronal Network}
In Kapitel \ref{Ansatz} wurde beschrieben, dass das Fully-Connected Neuronal Network auf zwei verschiedene Weisen trainiert wurde. Im ersten Experiment wurde das Fully-Connected Neuronal Network mit der Impulsverteilung ,welche aus dem Pitch-Wert des CNNs generiert wurde, trainiert. Im zweiten Experiment wurde die Impulsverteilung aus dem Pitch-Label generiert. In beiden Experimenten wurde das Network 500 Epochen trainiert. Die kleinere Epochenanzahl resultiert aus dem schnelleren Konvergenzverhalten des Fully-Connected Neuronal Networks. Für das Fully-Connected Neuronal Network wurde ebenfalls Mean Squared Error als Qualitätsmaß verwendet. 

\subsubsection{ CNN-Input}
In Abbildung \ref{img:train_fc1} ist die Lernkurve des ersten Experimentes dargestellt. Während des Trainings konnte ein minimaler Trainingfehler von 75.80 und ein minimaler Validierungssfehler von 163.74 erreicht werden. Der Verlauf des Training- und des Validierungsfehlers zeigt ähnliches Konvergenzverhalten, das für Generalisierung spricht. Dennoch gibt es im minimal erreichten Trainings und Validierungsfehlers einen Unterschied von einem Faktor zwei. Somit ist die Qualität des Fully-Connected Neuronal Networks auf den Trainingsdaten deutlich höher als die der Validierungsdaten. 

	\begin{figure}[hh]
	\centering
	\includegraphics[width=.75\textwidth]{images/learn_curve_fc1.png} 
	\caption{Verlauf des Trainings- und Validierungsfehlers in Anhängigkeit der Epoche im ersten Experiment}
	\label{img:train_fc1}
	\end{figure}
\subsubsection{ Label-Input}
Das zweite Experiment (Abbildung \ref{img:train_fc2}) zeigt ähnliches Konvergenzverhalten wie beim ersten Experiment. Jedoch kommt es bei einer höheren  Epochenzahl zu weniger oszillation des Fehlers. Der minimale Trainingsfehler liegt bei 100.98 und der minimale Validierungsfehler liegt bei 190.72. Somit konnte eine ähnliche Qualität auf den Trainings- und Validierungsdaten erreicht werden wie beim ersten Experiment. 
	\begin{figure}[hh]
	\centering
	\includegraphics[width=.75\textwidth]{images/learn_curve_fc2.png} 
	\caption{Verlauf des Trainings- und Validierungsfehlers in Anhängigkeit der Epoche im zweiten Experiment}
	\label{img:train_fc2}
	\end{figure}
	\section{Evaluierung}
	
	\subsection{Convolutional Neuronal Network}
Um die Qualität des CNNs zu evaluieren, wurden die nicht trainierten Samples des Testdatensatzes zur Qualitätsbestimmung genutzt. Es konnte eine durchschnittliche absolute Abweichung von 109.73 und eine durchschnittliche relative Abweichung von 37\% erreicht werden. Aus der durchschnittlichen relativen und absoluten Abweichung kann eine schlechte Qualität des CNNs geschlussfolgert werden.
	
 Eine wichtige Beobachtung der Analyse des CNNs ist, dass mit steigendem Pitch-Label die Qualität der Pitch-Schätzung sich verringert (siehe Abbildung \ref{img:experiment1}).Im Kapitel \ref{Simulation} wurde bereits analysiert, dass mit steigendem Pitch-Wert die Abstände der Peaks kleiner werden und somit ein dichteres Detektorbild entsteht.

	\begin{figure}[hh!]
	\centering
	\includegraphics[width=0.85\textwidth]{images/experiment1.png} 
	\caption{Qualität der Pitch-Schätzung in Abhängigkeit des Startparameters Feature-Size}
	\label{img:experiment1}
	\end{figure} 
 
Eine wichtige Eigenschaft von CNNs bzw der Convolutional-Layer ist, dass sie Lokalität der Input-Daten nicht berücksichtigen, somit können globale Änderungen, wie zum Beispiel eine Verdichtung des Detekorbildes durch ein CNN schwerer erfasst werden. Dies spiegelt sich auch in den Detektorbildern in Abbildung \ref{img:bad_experiment1} wieder, welche alle im Zentrum des Bildes sehr dicht besetzt sind. 

	\begin{figure}[hh]
	\centering
	\includegraphics[width=0.75\textwidth]{images/experiment1_bad_predictions.png} 
	\caption{Detektorbilder zu schlechten Schätzungen. Alle drei Detektorbilder weisen mit einer Absolute Abweichung über 100 eine überdurchschnittliche schlechte Qualität auf. }
	\label{img:bad_experiment1}
	\end{figure}
	
Bilder mit niedrigerem Pitch-Wert können besser geschätzt werden,wie die Detektorbilder in Abbildung \ref{img:good_experiment1}. Sie weisen eine geringere Peak-Dichte auf, womit das CNN scheinbar besser umgehen kann. Eine weitere Begrünung für die schlechte Qualität des CNNs ist das Sampling der Fouriertransformation in der Simulation. In der Simulation wurde das 2048 Pixel große Grating mit einer Fouriertransformation mit 2048 Stützstellen implementiert. Das hat zur Folge, dass Peaks im Detektorbild nur durch einen Wert dargestellt werden und Zwischenwerte komplett verloren gehen. 

	\begin{figure}[hh]
		\centering
	\includegraphics[width=0.75\textwidth]{images/experiment1_good_predictions.png} 
	\caption{Detektorbilder zu guten Schätzungen}
	\label{img:good_experiment1}
	\end{figure}

	\subsection{Fully Connected Neuronal Network}
	\begin{figure}[hh!]
	\centering
	\includegraphics[width=.75\textwidth]{images/experiment3_1.png} 
	\caption{Qualität der Feature-Size in Abhängigkeit des Startparameters Pitch des Fully-Connected Neuronal Networks mit CNN-Input}
	\label{img:experiment3_1}
	\end{figure}
	
	\begin{figure}[hh!]
	\centering
	\includegraphics[width=.75\textwidth]{images/experiment3_2.png} 
	\caption{Qualität der Feature-Size in Abhängigkeit des Startparameters Pitch des Fully-Connected Neuronal Networks mit Pitch-Label-Input}
	\label{img:experiment3_1}
	\end{figure}
	
	\begin{figure}[hh!]
	\centering
	\includegraphics[width=.75\textwidth]{images/experiment4_1.png} 
	\caption{Qualität der Feature-Size in Abhängigkeit des Startparameters Sigma des Fully-Connected Neuronal Networks mit CNN-Input}
	\label{img:experiment4_1}
	\end{figure}
	
	\begin{figure}[hh!]
	\centering
	\includegraphics[width=.75\textwidth]{images/experiment4_2.png} 
	\caption{Qualität der Feature-Size in Abhängigkeit des Startparameters Sigma des Fully-Connected Neuronal Networks mit Pitch-Label-Input}
	\label{img:experiment4_2}
	\end{figure}
	
	\begin{figure}[hh!]
	\centering
	\includegraphics[width=.75\textwidth]{images/experiment5_1.png} 
	\caption{Qualität des Sigmas  in Abhängigkeit des Startparameters Pitch des Fully-Connected Neuronal Networks mit mit CNN-Input}
	\label{img:experiment4_1}
	\end{figure}
	
	\begin{figure}[hh!]
	\centering
	\includegraphics[width=.75\textwidth]{images/experiment5_2.png} 
	\caption{Qualität des Sigmas in Abhängigkeit des Startparameters Pitch des Fully-Connected Neuronal Networks mit Pitch-Label-Input}
	\label{img:experiment4_2}
	\end{figure}
	
	\begin{figure}[hh!]
	\centering
	\includegraphics[width=.75\textwidth]{images/experiment6_1.png} 
	\caption{Qualität des Sigmas  in Abhängigkeit des Startparameters Feature-Size des Fully-Connected Neuronal Networks mit mit CNN-Input}
	\label{img:experiment4_1}
	\end{figure}
	
	\begin{figure}[hh!]
	\centering
	\includegraphics[width=.75\textwidth]{images/experiment6_2.png} 
	\caption{Qualität des Sigmas in Abhängigkeit des Startparameters Feature-Size des Fully-Connected Neuronal Networks mit Pitch-Label-Input}
	\label{img:experiment4_2}
	\end{figure}
	
	
	
	\section{Fazit}
	\section{Ausblick}
	

	
\end{document}